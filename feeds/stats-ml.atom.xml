<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Le blog - Stats &amp; ML</title><link href="https://blog.statoscop.fr/" rel="alternate"></link><link href="https://blog.statoscop.fr/feeds/stats-ml.atom.xml" rel="self"></link><id>https://blog.statoscop.fr/</id><updated>2024-10-16T00:00:00+02:00</updated><entry><title>Python pour la Data Science : configurer son environnement de travail</title><link href="https://blog.statoscop.fr/setup-python.html" rel="alternate"></link><published>2024-10-16T00:00:00+02:00</published><updated>2024-10-16T00:00:00+02:00</updated><author><name>Antoine</name></author><id>tag:blog.statoscop.fr,2024-10-16:/setup-python.html</id><summary type="html">&lt;p&gt;Les essentiels et rien que les essentiels pour se lancer en Data Science avec Python.&lt;/p&gt;</summary><content type="html">&lt;div class="toc"&gt;&lt;span class="toctitle"&gt;Table des matières&lt;/span&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#installer-python-et-vscode"&gt;Installer Python et VSCode&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#installation-de-python"&gt;Installation de Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#installation-de-vscode"&gt;Installation de VSCode&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#bonus-installation-de-git"&gt;Bonus : Installation de Git&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#travailler-avec-python-sur-vos-projets"&gt;Travailler avec Python sur vos projets&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#gestionnaire-denvironnements"&gt;Gestionnaire d'environnements&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#les-notebooks-jupyter"&gt;Les notebooks jupyter&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;Python est un &lt;strong&gt;langage de programmation extrêmement complet&lt;/strong&gt; et souvent plébiscité pour conduire ses projets en Data Science. Sa grande flexibilité, le nombre très important de &lt;a href="https://pypi.org/"&gt;modules développés&lt;/a&gt; et de logiciels permettant de le faire tourner constitue une grande part de sa richesse. Mais elle est aussi souvent source de beaucoup de difficultés pour ses nouvelles utilisatrices et utilisateurs. Il est en effet parfois difficile de reproduire un &lt;strong&gt;environnement de travail simple et minimaliste&lt;/strong&gt;, semblable à ce que l'on obtiendrait plus directement en utilisant R et RStudio.&lt;br&gt;
Une des réponses à cette problématique est la solution &lt;a href="https://www.anaconda.com/download/"&gt;Anaconda&lt;/a&gt;, mais elle nous semble trop lourde et souvent source de complications. C'est pour cela que cette semaine, on vous recommande &lt;strong&gt;un environnement de travail pour la Data Science avec Python&lt;/strong&gt;, en se focalisant sur les outils qui nous semblent les plus &lt;strong&gt;pratiques et utiles&lt;/strong&gt; au quotidien.  &lt;/p&gt;
&lt;h1 id="installer-python-et-vscode"&gt;Installer Python et VSCode&lt;/h1&gt;
&lt;h2 id="installation-de-python"&gt;Installation de Python&lt;/h2&gt;
&lt;p&gt;La première étape est bien sûr d'installer Python. Avant cela, vous pouvez tout de même vérifier que ça n'est pas déjà le cas en ouvrant le terminal de votre système d'exploitation et en tapant :  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;python&lt;span class="w"&gt; &lt;/span&gt;--version
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;blockquote&gt;
&lt;p&gt;Attention, parfois l'alias utilisé par votre système ne sera pas &lt;code&gt;python&lt;/code&gt; mais &lt;code&gt;python3&lt;/code&gt;, il faut donc modifier les instructions données dans cette note en conséquence, ou &lt;a href="https://www.askpython.com/python/examples/python3-alias-as-python"&gt;modifier l'alias&lt;/a&gt;.  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Si Python est installé, sa version va s'afficher dans la console, sinon vous recevrez un message d'erreur. Dans ce cas, rendez-vous sur la &lt;a href="https://www.python.org/downloads/"&gt;page du site officiel&lt;/a&gt; pour télécharger la version de Python qui vous convient. Je vous conseille la 3.12, qui est assez récente mais a déjà été éprouvée. Surtout, &lt;strong&gt;n'oubliez pas de cocher la case &lt;code&gt;Add Python to PATH&lt;/code&gt;&lt;/strong&gt; quand cela vous est demandé, afin de pouvoir accéder à Python en ligne de commande.  &lt;/p&gt;
&lt;p&gt;Une fois Python installé, vous pouvez vérifier que tout s'est bien passé en tapant à nouveau &lt;code&gt;python --version&lt;/code&gt; depuis un terminal. Vous pouvez alors lancer depuis votre terminal une session Python en lançant l'instruction &lt;code&gt;python&lt;/code&gt;. Mais nous allons préférer passer par un &lt;strong&gt;environnement de développement intégré, ou IDE&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id="installation-de-vscode"&gt;Installation de VSCode&lt;/h2&gt;
&lt;p&gt;Le choix de l'IDE est déjà une première étape peu évidente, puisqu'il en existe de nombreux :  &lt;a href="https://www.jetbrains.com/pycharm/"&gt;Pycharm&lt;/a&gt;, &lt;a href="https://www.spyder-ide.org/"&gt;Spyder&lt;/a&gt;, &lt;a href="https://jupyter.org/"&gt;Jupyter Notebook&lt;/a&gt;... Nous vous proposons d'installer VSCode, parce qu'il est sans doute &lt;strong&gt;le plus populaire&lt;/strong&gt; en ce moment, et qu'il peut être utilisé &lt;strong&gt;pour des scripts Python, mais aussi des notebooks Jupyter&lt;/strong&gt;. Il supporte également de &lt;strong&gt;nombreux autres langages que Python&lt;/strong&gt; (HTML/CSS, Javascript, C/C++, Ruby....) et pourra donc vous servir pour des projets plus tournés vers le développement Web. Enfin, il a un &lt;strong&gt;module intégré permettant d'utiliser Git&lt;/strong&gt; sans ligne de commande, ce qui peut être très pratique pour une première prise en main d'un outil de gestion de versions.  &lt;/p&gt;
&lt;p&gt;Pour installer VSCode, &lt;a href="https://code.visualstudio.com/download"&gt;suivez les instructions correspondant à l'OS que vous utilisez&lt;/a&gt;. Une fois installé, ouvrez-le et rendez vous dans l'onglet extensions que vous trouverez sur la barre latérale à gauche de votre écran :   &lt;/p&gt;
&lt;p&gt;&lt;img alt="Pelican" src="../images/setup_python/image-2.png"&gt;&lt;/p&gt;
&lt;p&gt;Ce sont ces extensions de VSCode qui lui permettent de &lt;strong&gt;gérer tant de langages différents&lt;/strong&gt;. Vous pouvez d'ores et déjà installer les extensions &lt;strong&gt;Python et Jupyter&lt;/strong&gt;.  &lt;/p&gt;
&lt;h2 id="bonus-installation-de-git"&gt;Bonus : Installation de Git&lt;/h2&gt;
&lt;p&gt;Ça n'est pas l'objectif de cet article, mais on vous conseille fortement d'utiliser Git pour tous vos projets de Data Science. Pour cela, commencez par &lt;a href="https://git-scm.com/downloads"&gt;télécharger Git&lt;/a&gt; et créez-vous un compte sur &lt;a href="https://about.gitlab.com/"&gt;Gitlab&lt;/a&gt; ou &lt;a href="https://github.com/"&gt;Github&lt;/a&gt;.&lt;br&gt;
Si vous n'êtez pas à l'aise avec les lignes de commande, VSCode propose justement &lt;strong&gt;un outil intégré permettant de gérer vos fichiers et commits&lt;/strong&gt; en clic-bouton, toujours accessible depuis la barre latérale :  &lt;/p&gt;
&lt;p&gt;&lt;img alt="Pelican" src="../images/setup_python/image-6.png"&gt;&lt;/p&gt;
&lt;p&gt;Pour se lancer avec Git sur vos projets de Data Science en Python, on vous conseille cet &lt;a href="https://pythonds.linogaliana.fr/content/git/introgit.html"&gt;excellent article de Lino Galiana&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id="travailler-avec-python-sur-vos-projets"&gt;Travailler avec Python sur vos projets&lt;/h1&gt;
&lt;p&gt;Ok, maintenant vous êtes prêts à vous lancer dans vos projets de Data Science. Il ne vous reste plus qu'à choisir et configurer un gestionnaire d'environnements avant de vous lancer enfin dans votre code Python!&lt;/p&gt;
&lt;h2 id="gestionnaire-denvironnements"&gt;Gestionnaire d'environnements&lt;/h2&gt;
&lt;p&gt;Un gestionnaire d'environnements vous permet de gérer les dépendances de votre projet afin que ceux-ci soient indépendants les uns des autres et plus reproductibles. En dehors du fait d'avoir des bibliothèques de packages propres à chaque projet, il vous permet également de gérer différentes versions de Python en fonction des besoins de chaque projet.&lt;br&gt;
Là aussi, il existe différentes possibilités : &lt;code&gt;virtualenv&lt;/code&gt;, &lt;code&gt;pyenv&lt;/code&gt;, &lt;code&gt;pipenv&lt;/code&gt;... Nous optons de notre côté pour le gestionnaire &lt;code&gt;conda&lt;/code&gt;, qui nous semble pratique d'utilisation, notamment pour changer de versions de python simplement. Pour l'installer, nous vous proposons d'&lt;a href="https://docs.anaconda.com/miniconda/miniconda-install/"&gt;installer &lt;code&gt;miniconda&lt;/code&gt;&lt;/a&gt; qui est une version allégée d'Anaconda nous permettant de faire tourner &lt;code&gt;conda&lt;/code&gt;. Une fois conda installé, rendez-vous sur le terminal, accessible directement sur VSCode en bas de votre écran :  &lt;/p&gt;
&lt;p&gt;&lt;img alt="Pelican" src="../images/setup_python/image-4.png"&gt;&lt;/p&gt;
&lt;p&gt;Vous pouvez maintenant créer votre premier environnement virtuel, en tapant dans la console :  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;conda&lt;span class="w"&gt; &lt;/span&gt;create&lt;span class="w"&gt; &lt;/span&gt;--name&lt;span class="w"&gt; &lt;/span&gt;mon_premier_env&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;python&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;.12&lt;span class="w"&gt; &lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Il n'est pas nécessaire de spécifier la version de python pour créer l'environnement mais c'est une bonne pratique, pour clarifier la version qui sera utilisée dans celui-ci. Vous pouvez aussi installer des packages directement à la création en mettant leurs noms à la suite de la version de Python. &lt;br&gt;
Une fois créé, il ne reste plus qu'à l'activer avec :  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;conda&lt;span class="w"&gt; &lt;/span&gt;activate&lt;span class="w"&gt; &lt;/span&gt;mon_premier_env&lt;span class="w"&gt; &lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Dans votre terminal, la mention &lt;code&gt;(base)&lt;/code&gt; devrait être remplacée par &lt;code&gt;(mon_premier_env)&lt;/code&gt;, vous indiquant que votre environnement est bien activé. 
Dorénavant, les packages que vous installerez seront installés seulement pour celui-ci. Nous allons ici installer pandas avec : &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;conda&lt;span class="w"&gt; &lt;/span&gt;install&lt;span class="w"&gt; &lt;/span&gt;pandas
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;blockquote&gt;
&lt;p&gt;Attention, ça n'est pas parce que vous utilisez &lt;code&gt;conda&lt;/code&gt; comme gestionnaire d'environnements que  vous ne pouvez pas utiliser &lt;code&gt;pip&lt;/code&gt; pour installer des packages. On préfèrera cependant utiliser &lt;code&gt;conda&lt;/code&gt; quand cela est possible pour faciliter les gestions de dépendances entre packages.  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Enfin, pour sortir de votre environnement il vous suffit de taper :  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;conda&lt;span class="w"&gt; &lt;/span&gt;deactivate
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2 id="les-notebooks-jupyter"&gt;Les notebooks jupyter&lt;/h2&gt;
&lt;p&gt;Normalement, vous avez déjà installé les extensions Jupyter et Python sur VSCode. Vous pouvez donc cliquer sur &lt;code&gt;File -&amp;gt; New File... -&amp;gt; Jupyter Notebook&lt;/code&gt;. Cela va vous créer votre premier notebook, avec une extension &lt;code&gt;.ipynb&lt;/code&gt;. 
On vous recommande les notebooks pour la partie exploration de vos données car ils vous permettent de faire tourner des blocs de Python et aussi d'intégrer du Markdown pour la mise en forme. C'est d'ailleurs des notebooks que l'on utilise pour rédiger nos &lt;a href="https://blog.statoscop.fr"&gt;notes de blog sur Python&lt;/a&gt;. Une fois votre notebook ouvert, cliquez sur &lt;code&gt;Select kernel&lt;/code&gt; en haut à droite de votre fichier :  &lt;/p&gt;
&lt;p&gt;&lt;img alt="Pelican" src="../images/setup_python/image-3.png"&gt;&lt;/p&gt;
&lt;p&gt;Dans &lt;code&gt;Python Environments...&lt;/code&gt; vous allez normalement trouver votre environnement conda. Maintenant, créez une cellule de code et lancez :  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Et là... catastrophe :  &lt;/p&gt;
&lt;p&gt;&lt;img alt="Pelican" src="../images/setup_python/image-5.png"&gt;&lt;/p&gt;
&lt;p&gt;Mais non, c'est normal! On a juste oublié de vous expliquer quelque chose. Les notebooks s'appuient sur une version améliorée de Python, que l'on appelle IPython. C'est une surcouche interactive de python qui permet notamment de faire tourner Python par blocs de code, comme dans les notebooks. Vous pouvez l'installer en clic-bouton comme cela vous est suggéré, ou revenir dans le terminal, activer votre environnement et lancer :  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;conda&lt;span class="w"&gt; &lt;/span&gt;install&lt;span class="w"&gt; &lt;/span&gt;ipykernel
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Maintenant, vous pouvez importer votre package &lt;code&gt;pandas&lt;/code&gt; depuis votre notebook et lancer vos premières analyses exploratoires. Il vous reste encore probablement de nombreux problèmes à résoudre, mais on espère que cet article vous aura bien accompagné pour vous lancer!  &lt;/p&gt;
&lt;p&gt;C'est la fin de cet article! N'hésitez pas à &lt;a href="https://www.statoscop.fr"&gt;visiter notre site&lt;/a&gt; et à nous suivre sur &lt;a href="https://twitter.com/stato_scop"&gt;Twitter&lt;/a&gt; et &lt;a href="https://www.linkedin.com/company/statoscop"&gt;Linkedin&lt;/a&gt;. Pour retrouver l'ensemble du code ayant servi à générer cette note, vous pouvez vous rendre sur le &lt;a href="https://github.com/Statoscop/notebooks-blog"&gt;github de Statoscop&lt;/a&gt;.  &lt;/p&gt;</content><category term="Python"></category><category term="Python"></category><category term="Data Science"></category><category term="conda"></category><category term="anaconda"></category><category term="vscode"></category><category term="notebook"></category></entry><entry><title>Comprendre et interpréter les p-values</title><link href="https://blog.statoscop.fr/comprendre-et-interpreter-les-p-values.html" rel="alternate"></link><published>2024-07-09T00:00:00+02:00</published><updated>2024-07-09T00:00:00+02:00</updated><author><name>Antoine</name></author><id>tag:blog.statoscop.fr,2024-07-09:/comprendre-et-interpreter-les-p-values.html</id><summary type="html">&lt;p&gt;Petite présentation intuitive des p-values et de leur utilisation dans nos modèles statistiques.&lt;/p&gt;</summary><content type="html">&lt;div class="toc"&gt;&lt;span class="toctitle"&gt;Table des matières&lt;/span&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#les-p-values-et-les-tests-statistiques"&gt;Les p-values et les tests statistiques&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#interpretation-des-p-values"&gt;Interprétation des p-values&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#conclusion"&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;Aujourd'hui c'est à un grand classique de la statistique que l'on s'attaque : la &lt;strong&gt;p-value, ou valeur p&lt;/strong&gt;. Fondamentale dans l'analyse des résultats de la recherche scientifique, elle est pourtant &lt;strong&gt;souvent mal interprétée&lt;/strong&gt;. C'est sur elle que l'on s'appuie pour &lt;strong&gt;confirmer ou infirmer une hypothèse&lt;/strong&gt; et juger de la &lt;strong&gt;significativé de nos résultats&lt;/strong&gt;. Mais qu'est-ce que cela implique et comment bien appréhender ce qu'elle permet (et surtout ce qu'elle ne permet pas) de conclure? On essaye de voir ça ensemble, de la manière la plus intuitive possible!  &lt;/p&gt;
&lt;h1 id="les-p-values-et-les-tests-statistiques"&gt;Les p-values et les tests statistiques&lt;/h1&gt;
&lt;p&gt;Pour comprendre les p-values, il faut aborder la notion de &lt;strong&gt;tests statistiques&lt;/strong&gt;. Ils permettent de tester une &lt;strong&gt;Hypothèse nulle &lt;code&gt;H0&lt;/code&gt;&lt;/strong&gt; contre une &lt;strong&gt;hypothèse alternative &lt;code&gt;H1&lt;/code&gt;&lt;/strong&gt;. Par exemple, prenons le cas d'une régression linéaire où on cherche à estimer des coefficients &lt;span class="math"&gt;\(\beta_i\)&lt;/span&gt; décrivant le lien entre une variable d'intérêt  &lt;span class="math"&gt;\(Y\)&lt;/span&gt; et des variables explicatives &lt;span class="math"&gt;\(X_i\)&lt;/span&gt; :  &lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_3 + \dots\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Pour chaque coefficient estimé &lt;span class="math"&gt;\(\beta_i\)&lt;/span&gt;, on utilise le &lt;strong&gt;test t de Student&lt;/strong&gt; qui nous permet de tester les hypothèses :&lt;br&gt;
- &lt;code&gt;H0&lt;/code&gt; : &lt;span class="math"&gt;\(\beta_i  = 0\)&lt;/span&gt;&lt;br&gt;
- &lt;code&gt;H1&lt;/code&gt; : &lt;span class="math"&gt;\(\beta_i \neq 0\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Le principe du test est le suivant : on va &lt;strong&gt;partir du principe que H0 est vrai&lt;/strong&gt; et on va voir &lt;strong&gt;quelle est la chance d'observer notre résultat dans ce monde théorique&lt;/strong&gt;. Ce test statistique va ainsi nous donner la &lt;strong&gt;distribution possible des résultats que l'on pourrait obtenir à partir de différents échantillons si &lt;code&gt;H0&lt;/code&gt; était vraie&lt;/strong&gt;. Selon où l'on se situe dans cette distribution, on va pouvoir juger de la &lt;strong&gt;vraisemblance de cette hypothèse H0&lt;/strong&gt;, en fonction d'un &lt;strong&gt;seuil alpha que l'on peut faire varier&lt;/strong&gt;. En fonction de la valeur de &lt;code&gt;t&lt;/code&gt; obtenue avec notre échantillon, on peut décider de rejeter ou non l'hypothèse &lt;code&gt;H0&lt;/code&gt; :  &lt;/p&gt;
&lt;p&gt;&lt;img alt="Pelican" src="../images/p_values/unnamed-chunk-1-1.png"&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Sur le graphique ci-dessus, la zone rouge représente &lt;strong&gt;5% de l'aire de la courbe de densité&lt;/strong&gt;. Si la valeur obtenue par notre test est dans cette zone, on sait que &lt;strong&gt;cela représenterait 5% ou moins des résultats possibles que l'on aurait obtenus si &lt;code&gt;H0&lt;/code&gt; était vraie&lt;/strong&gt;. On peut donc en déduire que &lt;strong&gt;la nullité du coefficient est peu probable&lt;/strong&gt;. &lt;/p&gt;
&lt;p&gt;Bien sûr, si on modifie le seuil alpha dans un sens plus restrictif, mettant le seuil de significativité à 1%, cela va restreindre la zone rouge de notre graphique. Il faudra alors obtenir &lt;strong&gt;une valeur &lt;code&gt;t&lt;/code&gt; encore plus extrême pour rejeter &lt;code&gt;H0&lt;/code&gt;&lt;/strong&gt; : &lt;/p&gt;
&lt;p&gt;&lt;img alt="Pelican" src="../images/p_values/unnamed-chunk-2-1.png"&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Ainsi, lorsqu'on fait tourner un modèle de régression sur notre logiciel de statistiques favori et que l'on obtient une p-value, il s'agit du &lt;strong&gt;seuil alpha de notre hypothèse &lt;code&gt;H0&lt;/code&gt;&lt;/strong&gt; qui doit nous permettre de décider de la rejeter ou non. On va donc l'utiliser pour décider de la &lt;strong&gt;significativité de ce coefficient&lt;/strong&gt;. Si l'on devait synthétiser ce que veut dire la p-value en une phrase, cela donnerait :   &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Si la vraie valeur du coefficient était 0 et que 
j'avais fait tourner ce modèle sur 100 échantillons 
différents, j'aurais obtenu un résultat au moins 
aussi extrême dans p cas.   &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Ainsi, &lt;strong&gt;plus p est faible, plus on peut écarter l'hypothèse que le coefficient estimé soit nul&lt;/strong&gt;.  &lt;/p&gt;
&lt;h1 id="interpretation-des-p-values"&gt;Interprétation des p-values&lt;/h1&gt;
&lt;p&gt;Il faut bien comprendre que la p-value et la &lt;strong&gt;significativité du coefficient&lt;/strong&gt; qui en découle ne portent que sur la question de savoir si ce coefficient est ou non différent de zéro. Cela n'indique pas si le résultat trouvé a une importance particulière. Un coefficient peut très bien être &lt;strong&gt;significatif statistiquement&lt;/strong&gt; (donc probablement différent de zéro) mais &lt;strong&gt;en pratique insignifiant&lt;/strong&gt;. Il faut donc le confronter à l'expertise pratique de la question de recherche étudiée.  &lt;/p&gt;
&lt;p&gt;Une faible p-value n'est pas non plus le signe d'une &lt;strong&gt;estimation précise&lt;/strong&gt;. Pour juger de cet aspect, il est important de regarder &lt;strong&gt;les intervalles de confiance&lt;/strong&gt;. Un coefficient peut très bien être &lt;strong&gt;significativement différent de zéro mais avoir un intervalle de confiance très large&lt;/strong&gt;, ce qui est très important à considérer en fonction des implications pratiques de votre recherche. On sait seulement que si par exemple &lt;strong&gt;l'intervalle de confiance à 95% ne contient pas 0&lt;/strong&gt; (ou 1 si on estime des &lt;a href="https://blog.statoscop.fr/risques-relatifs-et-odds-ratios-comment-les-interpreter-et-les-comparer.html"&gt;odds-ratios&lt;/a&gt;), le &lt;strong&gt;coefficient estimé est significatif à au moins 5%&lt;/strong&gt;. &lt;/p&gt;
&lt;p&gt;De plus, un résultat peut être &lt;strong&gt;non significatif en raison d'une mauvaise calibration du modèle&lt;/strong&gt; : un échantillon trop peu important, de trop nombreuses variables explicatives, etc... C'est notamment pour cette raison qu'il &lt;strong&gt;ne faut pas directement interpréter un coefficient non significatif comme un absence d'effet&lt;/strong&gt;. C'est plutôt une absence de preuve d'effet. Oui, c'est moins facile à rédiger, mais cela rend plus justice à la complexité des statistiques inférentielles.    &lt;/p&gt;
&lt;p&gt;En général, le consensus scientifique fixe le &lt;strong&gt;seuil de significativité à 5%&lt;/strong&gt;. Bien sûr, c'est forcément au moins partiellement arbitraire et cela pose question : on écarterait un résultat avec une p-value à 5,1% mais on afficherait fièrement celui avec une p-value à 4,9%?    &lt;/p&gt;
&lt;p&gt;Il est ainsi tentant pour les chercheurs de construire leur modèle en fonction de la p-value recherchée, et non de la question de recherche affichée, ce qui est complètement contre-productif. D'autant que la nature de la p-value fait que &lt;strong&gt;si l'on teste un nombre très important de fois, on finira bien par trouver des résultats significatifs&lt;/strong&gt;, mais uniquement du fait du hasard. Cette mauvaise pratique, volontaire ou non, est bien identifiée et se nomme le &lt;a href="https://en.wikipedia.org/wiki/Data_dredging"&gt;p-hacking&lt;/a&gt;. La bonne manière de se prémunir de cet écueil est de &lt;strong&gt;définir la question de recherche et les modèles statistiques en amont de la collecte de données&lt;/strong&gt; et de calibrer l'échantillon en fonction de ceux-ci. Il faut ensuite tâcher de ne pas s'écarter de ces axes de recherche...même si on n'obtient pas les p-values qu'on espérait!  &lt;/p&gt;
&lt;h1 id="conclusion"&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;La p-value, ça n'est donc pas du tout la &lt;em&gt;probabilité que le coefficient soit incorrect&lt;/em&gt; ! Dans le cas d'une régression, c'est un indicateur de la vraisemblance que celui-ci soit égal à zéro. Mais &lt;strong&gt;un coefficient significatif peut aussi avoir une estimation très imprécise, ou une valeur insignifiante&lt;/strong&gt;. Il est donc fondamental d'affiner son diagnostic, avec par exemple les intervalles de confiance, et surtout l'interprétation de quelqu'un qui comprend les implications pratiques d'un coefficient!  &lt;/p&gt;
&lt;p&gt;C'est tout pour aujourd'hui! N'hésitez pas à &lt;a href="https://www.statoscop.fr"&gt;visiter notre site (qui a fait peau neuve, vous avez remarqué?)&lt;/a&gt; et à nous suivre sur &lt;a href="https://twitter.com/stato_scop"&gt;Twitter&lt;/a&gt; et &lt;a href="https://www.linkedin.com/company/statoscop"&gt;Linkedin&lt;/a&gt;. Pour retrouver le code ayant servi à générer cette note, vous pouvez vous rendre sur le &lt;a href="https://github.com/Statoscop/notebooks-blog"&gt;github de Statoscop&lt;/a&gt;.  &lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="Stats &amp; ML"></category><category term="statistiques"></category><category term="p-values"></category><category term="R"></category><category term="tests"></category></entry><entry><title>Taux standardisés : calcul et interprétation avec R</title><link href="https://blog.statoscop.fr/taux-standardises-calcul-et-interpretation-avec-r.html" rel="alternate"></link><published>2023-05-17T00:00:00+02:00</published><updated>2023-05-17T00:00:00+02:00</updated><author><name>Antoine</name></author><id>tag:blog.statoscop.fr,2023-05-17:/taux-standardises-calcul-et-interpretation-avec-r.html</id><summary type="html">&lt;p&gt;Présentation de la méthode de standardisation directe sur les taux de survie des passagers du Titanic.&lt;/p&gt;</summary><content type="html">&lt;div class="toc"&gt;&lt;span class="toctitle"&gt;Table des matières&lt;/span&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#principe-de-la-standardisation-directe"&gt;Principe de la standardisation directe&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#analyses-exploratoires-des-donnees"&gt;Analyses exploratoires des données&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#calcul-pas-a-pas-des-taux-standardises-de-survie-au-naufrage-du-titanic"&gt;Calcul pas-à-pas des taux standardisés de survie au naufrage du Titanic&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#pour-conclure"&gt;Pour conclure&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;Dans cette note nous présentons la méthode de standardisation directe des taux, qui permet de comparer des fréquences d'évènement entre différentes sous-populations en contrôlant par une ou plusieurs autres variables. Après avoir défini le principe général de standardisation directe, on présente une mise en oeuvre pas-à-pas de la méthode sur une étude de cas à partir des données des passagers du Titanic.  &lt;/p&gt;
&lt;h1 id="principe-de-la-standardisation-directe"&gt;Principe de la standardisation directe&lt;/h1&gt;
&lt;p&gt;Les méthodes de standardisation des taux sont principalement étudiées en épidémiologie. Elles permettent en effet de répondre au problème suivant : comment &lt;strong&gt;comparer des indicateurs épidémiologiques&lt;/strong&gt; entre différents pays ayant leurs spécificités démographiques? &lt;br&gt;
On peut lire par exemple sur le site des &lt;a href="https://donnees.banquemondiale.org"&gt;données de la banque mondiale&lt;/a&gt; que le taux de mortalité en 2020 en Australie est de 6 pour 1000 habitants, contre 12 pour 1000 habitants en Allemagne. Or, cet indicateur est bien sûr fortement influencé par la structure d'âge de la population concernée. Pour correctement comparer cet indicateur entre l'Australie et l'Allemagne et éventuellement en tirer des conclusions sur des différences de qualité de vie entre les deux pays, il faudrait &lt;strong&gt;comparer ces taux à structure d'âge constante&lt;/strong&gt;. &lt;br&gt;
C'est précisément ce que permet de faire la standardisation directe. Il est nécessaire pour cela de disposer du détail de l'indicateur par tranche d'âge dans chacun des pays. Dans notre exemple, une fois qu'on dispose des taux de mortalité par tranche d'âge en Australie et en Allemagne, on les  applique à &lt;strong&gt;une structure d'âge de référence&lt;/strong&gt;, qui peut être soit celle d'un des deux pays, soit celle du monde entier si on dispose de l'information. On peut alors obtenir un nouveau taux de mortalité global &lt;strong&gt;corrigé de l'effet lié à l'âge&lt;/strong&gt; et permettant une comparaison plus pertinente entre les pays. Voyons concrètement comment on peut mettre en oeuvre cette méthode sur une étude de cas en R.  &lt;/p&gt;
&lt;h1 id="analyses-exploratoires-des-donnees"&gt;Analyses exploratoires des données&lt;/h1&gt;
&lt;p&gt;Pour notre petit exemple, on s'appuie sur un dataset très connu : les &lt;a href="https://www.kaggle.com/c/titanic"&gt;données des passagers du Titanic&lt;/a&gt;. Les informations qui nous intéressent ici sont la classe économique, l'âge et le fait d'avoir survécu ou non au naufrage. On ne garde que les observations ayant des valeurs renseignées pour ces 3 variables. On veut répondre à la question suivante : &lt;strong&gt;le fait d'être dans une classe économique aisée augmente-t-elle les chances de survie au nauffrage?&lt;/strong&gt;  &lt;/p&gt;
&lt;p&gt;La première approche de cette question est bien sûr de calculer les taux de survie par classe économique. le résultat est le suivant :  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;titanic_data&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;group_by&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pclass&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nf"&gt;summarise&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tx_survie&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;survived&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;n&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;knitr&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="nf"&gt;kable&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="right"&gt;pclass&lt;/th&gt;
&lt;th align="right"&gt;tx_survie&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="right"&gt;1&lt;/td&gt;
&lt;td align="right"&gt;0.6373239&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;2&lt;/td&gt;
&lt;td align="right"&gt;0.4406130&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;3&lt;/td&gt;
&lt;td align="right"&gt;0.2614770&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;On constate en effet une forte disparité des taux de survie en fonction de la classe économique, puisque les passagers de 1ere classe sont 63,7% à survivre, contre 44,1% des passagers de seconde classe et 26,1% des passagers de 3e classe.&lt;br&gt;
Est-on bien sûr cependant que l'on observe &lt;strong&gt;l'effet de la classe économique et pas d'un autre facteur de confusion&lt;/strong&gt;? On peut par exemple imaginer que l'âge a un effet important sur la chance de survie, et qu'il est également lié à la classe économique choisie pour le voyage. Vérifions ces hypothèses en croisant la répartition en tranches d'âge dans chaque classe :  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;titanic_data&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nf"&gt;group_by&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pclass&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;tr_age&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nf"&gt;summarise&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;eff&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;n&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;# À ce stade le df n&amp;#39;est plus groupé que par pclass&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nf"&gt;mutate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Proportion&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;eff&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;eff&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nf"&gt;select&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;eff&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;knitr&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="nf"&gt;kable&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="right"&gt;pclass&lt;/th&gt;
&lt;th align="left"&gt;tr_age&lt;/th&gt;
&lt;th align="right"&gt;Proportion&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="right"&gt;1&lt;/td&gt;
&lt;td align="left"&gt;0 - 17 ans&lt;/td&gt;
&lt;td align="right"&gt;0.0528169&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;1&lt;/td&gt;
&lt;td align="left"&gt;18 - 34 ans&lt;/td&gt;
&lt;td align="right"&gt;0.3239437&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;1&lt;/td&gt;
&lt;td align="left"&gt;35 - 49 ans&lt;/td&gt;
&lt;td align="right"&gt;0.3697183&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;1&lt;/td&gt;
&lt;td align="left"&gt;50 ans ou +&lt;/td&gt;
&lt;td align="right"&gt;0.2535211&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;2&lt;/td&gt;
&lt;td align="left"&gt;0 - 17 ans&lt;/td&gt;
&lt;td align="right"&gt;0.1264368&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;2&lt;/td&gt;
&lt;td align="left"&gt;18 - 34 ans&lt;/td&gt;
&lt;td align="right"&gt;0.5823755&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;2&lt;/td&gt;
&lt;td align="left"&gt;35 - 49 ans&lt;/td&gt;
&lt;td align="right"&gt;0.1954023&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;2&lt;/td&gt;
&lt;td align="left"&gt;50 ans ou +&lt;/td&gt;
&lt;td align="right"&gt;0.0957854&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;3&lt;/td&gt;
&lt;td align="left"&gt;0 - 17 ans&lt;/td&gt;
&lt;td align="right"&gt;0.2115768&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;3&lt;/td&gt;
&lt;td align="left"&gt;18 - 34 ans&lt;/td&gt;
&lt;td align="right"&gt;0.6047904&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;3&lt;/td&gt;
&lt;td align="left"&gt;35 - 49 ans&lt;/td&gt;
&lt;td align="right"&gt;0.1576846&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;3&lt;/td&gt;
&lt;td align="left"&gt;50 ans ou +&lt;/td&gt;
&lt;td align="right"&gt;0.0259481&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;On constate en effet que la classe 3 comporte bien plus de mineurs et bien moins de passagers de plus de cinquante ans que la première classe. Comme on s'y attendait, &lt;strong&gt;plus la classe économique est aisée, plus les passagers ont un âge élevé&lt;/strong&gt;. Voyons maintenant si les taux de survie varient en fonction de l'âge :  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;titanic_data&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;group_by&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tr_age&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nf"&gt;summarise&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tx_survie&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;survived&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;n&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;knitr&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="nf"&gt;kable&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;tr_age&lt;/th&gt;
&lt;th align="right"&gt;tx_survie&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;0 - 17 ans&lt;/td&gt;
&lt;td align="right"&gt;0.5259740&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;18 - 34 ans&lt;/td&gt;
&lt;td align="right"&gt;0.3765996&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;35 - 49 ans&lt;/td&gt;
&lt;td align="right"&gt;0.4085106&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;50 ans ou +&lt;/td&gt;
&lt;td align="right"&gt;0.4000000&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Les taux de survie ne semblent pas beaucoup varier en fonction de l'âge, à part pour les mineurs qui ont un taux de survie bien supérieur aux autres. Croisons maintenant les taux de survie en fonction de la classe économique &lt;strong&gt;et&lt;/strong&gt; de la tranche d'âge :  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;titanic_data&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;group_by&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pclass&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;tr_age&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nf"&gt;summarise&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tx_survie&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;survived&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;n&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;knitr&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="nf"&gt;kable&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="right"&gt;pclass&lt;/th&gt;
&lt;th align="left"&gt;tr_age&lt;/th&gt;
&lt;th align="right"&gt;tx_survie&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="right"&gt;1&lt;/td&gt;
&lt;td align="left"&gt;0 - 17 ans&lt;/td&gt;
&lt;td align="right"&gt;0.8666667&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;1&lt;/td&gt;
&lt;td align="left"&gt;18 - 34 ans&lt;/td&gt;
&lt;td align="right"&gt;0.7065217&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;1&lt;/td&gt;
&lt;td align="left"&gt;35 - 49 ans&lt;/td&gt;
&lt;td align="right"&gt;0.6285714&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;1&lt;/td&gt;
&lt;td align="left"&gt;50 ans ou +&lt;/td&gt;
&lt;td align="right"&gt;0.5138889&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;2&lt;/td&gt;
&lt;td align="left"&gt;0 - 17 ans&lt;/td&gt;
&lt;td align="right"&gt;0.8787879&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;2&lt;/td&gt;
&lt;td align="left"&gt;18 - 34 ans&lt;/td&gt;
&lt;td align="right"&gt;0.4144737&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;2&lt;/td&gt;
&lt;td align="left"&gt;35 - 49 ans&lt;/td&gt;
&lt;td align="right"&gt;0.3333333&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;2&lt;/td&gt;
&lt;td align="left"&gt;50 ans ou +&lt;/td&gt;
&lt;td align="right"&gt;0.2400000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;3&lt;/td&gt;
&lt;td align="left"&gt;0 - 17 ans&lt;/td&gt;
&lt;td align="right"&gt;0.3679245&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;3&lt;/td&gt;
&lt;td align="left"&gt;18 - 34 ans&lt;/td&gt;
&lt;td align="right"&gt;0.2574257&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;3&lt;/td&gt;
&lt;td align="left"&gt;35 - 49 ans&lt;/td&gt;
&lt;td align="right"&gt;0.1645570&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;3&lt;/td&gt;
&lt;td align="left"&gt;50 ans ou +&lt;/td&gt;
&lt;td align="right"&gt;0.0769231&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;On constate là plusieurs choses :&lt;br&gt;
- Au sein de chaque classe économique il y a un lien très clair entre l'âge et le taux de survie : plus on vieillit pluys celui-ci baisse.&lt;br&gt;
- Au sein de chaque tranche d'âge, plus la classe économique est élevée plus la chance de survie augmente. La seule exception est la tranche d'âge 0 - 17 ans de la seconde classe qui a un taux de survie légèrement supérieur à la population du même âge de la 1ere classe (87,9% contre 86,7%).  &lt;/p&gt;
&lt;p&gt;Au vu de ces éléments il apparaît légitime de calculer des taux standardisés pour comparer des fréquences de survie au sein de chaque classe corrigées de l'effet de l'âge.  &lt;/p&gt;
&lt;h1 id="calcul-pas-a-pas-des-taux-standardises-de-survie-au-naufrage-du-titanic"&gt;Calcul pas-à-pas des taux standardisés de survie au naufrage du Titanic&lt;/h1&gt;
&lt;p&gt;Au vu des résultats des taux de survie croisés par classe et âge, on sait déjà que la classe économique et l'âge jouent sur la chance de survie. Le calcul des taux standardisés de survie va permettre de quantifier &lt;strong&gt;l'effet de la classe économique isolé de l'effet âge&lt;/strong&gt;. Le principe est le suivant : on calcule le taux de survie que l'on observerait dans chaque classe économique &lt;strong&gt;si la répartition des passagers en classe d'âge était la même que celle de la population de référence&lt;/strong&gt;. Dans notre exemple, la population de référence est l'ensemble des passagers.&lt;/p&gt;
&lt;p&gt;La première étape est de récupérer les effectifs de classe d'âge de la population de référence :  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;titanic_data&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;group_by&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tr_age&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nf"&gt;summarise&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;eff&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;n&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;rep_age_ref&lt;/span&gt;

&lt;span class="n"&gt;knitr&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="nf"&gt;kable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rep_age_ref&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;tr_age&lt;/th&gt;
&lt;th align="right"&gt;eff&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;0 - 17 ans&lt;/td&gt;
&lt;td align="right"&gt;154&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;18 - 34 ans&lt;/td&gt;
&lt;td align="right"&gt;547&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;35 - 49 ans&lt;/td&gt;
&lt;td align="right"&gt;235&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;50 ans ou +&lt;/td&gt;
&lt;td align="right"&gt;110&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;On calcule ensuite comme précédemment les taux de survie par tranche d'âge de chaque classe économique et on transforme la table pour avoir une colonne par classe économique.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;titanic_data&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;group_by&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pclass&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;tr_age&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;# taux de survie par classe et tranche d&amp;#39;âge&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nf"&gt;summarise&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;survie&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;survived&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;n&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;# on transforme la table en largeur pour avoir trois colonnes&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;# donnant le taux de survie&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;tidyr&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="nf"&gt;pivot_wider&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;names_from&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;pclass&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;values_from&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;survie&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;                     &lt;/span&gt;&lt;span class="c1"&gt;# option names_glue pour spécifier le nom des variables créées&lt;/span&gt;
&lt;span class="w"&gt;                     &lt;/span&gt;&lt;span class="n"&gt;names_glue&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;{.value}_{pclass}&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;survie_age_class&lt;/span&gt;

&lt;span class="n"&gt;knitr&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="nf"&gt;kable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;survie_age_class&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;tr_age&lt;/th&gt;
&lt;th align="right"&gt;survie_1&lt;/th&gt;
&lt;th align="right"&gt;survie_2&lt;/th&gt;
&lt;th align="right"&gt;survie_3&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;0 - 17 ans&lt;/td&gt;
&lt;td align="right"&gt;0.8666667&lt;/td&gt;
&lt;td align="right"&gt;0.8787879&lt;/td&gt;
&lt;td align="right"&gt;0.3679245&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;18 - 34 ans&lt;/td&gt;
&lt;td align="right"&gt;0.7065217&lt;/td&gt;
&lt;td align="right"&gt;0.4144737&lt;/td&gt;
&lt;td align="right"&gt;0.2574257&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;35 - 49 ans&lt;/td&gt;
&lt;td align="right"&gt;0.6285714&lt;/td&gt;
&lt;td align="right"&gt;0.3333333&lt;/td&gt;
&lt;td align="right"&gt;0.1645570&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;50 ans ou +&lt;/td&gt;
&lt;td align="right"&gt;0.5138889&lt;/td&gt;
&lt;td align="right"&gt;0.2400000&lt;/td&gt;
&lt;td align="right"&gt;0.0769231&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Il ne reste plus qu'à fusionner les deux tables ainsi créées et à appliquer chacun des taux de survie aux effectifs par tranche d'âge de la population de référence :  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;rep_age_ref&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;inner_join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;survie_age_class&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;by&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;tr_age&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nf"&gt;mutate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nf"&gt;across&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;starts_with&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;survie_&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;~&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;.&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;eff&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;eff_survie_age_class&lt;/span&gt;
&lt;span class="n"&gt;knitr&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="nf"&gt;kable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;eff_survie_age_class&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;tr_age&lt;/th&gt;
&lt;th align="right"&gt;eff&lt;/th&gt;
&lt;th align="right"&gt;survie_1&lt;/th&gt;
&lt;th align="right"&gt;survie_2&lt;/th&gt;
&lt;th align="right"&gt;survie_3&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;0 - 17 ans&lt;/td&gt;
&lt;td align="right"&gt;154&lt;/td&gt;
&lt;td align="right"&gt;133.46667&lt;/td&gt;
&lt;td align="right"&gt;135.33333&lt;/td&gt;
&lt;td align="right"&gt;56.660377&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;18 - 34 ans&lt;/td&gt;
&lt;td align="right"&gt;547&lt;/td&gt;
&lt;td align="right"&gt;386.46739&lt;/td&gt;
&lt;td align="right"&gt;226.71711&lt;/td&gt;
&lt;td align="right"&gt;140.811881&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;35 - 49 ans&lt;/td&gt;
&lt;td align="right"&gt;235&lt;/td&gt;
&lt;td align="right"&gt;147.71429&lt;/td&gt;
&lt;td align="right"&gt;78.33333&lt;/td&gt;
&lt;td align="right"&gt;38.670886&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;50 ans ou +&lt;/td&gt;
&lt;td align="right"&gt;110&lt;/td&gt;
&lt;td align="right"&gt;56.52778&lt;/td&gt;
&lt;td align="right"&gt;26.40000&lt;/td&gt;
&lt;td align="right"&gt;8.461538&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;Si l'utilisation d'across ne vous semble pas claire, je ne saurais trop vous recommander &lt;a href="https://blog.statoscop.fr/fonctionnement-et-performances-dacross-dans-dplyr.html"&gt;notre précédent article de blog&lt;/a&gt; sur ce verbe bien pratique de dplyr.  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;On obtient finalement nos taux de survie standardisés en sommant les effectifs par tranche d'âge et en divisant par l'effectif total :  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;eff_survie_age_class&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nf"&gt;summarise&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;across&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;starts_with&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;survie_&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;~&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;.&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;eff&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;knitr&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="nf"&gt;kable&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="right"&gt;survie_1&lt;/th&gt;
&lt;th align="right"&gt;survie_2&lt;/th&gt;
&lt;th align="right"&gt;survie_3&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="right"&gt;0.692329&lt;/td&gt;
&lt;td align="right"&gt;0.446256&lt;/td&gt;
&lt;td align="right"&gt;0.2338477&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Par rapport aux taux de survie bruts présentés plus haut, on constate que &lt;strong&gt;les inégalités économiques de survie s'aggravent après avoir contrôlé par l'âge&lt;/strong&gt;. Le taux de survie standardisés de la classe 1 et de la classe 3 sont en effet de 69,2% et 23,4 % contre 63,7% et 26,1% avant la correction. Cela correspond à ce que l'on pouvait pressentir après l'analyse exploratoire puisque les passagers de la classe 3 sont plus jeunes et que les jeunes ont une meilleure chance de survie au sein de chaque classe économique.   &lt;/p&gt;
&lt;h1 id="pour-conclure"&gt;Pour conclure&lt;/h1&gt;
&lt;p&gt;J'espère que cet exemple vous aura permis de mieux appréhender la question de la standardisation directe. Bien sûr, la méthode utilisée ici comporte des limites, notamment l'utilisation de tranches d'âge très larges qui pourraient fausser le résultat. On peut par exemple penser que les enfants en bas âge ont bénéficié d'une attention toute particulière, et ils se retrouvent ici dans la même tranche d'âge que des adolescents. Mais nous sommes également contraints par les effectifs qui nous empêchent de faire une analyse trop fine de ces subtilités. Si ces questions vous intéressent, vous pouvez vous reporter à notre article sur &lt;a href="https://blog.statoscop.fr/le-dilemme-biais-variance-dans-la-modelisation-de-donnees.html"&gt;le dilemme biais-variance&lt;/a&gt;.   &lt;/p&gt;
&lt;p&gt;Enfin, nous avons passé sous silence une variable explicative très importante : le sexe des passagers. Les taux de survie sont en effet très différents pour les hommes et pour les femmes. Il est possible de reproduire cette analyse en prenant en compte cette variable, croisée également avec l'âge. Cependant, toujours en raison de trop faibles effectifs, il sera sans doute nécessaire d'agréger encore plus les tranches d'âge. Vous avez les cartes en main pour le faire, et mieux comprendre les fortunes diverses de Jack et Rose dans le célèbre film de la tragédie...  &lt;/p&gt;
&lt;p&gt;C'est la fin de cet article! N'hésitez pas à &lt;a href="https://www.statoscop.fr"&gt;visiter notre site&lt;/a&gt; et à nous suivre sur &lt;a href="https://twitter.com/stato_scop"&gt;Twitter&lt;/a&gt; et &lt;a href="https://www.linkedin.com/company/statoscop"&gt;Linkedin&lt;/a&gt;. Pour retrouver l'ensemble du code ayant servi à générer cette note, vous pouvez vous rendre sur le &lt;a href="https://github.com/Statoscop/notebooks-blog"&gt;github de Statoscop&lt;/a&gt;.  &lt;/p&gt;</content><category term="R"></category><category term="R"></category><category term="Rstats"></category><category term="data science"></category><category term="statistiques"></category></entry><entry><title>Risques relatifs et odds-ratios : comment les interpréter et les comparer?</title><link href="https://blog.statoscop.fr/risques-relatifs-et-odds-ratios-comment-les-interpreter-et-les-comparer.html" rel="alternate"></link><published>2022-03-04T00:00:00+01:00</published><updated>2022-03-04T00:00:00+01:00</updated><author><name>Antoine</name></author><id>tag:blog.statoscop.fr,2022-03-04:/risques-relatifs-et-odds-ratios-comment-les-interpreter-et-les-comparer.html</id><summary type="html">&lt;p&gt;Petite présentation des OR et des RR, et ce qu'ils veulent dire.&lt;/p&gt;</summary><content type="html">&lt;div class="toc"&gt;&lt;span class="toctitle"&gt;Table des matières&lt;/span&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#probabilites-et-cotes"&gt;Probabilités et cotes&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#definitions"&gt;Définitions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#lien-entre-cote-et-probabilite"&gt;Lien entre cote et probabilité&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#risques-relatifs-et-odds-ratios"&gt;Risques relatifs et odds ratios&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#interpretations"&gt;Interprétations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#comment-choisir-lindicateur-adapte"&gt;Comment choisir l'indicateur adapté&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#conclusion"&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;Dans cet article, on s'intéresse à la relation entre probabilités et cotes et aux implications concernant deux indicateurs souvent utilisés pour comparer le risque d'un évènement entre différents groupes d'individus : les risques relatifs (RR) et les odds ratios (OR). &lt;/p&gt;
&lt;h1 id="probabilites-et-cotes"&gt;Probabilités et cotes&lt;/h1&gt;
&lt;h2 id="definitions"&gt;Définitions&lt;/h2&gt;
&lt;p&gt;La &lt;strong&gt;probabilité&lt;/strong&gt; correspond à la vraisemblance d'un évènement. Elle est comprise entre 0 (évènement impossible) et 1 (évènement certain). On peut estimer une probabilité d'un évènement à partir de sa &lt;strong&gt;fréquence&lt;/strong&gt;, au sens du rapport entre &lt;strong&gt;le nombre de fois où cet évènement est observé&lt;/strong&gt; et le &lt;strong&gt;nombre d'observations total&lt;/strong&gt; dont on dispose. En épidémiologie, on parle aussi de &lt;strong&gt;prévalence&lt;/strong&gt;. Ainsi, si l'on constate par exemple à un instant T que pour 100 personnes 20 sont atteintes d'une maladie, on en concluera que le &lt;strong&gt;taux de prévalence de cette maladie&lt;/strong&gt; est de 20%. On peut aussi en déduire que la probabilité qu'un individu tiré au hasard ait cette maladie est de 20%.&lt;br&gt;
La &lt;strong&gt;cote&lt;/strong&gt; d'un évènement est le rapport entre &lt;strong&gt;le nombre de fois où cet évènement est observé&lt;/strong&gt; et le &lt;strong&gt;le nombre de fois où cet évènement n'est pas observé&lt;/strong&gt;. Pour notre maladie dont le taux de prévalence est de 20%, la cote est donc 20/80, car sur 100 personnes 20 ont la maladie et 80 ne l'ont pas. Notre cote est ainsi de 0,25. Si &lt;strong&gt;le taux de prévalence avait été de 50%, la cote aurait été de 1&lt;/strong&gt; (50/50) : c'est la valeur de la cote qui définit un évènement qui a autant de chances de se produire que de ne pas se produire. Si le taux de prévalence avait été de 1, la cote aurait été de... l'infini (100/0). Les cotes vont ainsi de 0 à l'infini. &lt;/p&gt;
&lt;h2 id="lien-entre-cote-et-probabilite"&gt;Lien entre cote et probabilité&lt;/h2&gt;
&lt;p&gt;Les valeurs des cotes de &lt;strong&gt;0 à 1&lt;/strong&gt; correspondent aux &lt;strong&gt;évènements qui ont moins de chances d'arriver que de ne pas arriver&lt;/strong&gt; et ceux de &lt;strong&gt;1 à l'infini&lt;/strong&gt; aux &lt;strong&gt;évènements qui ont plus de chances d'arriver que de ne pas arriver&lt;/strong&gt;. &lt;br&gt;
On peut représenter le lien entre une probabilité et sa cote, en n'oubliant pas de passer l'axe représentant la cote en &lt;strong&gt;échelle logarithmique&lt;/strong&gt;. En effet, c'est ici cette échelle qui va permettre de rendre compte visuellement de la symétrie des valeurs entre 0 et 1 et de celles entre 1 et l'infini :  &lt;/p&gt;
&lt;p&gt;&lt;img alt="Pelican" src="../images/or_rr/unnamed-chunk-1-1.png"&gt;&lt;/p&gt;
&lt;p&gt;Ainsi, une cote de 0,5 correspond à &lt;strong&gt;deux fois moins de chances&lt;/strong&gt; que l'évènement arrive plutôt qu'il n'arrive pas et une cote de 2 correspond à &lt;strong&gt;deux fois plus de chances&lt;/strong&gt; que l'évènement arrive plutôt qu'il n'arrive pas. C'est le même raisonnement pour 0,1 et 10 (10 fois plus ou moins de chances), pour 0,01 et 100 (100 fois plus ou  moins de chance), etc...  &lt;/p&gt;
&lt;p&gt;Les cotes se déduisent donc directement des probabilités. Mais lorsque l'on compare plusieurs populations, le choix de l'un ou l'autre des indicateurs va avoir une influence sur le résultat obtenu.    &lt;/p&gt;
&lt;h1 id="risques-relatifs-et-odds-ratios"&gt;Risques relatifs et odds ratios&lt;/h1&gt;
&lt;h2 id="interpretations"&gt;Interprétations&lt;/h2&gt;
&lt;p&gt;Les risques relatifs (RR) et les odds ratios (OR) sont utilisés pour &lt;strong&gt;comparer le risque d'un évènement entre plusieurs populations&lt;/strong&gt;. Reprenons notre exemple de la maladie dont la prévalence est de 20% dans la population. Imaginons qu'on observe en fait que cette prévalence varie fortement selon le sexe, et qu'elle est de 10% chez les hommes et de 30% chez les femmes.&lt;br&gt;
Le risque relatif pour une femme par rapport à un homme est &lt;strong&gt;le rapport de la probabilité pour une femme d'avoir cette maladie sur celle pour un homme&lt;/strong&gt;. Dans notre cas, ce risque relatif est donc de 3 (30%/10%). On interprète ce résultat comme le fait que les femmes ont 3 fois plus de chances d'avoir cette maladie que les hommes.&lt;br&gt;
L'odds ratio est &lt;strong&gt;le rapport de la cote de cette maladie pour une femme sur celle pour un homme&lt;/strong&gt;. La cote d'une femme est de 30/70, soit environ 0,43. Celle d'un homme est de 0,1/0,9, soit environ 0,11. Le rapport de ces cotes est donc de 3,9. Il est sensiblement différent du risque relatif et ne s'interprète pas aussi aisément. En effet, on ne peut pas ici affirmer que près de 4 fois plus de femmes ont cette maladie que les hommes, mais que la cote d'une femme est 4 fois plus élevée que celle d'un homme.  &lt;/p&gt;
&lt;h2 id="comment-choisir-lindicateur-adapte"&gt;Comment choisir l'indicateur adapté&lt;/h2&gt;
&lt;p&gt;Le débat entre risques relatifs et odds-ratios vient souvent du fait que lorsque l'on veut faire un modèle qui contrôle par plusieurs facteurs de risque (par exemple sexe, âge, classe sociale, type d'habitation...) on va le plus souvent se tourner vers la régression logistique. Or ce modèle permet d'obtenir facilement les odds-ratio associés à ces différents facteurs de risque. Bien sûr, on peut déduire d'un odds ratio le risque relatif si on connaît la prévalence de la variable d'intérêt que l'on étudie, mais il devient compliqué d'opérer cette transformation lorsque l'on contrôle par plusieurs variables.&lt;br&gt;
Les risques relatifs sont souvent considérés à raison comme plus intuitifs et faciles à présenter. Ils ont cependant l'inconvénient de &lt;strong&gt;ne pas prendre en compte du tout le niveau de risque de base lorsqu'ils comparent deux populations&lt;/strong&gt;. Ainsi, qu'une probabilité passe de 0,5% à 1%, de 25% à 50% ou de 40% à 80% entre deux groupes, le risque relatif sera toujours égal à 2 (ou 0,5 selon le groupe de référence). Les OR seront bien égaux à 2 dans le premier cas, mais à 3 dans le second et à 6 dans le dernier. &lt;strong&gt;Plus la prévalence de l'évènement qu'on observe est faible dans la population, plus les OR sont semblables aux RR&lt;/strong&gt;.&lt;br&gt;
Le débat même sur l'interprétabilité des RR et des OR n'est pas évident. Considérons un groupe A qui a une prévalence d'une maladie de 50% et un groupe B avec une prévalence de 100%. Est-il plus juste de dire qu'appartenir au groupe B multiplie son risque relatif d'avoir la maladie par 2 par rapport au groupe A comme nous le renseigne le RR ou par l'infini, comme le prétend l'OR? Dans cet exemple, l'OR a l'avantage de capter une situation "extrême" où personne n'échapperait à la maladie. Au niveau individuel, le &lt;em&gt;risque&lt;/em&gt; semble en effet infiniment de fois plus important dans le groupe B puisque l'évènement est...certain.&lt;/p&gt;
&lt;h1 id="conclusion"&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;Contrairement au risque relatif, les OR ne donnent pas les mêmes résultats en fonction de la prévalence initiale de l'évènement qu'ils décrivent. Cela peut être un inconvénient quand il est interprété à tort comme un risque relatif, comme c'est souvent le cas. Mais il permet aussi de décrire plus justement le risque relatif de l'évènement &lt;strong&gt;par rapport au non-évènement&lt;/strong&gt;, et en ce sens ajoute de l'information. Le RR permet lui de mieux rendre compte des différences de fréquence d'un évènement entre plusieurs populations.&lt;br&gt;
Quelque soit l'indicateur choisi, il est important de &lt;strong&gt;ne pas présenter seulement les OR ou les RR mais aussi la prévalence, ou la fréquence de l'évènement&lt;/strong&gt;, même non contrôlée de tous les facteurs de risque. Cela permet au moins d'identifier si les OR ont de grandes chances ou non de différer fortement des RR. Ensuite, c'est à vous de choisir quel indicateur correspond le mieux au type de résultats que vous voulez présenter.  &lt;br&gt;
C'est tout pour aujourd'hui! N'hésitez pas à &lt;a href="https://www.statoscop.fr"&gt;visiter notre site&lt;/a&gt; et à nous suivre sur &lt;a href="https://twitter.com/stato_scop"&gt;Twitter&lt;/a&gt; et &lt;a href="https://www.linkedin.com/company/statoscop"&gt;Linkedin&lt;/a&gt;. Pour retrouver le code ayant servi à générer cette note, vous pouvez vous rendre sur le &lt;a href="https://github.com/Statoscop/notebooks-blog"&gt;github de Statoscop&lt;/a&gt;.  &lt;/p&gt;</content><category term="Stats &amp; ML"></category><category term="statistiques"></category><category term="odds-ratio"></category><category term="OR"></category><category term="probabilités"></category></entry><entry><title>Le dilemme biais variance dans la modélisation de données</title><link href="https://blog.statoscop.fr/le-dilemme-biais-variance-dans-la-modelisation-de-donnees.html" rel="alternate"></link><published>2021-11-08T00:00:00+01:00</published><updated>2021-11-08T00:00:00+01:00</updated><author><name>Antoine</name></author><id>tag:blog.statoscop.fr,2021-11-08:/le-dilemme-biais-variance-dans-la-modelisation-de-donnees.html</id><summary type="html">&lt;p&gt;Présentation des enjeux théoriques et pratiques de l'arbitrage biais variance dans la construction d'un modèle de prédiction.&lt;/p&gt;</summary><content type="html">&lt;div class="toc"&gt;&lt;span class="toctitle"&gt;Table des matières&lt;/span&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#que-sont-le-biais-et-la-variance"&gt;Que sont le biais et la variance?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#enjeux-de-larbitrage-biais-variance"&gt;Enjeux de l'arbitrage biais variance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#liens-avec-loverfitting-et-lunderfitting-dans-les-modeles-de-machine-learning"&gt;Liens avec l'overfitting et l'underfitting dans les modèles de Machine Learning&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#appelons-un-chat-un-chat"&gt;Appelons un chat un chat&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#courbe-dapprentissage-dun-modele"&gt;Courbe d'apprentissage d'un modèle&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#conclusion"&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;L'arbitrage biais variance est souvent évoqué pour caractériser les enjeux de la construction d'un modèle de prédiction performant. L'idée de cet article est d'essayer de donner au lecteur les outils théoriques de cette question en essayant de privilégier une approche intuitive et pratique du problème. Après avoir défini ce que sont le biais et la variance, on présente les enjeux de cet arbitrage puis l'application concrète dans le cas de l'entraînement d'un modèle de Machine Learning.&lt;/p&gt;
&lt;h1 id="que-sont-le-biais-et-la-variance"&gt;Que sont le biais et la variance?&lt;/h1&gt;
&lt;p&gt;Pour expliquer le plus simplement possible ces concepts, on se place dans le contexte de l'observation de deux variables &lt;code&gt;Y&lt;/code&gt; et &lt;code&gt;X&lt;/code&gt;. Dans le cas d'une modélisation d'une relation entre &lt;code&gt;X&lt;/code&gt; et &lt;code&gt;Y&lt;/code&gt;, le biais d'un estimateur est son écart avec sa "vraie" valeur si on observait parfaitement la relation entre ces variables. On entend donc le biais comme &lt;strong&gt;l'écart entre la fonction modélisée et la fonction théorique&lt;/strong&gt; qui permettrait de restituer le lien entre &lt;code&gt;X&lt;/code&gt; et &lt;code&gt;Y&lt;/code&gt;. &lt;/p&gt;
&lt;p&gt;Une manière de jouer sur le biais d'un modèle c'est de modifier sa variance. La variance est une mesure de dispersion de valeurs, qui donne une estimation de l'écart de celles-ci à leur moyenne. La variance d'un modèle estime &lt;strong&gt;à quel point celui-ci fluctue autour de sa moyenne pour coller aux données&lt;/strong&gt;. Une mesure utilisée couramment dans le cas des régressions linéaires est le coefficient de détermination R2. Celui-ci calcule &lt;strong&gt;la part de la variance des données expliquée par la variance du modèle&lt;/strong&gt;. Autrement dit, plus mon modèle sera proche des points de mes données, plus sa variance et donc le R2 seront élevés. Pour illustrer ce concept, on présente plusieurs modèles appliqués au même jeu de données avec une variance plus ou moins élevée :&lt;/p&gt;
&lt;p&gt;&lt;img alt="Pelican" src="../images/biais_variance/unnamed-chunk-1-1.png"&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Pour chaque modèle, la courbe du modèle est celle qui apparaît en rouge et on a mis en évidence en vert la projection de chaque point sur sa valeur prédite par le modèle. Voyons comment interpréter ces graphiques :  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Le premier modèle est un modèle naïf qui se contente de prédire que pour chaque valeur de &lt;code&gt;X&lt;/code&gt;, &lt;code&gt;Y&lt;/code&gt; sera égale à sa moyenne. Par définition donc, sa variance est nulle et sa capacité prédictive faible.  &lt;/li&gt;
&lt;li&gt;Le second modèle est une régression linéaire simple qui a un R2 d'environ 50%. Il a donc une meilleure qualité prédictive que le premier modèle du fait qu'il capte une partie de la variance des données, ici à travers une corrélation positive entre &lt;code&gt;X&lt;/code&gt; et &lt;code&gt;Y&lt;/code&gt;.  &lt;/li&gt;
&lt;li&gt;Le troisième modèle est un modèle polynomial dont on voit qu'il est plus ajusté que le second. Les points prédits (en vert) par la courbe sont en effet plus proche des points que pour le précédent modèle et mécaniquement cela fait augmenter le R2. Le fait d'utiliser un modèle polynomial a donné au modèle une plus grande souplesse ce qui lui a permis de se rapprocher de certains points extrêmes qui étaient éloignés de la droite de régression du second modèle.  &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ainsi, plus la variance augmente, plus le modèle prédit en moyenne des valeurs proches de leurs vraies valeurs, ce qui fait diminuer le biais, puisqu'il est défini comme l'écart entre notre fonction de prédiction et une fonction qui permettrait de prédire parfaitement les données observées.  &lt;/p&gt;
&lt;h1 id="enjeux-de-larbitrage-biais-variance"&gt;Enjeux de l'arbitrage biais variance&lt;/h1&gt;
&lt;p&gt;D'après ce qu'on a vu, pourquoi alors ne pas simplement chercher à maximiser la variance pour minimiser le biais, c'est-à-dire son écart aux vraies valeurs? Tout simplement parce que dans le cas de la construction d'un modèle de prédiction, nous modélisons des relations entre des données à partir d'un échantillon pour prédire un résultat sur une nouvelle population. C'est donc la performance de ce modèle sur de nouvelles données qui va nous intéresser. Or, comme vous avez pu le pressentir en observant les graphiques précédents, &lt;strong&gt;un modèle avec une variance très élevée se généralise mal à de nouvelles données&lt;/strong&gt;. D'un autre côté, &lt;strong&gt;un modèle avec une faible variance aura lui aussi une qualité prédictive très faible&lt;/strong&gt; car il captera mal une éventuelle relation entre les variables.&lt;/p&gt;
&lt;p&gt;Tout le problème de cet arbitrage (ou dilemme) biais variance est donc de &lt;strong&gt;trouver un modèle qui ait une variance suffisamment forte pour limiter le biais mais suffisamment faible pour qu'il soit généralisable&lt;/strong&gt;. Les modèles précédents avaient été entraînés sur une base de données qui était un échantillon aléatoire correspondant à 10% des données d'un échantillon plus important. Pour mesurer la qualité prédictive de ces modèles on les applique donc aux données entières et on calcule l'écart moyen au carré de la prédiction à la vraie valeur, c'est-à-dire l'erreur quadratique moyenne ou en anglais &lt;strong&gt;MSE&lt;/strong&gt; pour &lt;em&gt;Mean Squared Error&lt;/em&gt; :&lt;/p&gt;
&lt;p&gt;&lt;img alt="Pelican" src="../images/biais_variance/unnamed-chunk-2-1.png"&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;On constate que, comme attendu, le modèle avec le plus de variance se généralise mal à des données non connues et présente une erreur de prédiction supérieure à celle du modèle linéaire simple. En effet, les variations de la courbe polynomiale qui lui permettait de coller au plus près des données sur lesquelles elle a été construite entraîne beaucoup de prédictions très éloignées de la vraie valeur des nouvelles données.&lt;br&gt;
L'erreur attendue d'un modèle de prédiction sur des données sur lesquelles il ne s'est pas entraîné peut en effet se décomposer en &lt;strong&gt;la somme du biais au carré et de la variance de ce modèle, c'est la décomposition biais-variance de l'erreur quadratique&lt;/strong&gt;. Si vous préférez vous en convaincre avec la formule et la démonstration mathématique, vous pouvez vous référer à &lt;a href="https://fr.wikipedia.org/wiki/Dilemme_biais-variance#Décomposition_biais-variance_de_l'erreur_quadratique"&gt;la page wikipédia qui en parle&lt;/a&gt;. Comme le biais diminue avec la variance, il faut donc trouver un niveau de complexité du modèle qui permette à la fois de minimiser l'écart à la vraie valeur (faible biais en augmentant la variance) et d'être généralisable en dehors de son échantillon d'entraînement (faible variance).&lt;/p&gt;
&lt;h1 id="liens-avec-loverfitting-et-lunderfitting-dans-les-modeles-de-machine-learning"&gt;Liens avec l'overfitting et l'underfitting dans les modèles de Machine Learning&lt;/h1&gt;
&lt;h2 id="appelons-un-chat-un-chat"&gt;Appelons un chat un chat&lt;/h2&gt;
&lt;p&gt;Le principe de l'apprentissage automatique supervisé est le même que celui qu'on a présenté jusqu'à maintenant : on renseigne au modèle des variables explicatives (&lt;code&gt;X&lt;/code&gt;) et une variable d'intérêt (&lt;code&gt;Y&lt;/code&gt;) qu'on aimerait pouvoir ensuite prédire à partir de nouvelles données &lt;code&gt;X&lt;/code&gt;. Par exemple, on renseigne des photos de chats et de chiens étiquettées : &lt;code&gt;Y&lt;/code&gt; est alors le label "chien" ou "chat" de la photo, &lt;code&gt;X&lt;/code&gt; la matrice de pixels de la photo. Le modèle devra être ensuite capable de prédire à partir d'une photo qu'il n'a jamais vue si celle-ci représente un chat ou un chien. Pour mesurer la qualité prédictive de notre modèle, on réserve des données labellisées sur lesquelles il ne s'entraînera pas. On va ensuite lui demander de prédire les labels déjà connus de ces données, ce qui va nous permettre d'évaluer la qualité de ces prédictions. Cet échantillon est en général appelé &lt;strong&gt;échantillon test&lt;/strong&gt; (&lt;em&gt;test set&lt;/em&gt; en anglais), et les données sur lesquelles le modèle est entraîné s'appelle l'&lt;strong&gt;échantillon d'entraînement&lt;/strong&gt; (&lt;em&gt;train set&lt;/em&gt;). En général, si l'on dispose de suffisamment de données, on n'aura pas trop de mal à construire un modèle qui parviendra à labelliser quasiment parfaitement &lt;strong&gt;nos données d'entraînement&lt;/strong&gt;. Tout le problème est d'avoir un modèle qui se généralise correctement à de nouvelles données.&lt;/p&gt;
&lt;h2 id="courbe-dapprentissage-dun-modele"&gt;Courbe d'apprentissage d'un modèle&lt;/h2&gt;
&lt;p&gt;Pour schématiser, imaginons que dans les données d'entraînement les chiens soient en général photographiées à l'extérieur et les chats à l'intérieur. Si mon modèle a une forte variance, cela signifie qu'il va prendre en compte beaucoup de détails de la photo. Il va par exemple donner du poids aux éléments de fond dans sa prédiction et sera incapable de labelliser correctement un chien photographié à l'intérieur. Un modèle bien plus basique qui se serait appuyé par exemple uniquement sur la forme des oreilles de l'animal aurait peut-être de meilleurs résultats.&lt;br&gt;
Dans le premier cas, on dit que l'on est dans une situation de &lt;strong&gt;surapprentissage, ou overfitting&lt;/strong&gt;. Le modèle a intégré des éléments anecdotiques, du bruit, dans son processus décisionnel et cela va réduire sa performance prédictive sur des données non connues. Autrement dit, &lt;strong&gt;sa variance est trop élevée&lt;/strong&gt;. Si au contraire le modèle est trop peu complexe et n'a pas intégré assez d'informations pour différencier un chat d'un chien même sur les données d'apprentissage, on dit qu'il est dans un état de &lt;strong&gt;sous-apprentissage, ou underfitting&lt;/strong&gt;.&lt;br&gt;
&lt;strong&gt;Dans les deux cas, le modèle va avoir de mauvaises performances prédictives sur des nouvelles données&lt;/strong&gt;. Ce constat peut être schématisé de la manière suivante :&lt;/p&gt;
&lt;p&gt;&lt;img alt="Pelican" src="../images/biais_variance/courb_apprent.png"&gt;  &lt;/p&gt;
&lt;p&gt;Notons bien ici que cette relation entre complexité du modèle et décomposition de l'erreur de prédiction s'entend &lt;strong&gt;à taille d'échantillon fixée&lt;/strong&gt;. Ainsi, plus l'échantillon sera grand, plus le modèle pourra être complexe avant d'entrer dans la phase de surapprentissage.  &lt;/p&gt;
&lt;h1 id="conclusion"&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;Dans le cadre d'une &lt;strong&gt;démarche prédictive&lt;/strong&gt;, il est donc tout à fait naturel de limiter l'apprentissage du modèle pour optimiser ses capacités prédictives. Cela peut être fait en réduisant le nombre de variables prédictives utilisées, en limitant le nombre de couches de neurones dans un réseau, mais aussi en utilisant des méthodes de réduction des dimensions, comme &lt;a href="https://blog.statoscop.fr/acp-python.html"&gt;nous vous l'avions montré avec l'analyse en composantes principales&lt;/a&gt;. Bien sûr, dans une &lt;strong&gt;démarche explicative&lt;/strong&gt;, il sera au contraire normal de sacrifier éventuellement une meilleure capacité prédictive pour mettre en évidence une relation avec une variable explicative. Si vous souhaitez aller plus loin, vous pouvez parcourir l'excellente étude de &lt;a href="https://www.stat.berkeley.edu/~aldous/157/Papers/shmueli.pdf"&gt;Shmueli, 2010&lt;/a&gt; qui expose les enjeux croisés des démarches explicative et prédictive dans la modélisation.&lt;br&gt;
Il me reste à remercier &lt;a href="https://twitter.com/EParoissien"&gt;Emmanuel Paroissien&lt;/a&gt;, chercheur à l'Inra, pour nos échanges qui m'ont aidé à construire cette note. N'hésitez pas à &lt;a href="https://www.statoscop.fr"&gt;visiter notre site&lt;/a&gt; et à nous suivre sur &lt;a href="https://twitter.com/stato_scop"&gt;Twitter&lt;/a&gt; et &lt;a href="https://www.linkedin.com/company/statoscop"&gt;Linkedin&lt;/a&gt;. Pour retrouver le code ayant servi à générer cette note, vous pouvez vous rendre sur le &lt;a href="https://github.com/Statoscop/notebooks-blog"&gt;dépôt github de nos notes de blog&lt;/a&gt;.  &lt;/p&gt;</content><category term="R"></category><category term="R"></category><category term="Rstats"></category><category term="data science"></category><category term="statistiques"></category><category term="Machine Learning"></category></entry><entry><title>Analyse en composantes principales avec Python</title><link href="https://blog.statoscop.fr/acp-python.html" rel="alternate"></link><published>2021-04-16T00:00:00+02:00</published><updated>2021-04-16T00:00:00+02:00</updated><author><name>Antoine</name></author><id>tag:blog.statoscop.fr,2021-04-16:/acp-python.html</id><summary type="html">&lt;p&gt;Présentation et exemples d'utilisation de l'ACP en statistiques et data science.&lt;/p&gt;</summary><content type="html">&lt;div class="toc"&gt;&lt;span class="toctitle"&gt;Table des matières&lt;/span&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#explication-introductive"&gt;Explication introductive&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#mise-en-oeuvre-dune-acp"&gt;Mise en oeuvre d'une ACP&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#analyse-exploratoire-de-nos-donnees"&gt;Analyse exploratoire de nos données&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#utilisation-de-lacp-pour-la-reduction-de-dimensions"&gt;Utilisation de l'ACP pour la réduction de dimensions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;Dans cet article, nous allons essayer de comprendre intuitivement comment fonctionne l'analyse en composantes principales. Nous présenterons ensuite à quoi celle-ci peut servir en prenant les exemples d'une analyse exploratoire des données et d'une problématique de réduction de dimension.   &lt;/p&gt;
&lt;h1 id="explication-introductive"&gt;Explication introductive&lt;/h1&gt;
&lt;p&gt;L'analyse en composantes principales est une méthode consistant à transformer des variables corrélées entre elles en nouvelles variables. Chacune de ces nouvelles variables est le résultat d'une combinaison linéaire des anciennes variables. &lt;/p&gt;
&lt;p&gt;&lt;em&gt;Note : une combinaison linéaire de 3 variables &lt;span class="math"&gt;\(V_1\)&lt;/span&gt;, &lt;span class="math"&gt;\(V_2\)&lt;/span&gt; et &lt;span class="math"&gt;\(V_3\)&lt;/span&gt; s'écrit &lt;span class="math"&gt;\(\alpha_1.V_1 + \alpha_2.V_2 + \alpha_3.V_3\)&lt;/span&gt; où les &lt;span class="math"&gt;\(\alpha_i\)&lt;/span&gt; sont des coefficients réels.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Ces nouvelles variables sont appelées &lt;strong&gt;composantes principales&lt;/strong&gt; et sont, par contruction, décorrélées les unes des autres.  &lt;/p&gt;
&lt;p&gt;Autrement dit, l'ACP projette vos données dans un nouvel espace. La première composante principale est construite de manière à capter la plus grande variance possible de vos données, la seconde la part la plus importante de la variance possible &lt;strong&gt;restant à expliquer&lt;/strong&gt;, et ainsi de suite.  &lt;/p&gt;
&lt;p&gt;Une illustration brillante de ce processus est proposée par &lt;a href="https://www.allisonhorst.com/" target="_blank"&gt;Allison Horst&lt;/a&gt;. Elle &lt;a href="https://twitter.com/allison_horst/status/1288904459490213888" target="_blank"&gt;représente&lt;/a&gt; un jeu de données à deux dimensions avec des crevettes et l'analyse en composantes principales comme les passages d'un requin-baleine affamé :  &lt;/p&gt;
&lt;p&gt;&lt;img alt="Pelican" src="../images/acp/output_3_0.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="Pelican" src="../images/acp/output_4_0.png"&gt;&lt;/p&gt;
&lt;p&gt;La problématique du requin-baleine est en effet la même que celle de la création d'une première composante principale : quel axe choisir pour avaler un maximum de crevettes dès le premier passage? L'axe choisi va ressembler à celui-ci :  &lt;/p&gt;
&lt;p&gt;&lt;img alt="Pelican" src="../images/acp/output_6_0.png"&gt;&lt;/p&gt;
&lt;p&gt;Il s'agit pour le requin de choisir la droite de sorte qu'il y ait un maximum de crevettes sur son parcours ce qui revient à ce que les crevettes soient le plus proche possible de cette droite. Mathématiquement, la première composante principale est la combinaison linéaire des deux axes &lt;span class="math"&gt;\(x\)&lt;/span&gt; et &lt;span class="math"&gt;\(y\)&lt;/span&gt; qui maximise l'inertie projetée ce qui revient à minimiser les écarts entre les points et cette droite.&lt;/p&gt;
&lt;p&gt;Dans cet exemple, la seconde composante principale sera l'axe perpendiculaire à ce premier axe.&lt;/p&gt;
&lt;p&gt;Si les points étaient parfaitement alignés sur une ligne, l'ensemble de la variance serait expliqué par la première composante et on serait parvenus à réduire le nombre de dimensions de notre problème sans perte d'information.&lt;/p&gt;
&lt;h1 id="mise-en-oeuvre-dune-acp"&gt;Mise en oeuvre d'une ACP&lt;/h1&gt;
&lt;p&gt;D'accord, on a projeté notre jeu de données dans un nouvel espace avec des nouvelles "variables" décrites comme combinaisons linéaires des précédentes telles que la première explique la plus grande partie de la variance possible, la seconde la plus grande partie de la variance restant à expliquer, etc... Mais ça nous sert à quoi?   &lt;/p&gt;
&lt;h2 id="analyse-exploratoire-de-nos-donnees"&gt;Analyse exploratoire de nos données&lt;/h2&gt;
&lt;p&gt;La caractéristique des composantes principales par rapport au jeu de données non transformé est que les premières composantes principales ont un fort pouvoir discriminant, puisqu'elles expliquent une grande partie de la variance totale du jeu de données. Ainsi, représenter notre jeu de données par rapport aux deux premiers axes de l'ACP peut permettre de vérifier que ces données permettent bien de distinguer différentes classes.  &lt;/p&gt;
&lt;p&gt;Prenons comme exemple la base de données &lt;code&gt;wine&lt;/code&gt; que l'on peut charger directement depuis le module &lt;code&gt;sklearn&lt;/code&gt;. Cette base de données contient des résultats d'analyses chimiques de 178 vins de 3 différents producteurs. Ces résultats sont synthétisés par 13 mesures différentes que l'on retrouve dans les données. Pour voir si ces mesures permettent ou non de distinguer les vins des trois producteurs, nous allons commencer par représenter les vins sur l'espace des deux premières composantes principales. Pour cela, on importe les données et on les centre-réduit avant d'appliquer notre ACP avec la fonction &lt;code&gt;sklearn.decomposition.PCA&lt;/code&gt;. On paramètre celle-ci pour qu'elle nous renvoie seulement les deux premières composantes :  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="c1"&gt;# Import fonction ACP&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.decomposition&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;PCA&lt;/span&gt;

&lt;span class="c1"&gt;# Import données&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.datasets&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;load_wine&lt;/span&gt;

&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;target&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;load_wine&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;return_X_y&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;target_names&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;load_wine&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;target_names&lt;/span&gt;
&lt;span class="n"&gt;feature_names&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;load_wine&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;feature_names&lt;/span&gt;
&lt;span class="c1"&gt;# on standardise nos données : &lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.preprocessing&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;StandardScaler&lt;/span&gt;
&lt;span class="n"&gt;values_cr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;StandardScaler&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# On paramètre notre PCA pour garder les deux premières composantes&lt;/span&gt;
&lt;span class="n"&gt;pca&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;PCA&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;pca_wine&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pca&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;values_cr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# en sortie : le même nombre de lignes que les données en entrées&lt;/span&gt;
&lt;span class="c1"&gt;# et le nombre de variables correspondant au nombre de composantes&lt;/span&gt;
&lt;span class="c1"&gt;# conservées&lt;/span&gt;
&lt;span class="n"&gt;pca_wine&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;(178, 2)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;En sortie, nous obtenons les vecteurs des deux premières composantes dans l'objet &lt;code&gt;pca_wine&lt;/code&gt;. Notons que nous aurions pu paramétrer la fonction &lt;code&gt;PCA&lt;/code&gt; de manière à ce qu'elle nous renvoie le nombre de composantes nécessaire à expliquer &lt;code&gt;X&lt;/code&gt;% de la variance, comme nous le ferons par la suite. Depuis l'objet &lt;code&gt;pca&lt;/code&gt;, on peut voir le vecteur de la variance expliquée par chaque composante avec &lt;code&gt;pca.explained_variance_ratio_&lt;/code&gt; et donc la variance totale expliquée par nos deux composantes en sommant les éléments de ce vecteur :  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;pca&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;explained_variance_ratio_&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="mf"&gt;0.554063383569353&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;On explique donc 55 % de la variance totale de nos données avec 2 composantes, alors que celle-ci contient 13 variables. Voyons si cela suffit à discriminer nos 3 producteurs visuellement :  &lt;/p&gt;
&lt;!--- ![Pelican](../images/acp/output_13_0.png)--&gt;
&lt;p&gt;&lt;img alt="Pelican" src="../images/acp/output_13_0.png" style="max-width:80% !important" &gt;&lt;/p&gt;
&lt;p&gt;On constate ici que les 3 producteurs sont bien répartis dans des zones distinctes du plan et ce résultat semble montrer que chacun produit des types de vin caractéristiques.&lt;/p&gt;
&lt;p&gt;On peut se convaincre que l'ACP a bien joué son rôle en produisant le même type de schéma avec deux autres variables originales du jeu de données (sans transformation linéaire), disons le degré d'alcool et l'intensité de la couleur. On s'attend bien sûr à ce que les classes soient moins discriminées qu'avec les deux premières composantes principales :  &lt;/p&gt;
&lt;p&gt;&lt;img alt="Pelican" src="../images/acp/output_15_0.png" style="max-width:80% !important" &gt;&lt;/p&gt;
&lt;p&gt;Ces variables permettent de distinguer des tendances, comme le fait que le producteur 1 produit des vins plutôt moins alcoolisés et dont la couleur est peu intense alors que le producteur 0 produit des vins plus alcoolisés. Mais ces variables seules ne permettent pas de partitionner nos classes aussi clairement qu'avec les deux premières composantes de notre ACP.   &lt;/p&gt;
&lt;p&gt;L'ACP ne permet certes pas au premier coup d'oeil de proposer une interprétation des résultats, mais il est néanmoins possible d'étudier comment chaque variable contribue aux composantes avec l'instruction &lt;code&gt;pca.components_&lt;/code&gt; :  &lt;/p&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Noms des variables&lt;/th&gt;
      &lt;th&gt;Composante 1&lt;/th&gt;
      &lt;th&gt;Composante 2&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;alcohol&lt;/td&gt;
      &lt;td&gt;0.144329&lt;/td&gt;
      &lt;td&gt;-0.483652&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;malic_acid&lt;/td&gt;
      &lt;td&gt;-0.245188&lt;/td&gt;
      &lt;td&gt;-0.224931&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;ash&lt;/td&gt;
      &lt;td&gt;-0.002051&lt;/td&gt;
      &lt;td&gt;-0.316069&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;alcalinity_of_ash&lt;/td&gt;
      &lt;td&gt;-0.239320&lt;/td&gt;
      &lt;td&gt;0.010591&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;magnesium&lt;/td&gt;
      &lt;td&gt;0.141992&lt;/td&gt;
      &lt;td&gt;-0.299634&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;td&gt;total_phenols&lt;/td&gt;
      &lt;td&gt;0.394661&lt;/td&gt;
      &lt;td&gt;-0.065040&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;6&lt;/th&gt;
      &lt;td&gt;flavanoids&lt;/td&gt;
      &lt;td&gt;0.422934&lt;/td&gt;
      &lt;td&gt;0.003360&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;7&lt;/th&gt;
      &lt;td&gt;nonflavanoid_phenols&lt;/td&gt;
      &lt;td&gt;-0.298533&lt;/td&gt;
      &lt;td&gt;-0.028779&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;8&lt;/th&gt;
      &lt;td&gt;proanthocyanins&lt;/td&gt;
      &lt;td&gt;0.313429&lt;/td&gt;
      &lt;td&gt;-0.039302&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;9&lt;/th&gt;
      &lt;td&gt;color_intensity&lt;/td&gt;
      &lt;td&gt;-0.088617&lt;/td&gt;
      &lt;td&gt;-0.529996&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;10&lt;/th&gt;
      &lt;td&gt;hue&lt;/td&gt;
      &lt;td&gt;0.296715&lt;/td&gt;
      &lt;td&gt;0.279235&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;11&lt;/th&gt;
      &lt;td&gt;od280/od315_of_diluted_wines&lt;/td&gt;
      &lt;td&gt;0.376167&lt;/td&gt;
      &lt;td&gt;0.164496&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;12&lt;/th&gt;
      &lt;td&gt;proline&lt;/td&gt;
      &lt;td&gt;0.286752&lt;/td&gt;
      &lt;td&gt;-0.364903&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Ce tableau représente les coefficients de la combinaison linéaire des variables pour chaque composante. Il nous permet par exemple de constater que l'intensité de la couleur et l'alcool jouent fortement et négativement sur la seconde composante. Cela correspond à ce que l'on observait dans les deux graphiques précédents puisque les vins des producteurs 0 et 2 ont des valeurs négatives sur l'axe de la seconde composante (1er graphique) et ce sont bien ceux dont le taux en alcool et l'intensité de la couleur sont les plus importants (2e graphique)&lt;/p&gt;
&lt;h2 id="utilisation-de-lacp-pour-la-reduction-de-dimensions"&gt;Utilisation de l'ACP pour la réduction de dimensions&lt;/h2&gt;
&lt;p&gt;La propriété de l'ACP de capter une partie importante de la variance des données à partir de moins de variables est particulièrement intéressante dans le domaine du Machine Learning pour être capable de fournir des prédictions avec des modèles plus légers (car utilisant moins de variables) et des résultats au moins aussi performants.&lt;br&gt;
Pour notre exemple, même si la réduction de dimensions n'est pas un enjeu fondamental vu le faible nombre de variables, nous pouvons tester si nous parvenons à faire un modèle de prédiction de l'origine du vin (producteur 0, 1 ou 2) en réduisant le nombre de dimensions.&lt;br&gt;
Tout d'abord, commençons par déterminer ce nombre de dimensions. Le graphique suivant nous donne l'évolution de la variance expliquée en fonction du nombre de composantes :   &lt;/p&gt;
&lt;p&gt;&lt;img alt="Pelican" src="../images/acp/output_20_0.png" style="max-width:80% !important" &gt;&lt;/p&gt;
&lt;p&gt;L'ACP permettrait d'expliquer plus de 70% de la variance totale dès 4 composantes. Pour voir si cela est suffisant pour entraîner un modèle de prédiction, on peut comparer les performances d'un arbre de classification sur les données transformées après PCA et sur les données brutes. On utilise une méthode de validation croisée pour estimer les performances du modèle qui consiste à partitionner les données en 5 groupes et à entraîner les données sur 4 groupes et les tester sur celui restant. On fait cela 5 fois pour parcourir le champ des possibles et on évalue la précision globale du modèle en faisant la moyenne de ces 5 résultats. Cette méthode doit permettre d'estimer la qualité du modèle sur des données sur lesquelles il n'a pas été entraîné et de ne pas prendre en compte le surapprentissage dans son évaluation. Le tableau suivant donne les taux de précision obtenus pour chaque méthode, c'est à dire le nombre de vins correctement classifiés sur le nombre de vins total.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# Plutôt que de renseigner le nombre de composantes &lt;/span&gt;
&lt;span class="c1"&gt;# on renseigne la valeur minimum de la variance &lt;/span&gt;
&lt;span class="c1"&gt;# expliquée totale que l&amp;#39;on souhaite&lt;/span&gt;
&lt;span class="n"&gt;pca&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;PCA&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.70&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; 
&lt;span class="n"&gt;wine_pca&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pca&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;values_cr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# On entraîne notre modèle et on l&amp;#39;évalue avec une &lt;/span&gt;
&lt;span class="c1"&gt;# méthode de validation croisée &lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.model_selection&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;cross_val_score&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.tree&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;DecisionTreeClassifier&lt;/span&gt;
&lt;span class="n"&gt;clf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;DecisionTreeClassifier&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;mean_pca&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cross_val_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;clf&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;wine_pca&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;target&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cv&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;mean_all&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cross_val_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;clf&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;target&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cv&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Précision moyenne après ACP&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;mean_pca&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; 
              &lt;span class="s2"&gt;&amp;quot;Précision moyenne sans ACP&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;mean_all&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; 
              &lt;span class="s2"&gt;&amp;quot;Nombre de composantes&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;wine_pca&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]]})&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Précision moyenne après ACP&lt;/th&gt;
      &lt;th&gt;Précision moyenne sans ACP&lt;/th&gt;
      &lt;th&gt;Nombre de composantes&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;0.933175&lt;/td&gt;
      &lt;td&gt;0.887619&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;On constate que l'ACP n'a pas seulement permis de réduire le nombre de dimensions de notre problème, elle nous offre aussi une précision globale du modèle supérieure. Cela n'est pas toujours le cas - puisque ça dépend de votre problématique, des variables explicatives dont vous disposez et du nombre de composantes que vous retenez - mais ici c'est dû au fait qu'elle permet de réduire le bruit associé aux données en ne conservant qu'une partie de l'information totale. Cela permet ainsi de prévenir les problèmes de surapprentissage, c'est à dire le fait que le modèle explique parfaitement les données d'entraînement mais se généralise mal à de nouvelles données. Ce sujet est abordé dans &lt;a href="https://blog.statoscop.fr/larbitrage-biaisvariance-dans-la-modelisation-de-donnees.html"&gt;cet article de notre blog sur l'arbitrage biais/variance&lt;/a&gt;.  &lt;/p&gt;
&lt;p&gt;C'est tout pour aujourd'hui! Si vous voulez voir d'autres exemples d'utilisation de l'ACP, je vous conseille &lt;a href="https://jakevdp.github.io/PythonDataScienceHandbook/05.09-principal-component-analysis.html" target="_blank"&gt;cet article&lt;/a&gt; qui aborde notamment le cas du traitement des images, pour lequel il est particulièrement intéressant de réduire le nombre de dimensions. N'hésitez pas à &lt;a href="https://www.statoscop.fr"&gt;visiter notre site&lt;/a&gt; et à nous suivre sur &lt;a href="https://twitter.com/stato_scop"&gt;Twitter&lt;/a&gt; pour ne pas rater les prochains articles! Vous pouvez trouver le notebook avec l'ensemble du code ayant servi à générer cette note sur le &lt;a href="https://github.com/Statoscop/notebooks-blog" target="_blank"&gt;github de Statoscop&lt;/a&gt;.   &lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="Python"></category><category term="Python"></category><category term="Machine Learning"></category><category term="Statistiques"></category><category term="Data Science"></category></entry></feed>