<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Le blog - Stats &amp; ML</title><link href="https://blog.statoscop.fr/" rel="alternate"></link><link href="https://blog.statoscop.fr/feeds/stats-ml.atom.xml" rel="self"></link><id>https://blog.statoscop.fr/</id><updated>2023-05-17T00:00:00+02:00</updated><entry><title>Taux standardisés : calcul et interprétation avec R</title><link href="https://blog.statoscop.fr/taux-standardises-calcul-et-interpretation-avec-r.html" rel="alternate"></link><published>2023-05-17T00:00:00+02:00</published><updated>2023-05-17T00:00:00+02:00</updated><author><name>Antoine</name></author><id>tag:blog.statoscop.fr,2023-05-17:/taux-standardises-calcul-et-interpretation-avec-r.html</id><summary type="html">&lt;p&gt;Présentation de la méthode de standardisation directe sur les taux de survie des passagers du Titanic.&lt;/p&gt;</summary><content type="html">&lt;div class="toc"&gt;&lt;span class="toctitle"&gt;Table des matières&lt;/span&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#principe-de-la-standardisation-directe"&gt;Principe de la standardisation directe&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#analyses-exploratoires-des-donnees"&gt;Analyses exploratoires des données&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#calcul-pas-a-pas-des-taux-standardises-de-survie-au-naufrage-du-titanic"&gt;Calcul pas-à-pas des taux standardisés de survie au naufrage du Titanic&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#pour-conclure"&gt;Pour conclure&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;Dans cette note nous présentons la méthode de standardisation directe des taux, qui permet de comparer des fréquences d'évènement entre différentes sous-populations en contrôlant par une ou plusieurs autres variables. Après avoir défini le principe général de standardisation directe, on présente une mise en oeuvre pas-à-pas de la méthode sur une étude de cas à partir des données des passagers du Titanic.  &lt;/p&gt;
&lt;h1 id="principe-de-la-standardisation-directe"&gt;Principe de la standardisation directe&lt;/h1&gt;
&lt;p&gt;Les méthodes de standardisation des taux sont principalement étudiées en épidémiologie. Elles permettent en effet de répondre au problème suivant : comment &lt;strong&gt;comparer des indicateurs épidémiologiques&lt;/strong&gt; entre différents pays ayant leurs spécificités démographiques? &lt;br&gt;
On peut lire par exemple sur le site des &lt;a href="https://donnees.banquemondiale.org"&gt;données de la banque mondiale&lt;/a&gt; que le taux de mortalité en 2020 en Australie est de 6 pour 1000 habitants, contre 12 pour 1000 habitants en Allemagne. Or, cet indicateur est bien sûr fortement influencé par la structure d'âge de la population concernée. Pour correctement comparer cet indicateur entre l'Australie et l'Allemagne et éventuellement en tirer des conclusions sur des différences de qualité de vie entre les deux pays, il faudrait &lt;strong&gt;comparer ces taux à structure d'âge constante&lt;/strong&gt;. &lt;br&gt;
C'est précisément ce que permet de faire la standardisation directe. Il est nécessaire pour cela de disposer du détail de l'indicateur par tranche d'âge dans chacun des pays. Dans notre exemple, une fois qu'on dispose des taux de mortalité par tranche d'âge en Australie et en Allemagne, on les  applique à &lt;strong&gt;une structure d'âge de référence&lt;/strong&gt;, qui peut être soit celle d'un des deux pays, soit celle du monde entier si on dispose de l'information. On peut alors obtenir un nouveau taux de mortalité global &lt;strong&gt;corrigé de l'effet lié à l'âge&lt;/strong&gt; et permettant une comparaison plus pertinente entre les pays. Voyons concrètement comment on peut mettre en oeuvre cette méthode sur une étude de cas en R.  &lt;/p&gt;
&lt;h1 id="analyses-exploratoires-des-donnees"&gt;Analyses exploratoires des données&lt;/h1&gt;
&lt;p&gt;Pour notre petit exemple, on s'appuie sur un dataset très connu : les &lt;a href="https://www.kaggle.com/c/titanic"&gt;données des passagers du Titanic&lt;/a&gt;. Les informations qui nous intéressent ici sont la classe économique, l'âge et le fait d'avoir survécu ou non au naufrage. On ne garde que les observations ayant des valeurs renseignées pour ces 3 variables. On veut répondre à la question suivante : &lt;strong&gt;le fait d'être dans une classe économique aisée augmente-t-elle les chances de survie au nauffrage?&lt;/strong&gt;  &lt;/p&gt;
&lt;p&gt;La première approche de cette question est bien sûr de calculer les taux de survie par classe économique. le résultat est le suivant :  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;titanic_data&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; &lt;span class="nf"&gt;group_by&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pclass&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; 
  &lt;span class="nf"&gt;summarise&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tx_survie&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;survived&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="nf"&gt;n&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; 
  &lt;span class="n"&gt;knitr&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="nf"&gt;kable&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="right"&gt;pclass&lt;/th&gt;
&lt;th align="right"&gt;tx_survie&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="right"&gt;1&lt;/td&gt;
&lt;td align="right"&gt;0.6373239&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;2&lt;/td&gt;
&lt;td align="right"&gt;0.4406130&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;3&lt;/td&gt;
&lt;td align="right"&gt;0.2614770&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;On constate en effet une forte disparité des taux de survie en fonction de la classe économique, puisque les passagers de 1ere classe sont 63,7% à survivre, contre 44,1% des passagers de seconde classe et 26,1% des passagers de 3e classe.&lt;br&gt;
Est-on bien sûr cependant que l'on observe &lt;strong&gt;l'effet de la classe économique et pas d'un autre facteur de confusion&lt;/strong&gt;? On peut par exemple imaginer que l'âge a un effet important sur la chance de survie, et qu'il est également lié à la classe économique choisie pour le voyage. Vérifions ces hypothèses en croisant la répartition en tranches d'âge dans chaque classe :  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;titanic_data&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; 
  &lt;span class="nf"&gt;group_by&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pclass&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tr_age&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; 
  &lt;span class="nf"&gt;summarise&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;eff&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;n&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; 
  &lt;span class="c1"&gt;# À ce stade le df n&amp;#39;est plus groupé que par pclass&lt;/span&gt;
  &lt;span class="nf"&gt;mutate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Proportion&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;eff&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="nf"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;eff&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; 
  &lt;span class="nf"&gt;select&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;eff&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; 
  &lt;span class="n"&gt;knitr&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="nf"&gt;kable&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="right"&gt;pclass&lt;/th&gt;
&lt;th align="left"&gt;tr_age&lt;/th&gt;
&lt;th align="right"&gt;Proportion&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="right"&gt;1&lt;/td&gt;
&lt;td align="left"&gt;0 - 17 ans&lt;/td&gt;
&lt;td align="right"&gt;0.0528169&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;1&lt;/td&gt;
&lt;td align="left"&gt;18 - 34 ans&lt;/td&gt;
&lt;td align="right"&gt;0.3239437&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;1&lt;/td&gt;
&lt;td align="left"&gt;35 - 49 ans&lt;/td&gt;
&lt;td align="right"&gt;0.3697183&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;1&lt;/td&gt;
&lt;td align="left"&gt;50 ans ou +&lt;/td&gt;
&lt;td align="right"&gt;0.2535211&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;2&lt;/td&gt;
&lt;td align="left"&gt;0 - 17 ans&lt;/td&gt;
&lt;td align="right"&gt;0.1264368&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;2&lt;/td&gt;
&lt;td align="left"&gt;18 - 34 ans&lt;/td&gt;
&lt;td align="right"&gt;0.5823755&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;2&lt;/td&gt;
&lt;td align="left"&gt;35 - 49 ans&lt;/td&gt;
&lt;td align="right"&gt;0.1954023&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;2&lt;/td&gt;
&lt;td align="left"&gt;50 ans ou +&lt;/td&gt;
&lt;td align="right"&gt;0.0957854&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;3&lt;/td&gt;
&lt;td align="left"&gt;0 - 17 ans&lt;/td&gt;
&lt;td align="right"&gt;0.2115768&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;3&lt;/td&gt;
&lt;td align="left"&gt;18 - 34 ans&lt;/td&gt;
&lt;td align="right"&gt;0.6047904&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;3&lt;/td&gt;
&lt;td align="left"&gt;35 - 49 ans&lt;/td&gt;
&lt;td align="right"&gt;0.1576846&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;3&lt;/td&gt;
&lt;td align="left"&gt;50 ans ou +&lt;/td&gt;
&lt;td align="right"&gt;0.0259481&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;On constate en effet que la classe 3 comporte bien plus de mineurs et bien moins de passagers de plus de cinquante ans que la première classe. Comme on s'y attendait, &lt;strong&gt;plus la classe économique est aisée, plus les passagers ont un âge élevé&lt;/strong&gt;. Voyons maintenant si les taux de survie varient en fonction de l'âge :  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;titanic_data&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; &lt;span class="nf"&gt;group_by&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tr_age&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; 
  &lt;span class="nf"&gt;summarise&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tx_survie&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;survived&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="nf"&gt;n&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; 
  &lt;span class="n"&gt;knitr&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="nf"&gt;kable&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;tr_age&lt;/th&gt;
&lt;th align="right"&gt;tx_survie&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;0 - 17 ans&lt;/td&gt;
&lt;td align="right"&gt;0.5259740&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;18 - 34 ans&lt;/td&gt;
&lt;td align="right"&gt;0.3765996&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;35 - 49 ans&lt;/td&gt;
&lt;td align="right"&gt;0.4085106&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;50 ans ou +&lt;/td&gt;
&lt;td align="right"&gt;0.4000000&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Les taux de survie ne semblent pas beaucoup varier en fonction de l'âge, à part pour les mineurs qui ont un taux de survie bien supérieur aux autres. Croisons maintenant les taux de survie en fonction de la classe économique &lt;strong&gt;et&lt;/strong&gt; de la tranche d'âge :  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;titanic_data&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; &lt;span class="nf"&gt;group_by&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pclass&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tr_age&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; 
  &lt;span class="nf"&gt;summarise&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tx_survie&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;survived&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="nf"&gt;n&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; 
  &lt;span class="n"&gt;knitr&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="nf"&gt;kable&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="right"&gt;pclass&lt;/th&gt;
&lt;th align="left"&gt;tr_age&lt;/th&gt;
&lt;th align="right"&gt;tx_survie&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="right"&gt;1&lt;/td&gt;
&lt;td align="left"&gt;0 - 17 ans&lt;/td&gt;
&lt;td align="right"&gt;0.8666667&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;1&lt;/td&gt;
&lt;td align="left"&gt;18 - 34 ans&lt;/td&gt;
&lt;td align="right"&gt;0.7065217&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;1&lt;/td&gt;
&lt;td align="left"&gt;35 - 49 ans&lt;/td&gt;
&lt;td align="right"&gt;0.6285714&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;1&lt;/td&gt;
&lt;td align="left"&gt;50 ans ou +&lt;/td&gt;
&lt;td align="right"&gt;0.5138889&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;2&lt;/td&gt;
&lt;td align="left"&gt;0 - 17 ans&lt;/td&gt;
&lt;td align="right"&gt;0.8787879&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;2&lt;/td&gt;
&lt;td align="left"&gt;18 - 34 ans&lt;/td&gt;
&lt;td align="right"&gt;0.4144737&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;2&lt;/td&gt;
&lt;td align="left"&gt;35 - 49 ans&lt;/td&gt;
&lt;td align="right"&gt;0.3333333&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;2&lt;/td&gt;
&lt;td align="left"&gt;50 ans ou +&lt;/td&gt;
&lt;td align="right"&gt;0.2400000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;3&lt;/td&gt;
&lt;td align="left"&gt;0 - 17 ans&lt;/td&gt;
&lt;td align="right"&gt;0.3679245&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;3&lt;/td&gt;
&lt;td align="left"&gt;18 - 34 ans&lt;/td&gt;
&lt;td align="right"&gt;0.2574257&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;3&lt;/td&gt;
&lt;td align="left"&gt;35 - 49 ans&lt;/td&gt;
&lt;td align="right"&gt;0.1645570&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;3&lt;/td&gt;
&lt;td align="left"&gt;50 ans ou +&lt;/td&gt;
&lt;td align="right"&gt;0.0769231&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;On constate là plusieurs choses :&lt;br&gt;
- Au sein de chaque classe économique il y a un lien très clair entre l'âge et le taux de survie : plus on vieillit pluys celui-ci baisse.&lt;br&gt;
- Au sein de chaque tranche d'âge, plus la classe économique est élevée plus la chance de survie augmente. La seule exception est la tranche d'âge 0 - 17 ans de la seconde classe qui a un taux de survie légèrement supérieur à la population du même âge de la 1ere classe (87,9% contre 86,7%).  &lt;/p&gt;
&lt;p&gt;Au vu de ces éléments il apparaît légitime de calculer des taux standardisés pour comparer des fréquences de survie au sein de chaque classe corrigées de l'effet de l'âge.  &lt;/p&gt;
&lt;h1 id="calcul-pas-a-pas-des-taux-standardises-de-survie-au-naufrage-du-titanic"&gt;Calcul pas-à-pas des taux standardisés de survie au naufrage du Titanic&lt;/h1&gt;
&lt;p&gt;Au vu des résultats des taux de survie croisés par classe et âge, on sait déjà que la classe économique et l'âge jouent sur la chance de survie. Le calcul des taux standardisés de survie va permettre de quantifier &lt;strong&gt;l'effet de la classe économique isolé de l'effet âge&lt;/strong&gt;. Le principe est le suivant : on calcule le taux de survie que l'on observerait dans chaque classe économique &lt;strong&gt;si la répartition des passagers en classe d'âge était la même que celle de la population de référence&lt;/strong&gt;. Dans notre exemple, la population de référence est l'ensemble des passagers.&lt;/p&gt;
&lt;p&gt;La première étape est de récupérer les effectifs de classe d'âge de la population de référence :  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;titanic_data&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; &lt;span class="nf"&gt;group_by&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tr_age&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; 
  &lt;span class="nf"&gt;summarise&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;eff&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;n&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;rep_age_ref&lt;/span&gt;

&lt;span class="n"&gt;knitr&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="nf"&gt;kable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rep_age_ref&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;tr_age&lt;/th&gt;
&lt;th align="right"&gt;eff&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;0 - 17 ans&lt;/td&gt;
&lt;td align="right"&gt;154&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;18 - 34 ans&lt;/td&gt;
&lt;td align="right"&gt;547&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;35 - 49 ans&lt;/td&gt;
&lt;td align="right"&gt;235&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;50 ans ou +&lt;/td&gt;
&lt;td align="right"&gt;110&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;On calcule ensuite comme précédemment les taux de survie par tranche d'âge de chaque classe économique et on transforme la table pour avoir une colonne par classe économique.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;titanic_data&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; &lt;span class="nf"&gt;group_by&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pclass&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tr_age&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; 
  &lt;span class="c1"&gt;# taux de survie par classe et tranche d&amp;#39;âge&lt;/span&gt;
  &lt;span class="nf"&gt;summarise&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;survie&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;survived&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="nf"&gt;n&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; 
  &lt;span class="c1"&gt;# on transforme la table en largeur pour avoir trois colonnes&lt;/span&gt;
  &lt;span class="c1"&gt;# donnant le taux de survie&lt;/span&gt;
  &lt;span class="n"&gt;tidyr&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="nf"&gt;pivot_wider&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;names_from&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pclass&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;values_from&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;survie&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                     &lt;span class="c1"&gt;# option names_glue pour spécifier le nom des variables créées&lt;/span&gt;
                     &lt;span class="n"&gt;names_glue&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;{.value}_{pclass}&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;survie_age_class&lt;/span&gt;

&lt;span class="n"&gt;knitr&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="nf"&gt;kable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;survie_age_class&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;tr_age&lt;/th&gt;
&lt;th align="right"&gt;survie_1&lt;/th&gt;
&lt;th align="right"&gt;survie_2&lt;/th&gt;
&lt;th align="right"&gt;survie_3&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;0 - 17 ans&lt;/td&gt;
&lt;td align="right"&gt;0.8666667&lt;/td&gt;
&lt;td align="right"&gt;0.8787879&lt;/td&gt;
&lt;td align="right"&gt;0.3679245&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;18 - 34 ans&lt;/td&gt;
&lt;td align="right"&gt;0.7065217&lt;/td&gt;
&lt;td align="right"&gt;0.4144737&lt;/td&gt;
&lt;td align="right"&gt;0.2574257&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;35 - 49 ans&lt;/td&gt;
&lt;td align="right"&gt;0.6285714&lt;/td&gt;
&lt;td align="right"&gt;0.3333333&lt;/td&gt;
&lt;td align="right"&gt;0.1645570&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;50 ans ou +&lt;/td&gt;
&lt;td align="right"&gt;0.5138889&lt;/td&gt;
&lt;td align="right"&gt;0.2400000&lt;/td&gt;
&lt;td align="right"&gt;0.0769231&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Il ne reste plus qu'à fusionner les deux tables ainsi créées et à appliquer chacun des taux de survie aux effectifs par tranche d'âge de la population de référence :  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;rep_age_ref&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; &lt;span class="nf"&gt;inner_join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;survie_age_class&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;by&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;tr_age&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; 
  &lt;span class="nf"&gt;mutate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="nf"&gt;across&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;starts_with&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;survie_&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="o"&gt;~&lt;/span&gt; &lt;span class="n"&gt;.&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;eff&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;eff_survie_age_class&lt;/span&gt;
&lt;span class="n"&gt;knitr&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="nf"&gt;kable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;eff_survie_age_class&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;tr_age&lt;/th&gt;
&lt;th align="right"&gt;eff&lt;/th&gt;
&lt;th align="right"&gt;survie_1&lt;/th&gt;
&lt;th align="right"&gt;survie_2&lt;/th&gt;
&lt;th align="right"&gt;survie_3&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;0 - 17 ans&lt;/td&gt;
&lt;td align="right"&gt;154&lt;/td&gt;
&lt;td align="right"&gt;133.46667&lt;/td&gt;
&lt;td align="right"&gt;135.33333&lt;/td&gt;
&lt;td align="right"&gt;56.660377&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;18 - 34 ans&lt;/td&gt;
&lt;td align="right"&gt;547&lt;/td&gt;
&lt;td align="right"&gt;386.46739&lt;/td&gt;
&lt;td align="right"&gt;226.71711&lt;/td&gt;
&lt;td align="right"&gt;140.811881&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;35 - 49 ans&lt;/td&gt;
&lt;td align="right"&gt;235&lt;/td&gt;
&lt;td align="right"&gt;147.71429&lt;/td&gt;
&lt;td align="right"&gt;78.33333&lt;/td&gt;
&lt;td align="right"&gt;38.670886&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;50 ans ou +&lt;/td&gt;
&lt;td align="right"&gt;110&lt;/td&gt;
&lt;td align="right"&gt;56.52778&lt;/td&gt;
&lt;td align="right"&gt;26.40000&lt;/td&gt;
&lt;td align="right"&gt;8.461538&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;Si l'utilisation d'across ne vous semble pas claire, je ne saurais trop vous recommander &lt;a href="https://blog.statoscop.fr/fonctionnement-et-performances-dacross-dans-dplyr.html"&gt;notre précédent article de blog&lt;/a&gt; sur ce verbe bien pratique de dplyr.  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;On obtient finalement nos taux de survie standardisés en sommant les effectifs par tranche d'âge et en divisant par l'effectif total :  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;eff_survie_age_class&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; 
  &lt;span class="nf"&gt;summarise&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;across&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;starts_with&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;survie_&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="o"&gt;~&lt;/span&gt; &lt;span class="nf"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;.&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="nf"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;eff&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; 
  &lt;span class="n"&gt;knitr&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="nf"&gt;kable&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="right"&gt;survie_1&lt;/th&gt;
&lt;th align="right"&gt;survie_2&lt;/th&gt;
&lt;th align="right"&gt;survie_3&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="right"&gt;0.692329&lt;/td&gt;
&lt;td align="right"&gt;0.446256&lt;/td&gt;
&lt;td align="right"&gt;0.2338477&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Par rapport aux taux de survie bruts présentés plus haut, on constate que &lt;strong&gt;les inégalités économiques de survie s'aggravent après avoir contrôlé par l'âge&lt;/strong&gt;. Le taux de survie standardisés de la classe 1 et de la classe 3 sont en effet de 69,2% et 23,4 % contre 63,7% et 26,1% avant la correction. Cela correspond à ce que l'on pouvait pressentir après l'analyse exploratoire puisque les passagers de la classe 3 sont plus jeunes et que les jeunes ont une meilleure chance de survie au sein de chaque classe économique.   &lt;/p&gt;
&lt;h1 id="pour-conclure"&gt;Pour conclure&lt;/h1&gt;
&lt;p&gt;J'espère que cet exemple vous aura permis de mieux appréhender la question de la standardisation directe. Bien sûr, la méthode utilisée ici comporte des limites, notamment l'utilisation de tranches d'âge très larges qui pourraient fausser le résultat. On peut par exemple penser que les enfants en bas âge ont bénéficié d'une attention toute particulière, et ils se retrouvent ici dans la même tranche d'âge que des adolescents. Mais nous sommes également contraints par les effectifs qui nous empêchent de faire une analyse trop fine de ces subtilités. Si ces questions vous intéressent, vous pouvez vous reporter à notre article sur &lt;a href="https://blog.statoscop.fr/le-dilemme-biais-variance-dans-la-modelisation-de-donnees.html"&gt;le dilemme biais-variance&lt;/a&gt;.   &lt;/p&gt;
&lt;p&gt;Enfin, nous avons passé sous silence une variable explicative très importante : le sexe des passagers. Les taux de survie sont en effet très différents pour les hommes et pour les femmes. Il est possible de reproduire cette analyse en prenant en compte cette variable, croisée également avec l'âge. Cependant, toujours en raison de trop faibles effectifs, il sera sans doute nécessaire d'agréger encore plus les tranches d'âge. Vous avez les cartes en main pour le faire, et mieux comprendre les fortunes diverses de Jack et Rose dans le célèbre film de la tragédie...  &lt;/p&gt;
&lt;p&gt;C'est la fin de cet article! N'hésitez pas à &lt;a href="https://www.statoscop.fr"&gt;visiter notre site&lt;/a&gt; et à nous suivre sur &lt;a href="https://twitter.com/stato_scop"&gt;Twitter&lt;/a&gt; et &lt;a href="https://www.linkedin.com/company/statoscop"&gt;Linkedin&lt;/a&gt;. Pour retrouver l'ensemble du code ayant servi à générer cette note, vous pouvez vous rendre sur le &lt;a href="https://github.com/Statoscop/notebooks-blog"&gt;github de Statoscop&lt;/a&gt;.  &lt;/p&gt;</content><category term="R"></category><category term="R"></category><category term="Rstats"></category><category term="data science"></category><category term="statistiques"></category></entry><entry><title>Risques relatifs et odds-ratios : comment les interpréter et les comparer?</title><link href="https://blog.statoscop.fr/risques-relatifs-et-odds-ratios-comment-les-interpreter-et-les-comparer.html" rel="alternate"></link><published>2022-03-04T00:00:00+01:00</published><updated>2022-03-04T00:00:00+01:00</updated><author><name>Antoine</name></author><id>tag:blog.statoscop.fr,2022-03-04:/risques-relatifs-et-odds-ratios-comment-les-interpreter-et-les-comparer.html</id><summary type="html">&lt;p&gt;Petite présentation des OR et des RR, et ce qu'ils veulent dire.&lt;/p&gt;</summary><content type="html">&lt;div class="toc"&gt;&lt;span class="toctitle"&gt;Table des matières&lt;/span&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#probabilites-et-cotes"&gt;Probabilités et cotes&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#definitions"&gt;Définitions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#lien-entre-cote-et-probabilite"&gt;Lien entre cote et probabilité&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#risques-relatifs-et-odds-ratios"&gt;Risques relatifs et odds ratios&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#interpretations"&gt;Interprétations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#comment-choisir-lindicateur-adapte"&gt;Comment choisir l'indicateur adapté&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#conclusion"&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;Dans cet article, on s'intéresse à la relation entre probabilités et cotes et aux implications concernant deux indicateurs souvent utilisés pour comparer le risque d'un évènement entre différents groupes d'individus : les risques relatifs (RR) et les odds ratios (OR). &lt;/p&gt;
&lt;h1 id="probabilites-et-cotes"&gt;Probabilités et cotes&lt;/h1&gt;
&lt;h2 id="definitions"&gt;Définitions&lt;/h2&gt;
&lt;p&gt;La &lt;strong&gt;probabilité&lt;/strong&gt; correspond à la vraisemblance d'un évènement. Elle est comprise entre 0 (évènement impossible) et 1 (évènement certain). On peut estimer une probabilité d'un évènement à partir de sa &lt;strong&gt;fréquence&lt;/strong&gt;, au sens du rapport entre &lt;strong&gt;le nombre de fois où cet évènement est observé&lt;/strong&gt; et le &lt;strong&gt;nombre d'observations total&lt;/strong&gt; dont on dispose. En épidémiologie, on parle aussi de &lt;strong&gt;prévalence&lt;/strong&gt;. Ainsi, si l'on constate par exemple à un instant T que pour 100 personnes 20 sont atteintes d'une maladie, on en concluera que le &lt;strong&gt;taux de prévalence de cette maladie&lt;/strong&gt; est de 20%. On peut aussi en déduire que la probabilité qu'un individu tiré au hasard ait cette maladie est de 20%.&lt;br&gt;
La &lt;strong&gt;cote&lt;/strong&gt; d'un évènement est le rapport entre &lt;strong&gt;le nombre de fois où cet évènement est observé&lt;/strong&gt; et le &lt;strong&gt;le nombre de fois où cet évènement n'est pas observé&lt;/strong&gt;. Pour notre maladie dont le taux de prévalence est de 20%, la cote est donc 20/80, car sur 100 personnes 20 ont la maladie et 80 ne l'ont pas. Notre cote est ainsi de 0,25. Si &lt;strong&gt;le taux de prévalence avait été de 50%, la cote aurait été de 1&lt;/strong&gt; (50/50) : c'est la valeur de la cote qui définit un évènement qui a autant de chances de se produire que de ne pas se produire. Si le taux de prévalence avait été de 1, la cote aurait été de... l'infini (100/0). Les cotes vont ainsi de 0 à l'infini. &lt;/p&gt;
&lt;h2 id="lien-entre-cote-et-probabilite"&gt;Lien entre cote et probabilité&lt;/h2&gt;
&lt;p&gt;Les valeurs des cotes de &lt;strong&gt;0 à 1&lt;/strong&gt; correspondent aux &lt;strong&gt;évènements qui ont moins de chances d'arriver que de ne pas arriver&lt;/strong&gt; et ceux de &lt;strong&gt;1 à l'infini&lt;/strong&gt; aux &lt;strong&gt;évènements qui ont plus de chances d'arriver que de ne pas arriver&lt;/strong&gt;. &lt;br&gt;
On peut représenter le lien entre une probabilité et sa cote, en n'oubliant pas de passer l'axe représentant la cote en &lt;strong&gt;échelle logarithmique&lt;/strong&gt;. En effet, c'est ici cette échelle qui va permettre de rendre compte visuellement de la symétrie des valeurs entre 0 et 1 et de celles entre 1 et l'infini :  &lt;/p&gt;
&lt;p&gt;&lt;img alt="Pelican" src="../images/or_rr/unnamed-chunk-1-1.png"&gt;&lt;/p&gt;
&lt;p&gt;Ainsi, une cote de 0,5 correspond à &lt;strong&gt;deux fois moins de chances&lt;/strong&gt; que l'évènement arrive plutôt qu'il n'arrive pas et une cote de 2 correspond à &lt;strong&gt;deux fois plus de chances&lt;/strong&gt; que l'évènement arrive plutôt qu'il n'arrive pas. C'est le même raisonnement pour 0,1 et 10 (10 fois plus ou moins de chances), pour 0,01 et 100 (100 fois plus ou  moins de chance), etc...  &lt;/p&gt;
&lt;p&gt;Les cotes se déduisent donc directement des probabilités. Mais lorsque l'on compare plusieurs populations, le choix de l'un ou l'autre des indicateurs va avoir une influence sur le résultat obtenu.    &lt;/p&gt;
&lt;h1 id="risques-relatifs-et-odds-ratios"&gt;Risques relatifs et odds ratios&lt;/h1&gt;
&lt;h2 id="interpretations"&gt;Interprétations&lt;/h2&gt;
&lt;p&gt;Les risques relatifs (RR) et les odds ratios (OR) sont utilisés pour &lt;strong&gt;comparer le risque d'un évènement entre plusieurs populations&lt;/strong&gt;. Reprenons notre exemple de la maladie dont la prévalence est de 20% dans la population. Imaginons qu'on observe en fait que cette prévalence varie fortement selon le sexe, et qu'elle est de 10% chez les hommes et de 30% chez les femmes.&lt;br&gt;
Le risque relatif pour une femme par rapport à un homme est &lt;strong&gt;le rapport de la probabilité pour une femme d'avoir cette maladie sur celle pour un homme&lt;/strong&gt;. Dans notre cas, ce risque relatif est donc de 3 (30%/10%). On interprète ce résultat comme le fait que les femmes ont 3 fois plus de chances d'avoir cette maladie que les hommes.&lt;br&gt;
L'odds ratio est &lt;strong&gt;le rapport de la cote de cette maladie pour une femme sur celle pour un homme&lt;/strong&gt;. La cote d'une femme est de 30/70, soit environ 0,43. Celle d'un homme est de 0,1/0,9, soit environ 0,11. Le rapport de ces cotes est donc de 3,9. Il est sensiblement différent du risque relatif et ne s'interprète pas aussi aisément. En effet, on ne peut pas ici affirmer que près de 4 fois plus de femmes ont cette maladie que les hommes, mais que la cote d'une femme est 4 fois plus élevée que celle d'un homme.  &lt;/p&gt;
&lt;h2 id="comment-choisir-lindicateur-adapte"&gt;Comment choisir l'indicateur adapté&lt;/h2&gt;
&lt;p&gt;Le débat entre risques relatifs et odds-ratios vient souvent du fait que lorsque l'on veut faire un modèle qui contrôle par plusieurs facteurs de risque (par exemple sexe, âge, classe sociale, type d'habitation...) on va le plus souvent se tourner vers la régression logistique. Or ce modèle permet d'obtenir facilement les odds-ratio associés à ces différents facteurs de risque. Bien sûr, on peut déduire d'un odds ratio le risque relatif si on connaît la prévalence de la variable d'intérêt que l'on étudie, mais il devient compliqué d'opérer cette transformation lorsque l'on contrôle par plusieurs variables.&lt;br&gt;
Les risques relatifs sont souvent considérés à raison comme plus intuitifs et faciles à présenter. Ils ont cependant l'inconvénient de &lt;strong&gt;ne pas prendre en compte du tout le niveau de risque de base lorsqu'ils comparent deux populations&lt;/strong&gt;. Ainsi, qu'une probabilité passe de 0,5% à 1%, de 25% à 50% ou de 40% à 80% entre deux groupes, le risque relatif sera toujours égal à 2 (ou 0,5 selon le groupe de référence). Les OR seront bien égaux à 2 dans le premier cas, mais à 3 dans le second et à 6 dans le dernier. &lt;strong&gt;Plus la prévalence de l'évènement qu'on observe est faible dans la population, plus les OR sont semblables aux RR&lt;/strong&gt;.&lt;br&gt;
Le débat même sur l'interprétabilité des RR et des OR n'est pas évident. Considérons un groupe A qui a une prévalence d'une maladie de 50% et un groupe B avec une prévalence de 100%. Est-il plus juste de dire qu'appartenir au groupe B multiplie son risque relatif d'avoir la maladie par 2 par rapport au groupe A comme nous le renseigne le RR ou par l'infini, comme le prétend l'OR? Dans cet exemple, l'OR a l'avantage de capter une situation "extrême" où personne n'échapperait à la maladie. Au niveau individuel, le &lt;em&gt;risque&lt;/em&gt; semble en effet infiniment de fois plus important dans le groupe B puisque l'évènement est...certain.&lt;/p&gt;
&lt;h1 id="conclusion"&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;Contrairement au risque relatif, les OR ne donnent pas les mêmes résultats en fonction de la prévalence initiale de l'évènement qu'ils décrivent. Cela peut être un inconvénient quand il est interprété à tort comme un risque relatif, comme c'est souvent le cas. Mais il permet aussi de décrire plus justement le risque relatif de l'évènement &lt;strong&gt;par rapport au non-évènement&lt;/strong&gt;, et en ce sens ajoute de l'information. Le RR permet lui de mieux rendre compte des différences de fréquence d'un évènement entre plusieurs populations.&lt;br&gt;
Quelque soit l'indicateur choisi, il est important de &lt;strong&gt;ne pas présenter seulement les OR ou les RR mais aussi la prévalence, ou la fréquence de l'évènement&lt;/strong&gt;, même non contrôlée de tous les facteurs de risque. Cela permet au moins d'identifier si les OR ont de grandes chances ou non de différer fortement des RR. Ensuite, c'est à vous de choisir quel indicateur correspond le mieux au type de résultats que vous voulez présenter.  &lt;br&gt;
C'est tout pour aujourd'hui! N'hésitez pas à &lt;a href="https://www.statoscop.fr"&gt;visiter notre site&lt;/a&gt; et à nous suivre sur &lt;a href="https://twitter.com/stato_scop"&gt;Twitter&lt;/a&gt; et &lt;a href="https://www.linkedin.com/company/statoscop"&gt;Linkedin&lt;/a&gt;. Pour retrouver le code ayant servi à générer cette note, vous pouvez vous rendre sur le &lt;a href="https://github.com/Statoscop/notebooks-blog"&gt;github de Statoscop&lt;/a&gt;.  &lt;/p&gt;</content><category term="Stats &amp; ML"></category><category term="statistiques"></category><category term="odds-ratio"></category><category term="OR"></category><category term="probabilités"></category></entry><entry><title>Le dilemme biais variance dans la modélisation de données</title><link href="https://blog.statoscop.fr/le-dilemme-biais-variance-dans-la-modelisation-de-donnees.html" rel="alternate"></link><published>2021-11-08T00:00:00+01:00</published><updated>2021-11-08T00:00:00+01:00</updated><author><name>Antoine</name></author><id>tag:blog.statoscop.fr,2021-11-08:/le-dilemme-biais-variance-dans-la-modelisation-de-donnees.html</id><summary type="html">&lt;p&gt;Présentation des enjeux théoriques et pratiques de l'arbitrage biais variance dans la construction d'un modèle de prédiction.&lt;/p&gt;</summary><content type="html">&lt;div class="toc"&gt;&lt;span class="toctitle"&gt;Table des matières&lt;/span&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#que-sont-le-biais-et-la-variance"&gt;Que sont le biais et la variance?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#enjeux-de-larbitrage-biais-variance"&gt;Enjeux de l'arbitrage biais variance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#liens-avec-loverfitting-et-lunderfitting-dans-les-modeles-de-machine-learning"&gt;Liens avec l'overfitting et l'underfitting dans les modèles de Machine Learning&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#appelons-un-chat-un-chat"&gt;Appelons un chat un chat&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#courbe-dapprentissage-dun-modele"&gt;Courbe d'apprentissage d'un modèle&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#conclusion"&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;L'arbitrage biais variance est souvent évoqué pour caractériser les enjeux de la construction d'un modèle de prédiction performant. L'idée de cet article est d'essayer de donner au lecteur les outils théoriques de cette question en essayant de privilégier une approche intuitive et pratique du problème. Après avoir défini ce que sont le biais et la variance, on présente les enjeux de cet arbitrage puis l'application concrète dans le cas de l'entraînement d'un modèle de Machine Learning.&lt;/p&gt;
&lt;h1 id="que-sont-le-biais-et-la-variance"&gt;Que sont le biais et la variance?&lt;/h1&gt;
&lt;p&gt;Pour expliquer le plus simplement possible ces concepts, on se place dans le contexte de l'observation de deux variables &lt;code&gt;Y&lt;/code&gt; et &lt;code&gt;X&lt;/code&gt;. Dans le cas d'une modélisation d'une relation entre &lt;code&gt;X&lt;/code&gt; et &lt;code&gt;Y&lt;/code&gt;, le biais d'un estimateur est son écart avec sa "vraie" valeur si on observait parfaitement la relation entre ces variables. On entend donc le biais comme &lt;strong&gt;l'écart entre la fonction modélisée et la fonction théorique&lt;/strong&gt; qui permettrait de restituer le lien entre &lt;code&gt;X&lt;/code&gt; et &lt;code&gt;Y&lt;/code&gt;. &lt;/p&gt;
&lt;p&gt;Une manière de jouer sur le biais d'un modèle c'est de modifier sa variance. La variance est une mesure de dispersion de valeurs, qui donne une estimation de l'écart de celles-ci à leur moyenne. La variance d'un modèle estime &lt;strong&gt;à quel point celui-ci fluctue autour de sa moyenne pour coller aux données&lt;/strong&gt;. Une mesure utilisée couramment dans le cas des régressions linéaires est le coefficient de détermination R2. Celui-ci calcule &lt;strong&gt;la part de la variance des données expliquée par la variance du modèle&lt;/strong&gt;. Autrement dit, plus mon modèle sera proche des points de mes données, plus sa variance et donc le R2 seront élevés. Pour illustrer ce concept, on présente plusieurs modèles appliqués au même jeu de données avec une variance plus ou moins élevée :&lt;/p&gt;
&lt;p&gt;&lt;img alt="Pelican" src="../images/biais_variance/unnamed-chunk-1-1.png"&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Pour chaque modèle, la courbe du modèle est celle qui apparaît en rouge et on a mis en évidence en vert la projection de chaque point sur sa valeur prédite par le modèle. Voyons comment interpréter ces graphiques :  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Le premier modèle est un modèle naïf qui se contente de prédire que pour chaque valeur de &lt;code&gt;X&lt;/code&gt;, &lt;code&gt;Y&lt;/code&gt; sera égale à sa moyenne. Par définition donc, sa variance est nulle et sa capacité prédictive faible.  &lt;/li&gt;
&lt;li&gt;Le second modèle est une régression linéaire simple qui a un R2 d'environ 50%. Il a donc une meilleure qualité prédictive que le premier modèle du fait qu'il capte une partie de la variance des données, ici à travers une corrélation positive entre &lt;code&gt;X&lt;/code&gt; et &lt;code&gt;Y&lt;/code&gt;.  &lt;/li&gt;
&lt;li&gt;Le troisième modèle est un modèle polynomial dont on voit qu'il est plus ajusté que le second. Les points prédits (en vert) par la courbe sont en effet plus proche des points que pour le précédent modèle et mécaniquement cela fait augmenter le R2. Le fait d'utiliser un modèle polynomial a donné au modèle une plus grande souplesse ce qui lui a permis de se rapprocher de certains points extrêmes qui étaient éloignés de la droite de régression du second modèle.  &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ainsi, plus la variance augmente, plus le modèle prédit en moyenne des valeurs proches de leurs vraies valeurs, ce qui fait diminuer le biais, puisqu'il est défini comme l'écart entre notre fonction de prédiction et une fonction qui permettrait de prédire parfaitement les données observées.  &lt;/p&gt;
&lt;h1 id="enjeux-de-larbitrage-biais-variance"&gt;Enjeux de l'arbitrage biais variance&lt;/h1&gt;
&lt;p&gt;D'après ce qu'on a vu, pourquoi alors ne pas simplement chercher à maximiser la variance pour minimiser le biais, c'est-à-dire son écart aux vraies valeurs? Tout simplement parce que dans le cas de la construction d'un modèle de prédiction, nous modélisons des relations entre des données à partir d'un échantillon pour prédire un résultat sur une nouvelle population. C'est donc la performance de ce modèle sur de nouvelles données qui va nous intéresser. Or, comme vous avez pu le pressentir en observant les graphiques précédents, &lt;strong&gt;un modèle avec une variance très élevée se généralise mal à de nouvelles données&lt;/strong&gt;. D'un autre côté, &lt;strong&gt;un modèle avec une faible variance aura lui aussi une qualité prédictive très faible&lt;/strong&gt; car il captera mal une éventuelle relation entre les variables.&lt;/p&gt;
&lt;p&gt;Tout le problème de cet arbitrage (ou dilemme) biais variance est donc de &lt;strong&gt;trouver un modèle qui ait une variance suffisamment forte pour limiter le biais mais suffisamment faible pour qu'il soit généralisable&lt;/strong&gt;. Les modèles précédents avaient été entraînés sur une base de données qui était un échantillon aléatoire correspondant à 10% des données d'un échantillon plus important. Pour mesurer la qualité prédictive de ces modèles on les applique donc aux données entières et on calcule l'écart moyen au carré de la prédiction à la vraie valeur, c'est-à-dire l'erreur quadratique moyenne ou en anglais &lt;strong&gt;MSE&lt;/strong&gt; pour &lt;em&gt;Mean Squared Error&lt;/em&gt; :&lt;/p&gt;
&lt;p&gt;&lt;img alt="Pelican" src="../images/biais_variance/unnamed-chunk-2-1.png"&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;On constate que, comme attendu, le modèle avec le plus de variance se généralise mal à des données non connues et présente une erreur de prédiction supérieure à celle du modèle linéaire simple. En effet, les variations de la courbe polynomiale qui lui permettait de coller au plus près des données sur lesquelles elle a été construite entraîne beaucoup de prédictions très éloignées de la vraie valeur des nouvelles données.&lt;br&gt;
L'erreur attendue d'un modèle de prédiction sur des données sur lesquelles il ne s'est pas entraîné peut en effet se décomposer en &lt;strong&gt;la somme du biais au carré et de la variance de ce modèle, c'est la décomposition biais-variance de l'erreur quadratique&lt;/strong&gt;. Si vous préférez vous en convaincre avec la formule et la démonstration mathématique, vous pouvez vous référer à &lt;a href="https://fr.wikipedia.org/wiki/Dilemme_biais-variance#Décomposition_biais-variance_de_l'erreur_quadratique"&gt;la page wikipédia qui en parle&lt;/a&gt;. Comme le biais diminue avec la variance, il faut donc trouver un niveau de complexité du modèle qui permette à la fois de minimiser l'écart à la vraie valeur (faible biais en augmentant la variance) et d'être généralisable en dehors de son échantillon d'entraînement (faible variance).&lt;/p&gt;
&lt;h1 id="liens-avec-loverfitting-et-lunderfitting-dans-les-modeles-de-machine-learning"&gt;Liens avec l'overfitting et l'underfitting dans les modèles de Machine Learning&lt;/h1&gt;
&lt;h2 id="appelons-un-chat-un-chat"&gt;Appelons un chat un chat&lt;/h2&gt;
&lt;p&gt;Le principe de l'apprentissage automatique supervisé est le même que celui qu'on a présenté jusqu'à maintenant : on renseigne au modèle des variables explicatives (&lt;code&gt;X&lt;/code&gt;) et une variable d'intérêt (&lt;code&gt;Y&lt;/code&gt;) qu'on aimerait pouvoir ensuite prédire à partir de nouvelles données &lt;code&gt;X&lt;/code&gt;. Par exemple, on renseigne des photos de chats et de chiens étiquettées : &lt;code&gt;Y&lt;/code&gt; est alors le label "chien" ou "chat" de la photo, &lt;code&gt;X&lt;/code&gt; la matrice de pixels de la photo. Le modèle devra être ensuite capable de prédire à partir d'une photo qu'il n'a jamais vue si celle-ci représente un chat ou un chien. Pour mesurer la qualité prédictive de notre modèle, on réserve des données labellisées sur lesquelles il ne s'entraînera pas. On va ensuite lui demander de prédire les labels déjà connus de ces données, ce qui va nous permettre d'évaluer la qualité de ces prédictions. Cet échantillon est en général appelé &lt;strong&gt;échantillon test&lt;/strong&gt; (&lt;em&gt;test set&lt;/em&gt; en anglais), et les données sur lesquelles le modèle est entraîné s'appelle l'&lt;strong&gt;échantillon d'entraînement&lt;/strong&gt; (&lt;em&gt;train set&lt;/em&gt;). En général, si l'on dispose de suffisamment de données, on n'aura pas trop de mal à construire un modèle qui parviendra à labelliser quasiment parfaitement &lt;strong&gt;nos données d'entraînement&lt;/strong&gt;. Tout le problème est d'avoir un modèle qui se généralise correctement à de nouvelles données.&lt;/p&gt;
&lt;h2 id="courbe-dapprentissage-dun-modele"&gt;Courbe d'apprentissage d'un modèle&lt;/h2&gt;
&lt;p&gt;Pour schématiser, imaginons que dans les données d'entraînement les chiens soient en général photographiées à l'extérieur et les chats à l'intérieur. Si mon modèle a une forte variance, cela signifie qu'il va prendre en compte beaucoup de détails de la photo. Il va par exemple donner du poids aux éléments de fond dans sa prédiction et sera incapable de labelliser correctement un chien photographié à l'intérieur. Un modèle bien plus basique qui se serait appuyé par exemple uniquement sur la forme des oreilles de l'animal aurait peut-être de meilleurs résultats.&lt;br&gt;
Dans le premier cas, on dit que l'on est dans une situation de &lt;strong&gt;surapprentissage, ou overfitting&lt;/strong&gt;. Le modèle a intégré des éléments anecdotiques, du bruit, dans son processus décisionnel et cela va réduire sa performance prédictive sur des données non connues. Autrement dit, &lt;strong&gt;sa variance est trop élevée&lt;/strong&gt;. Si au contraire le modèle est trop peu complexe et n'a pas intégré assez d'informations pour différencier un chat d'un chien même sur les données d'apprentissage, on dit qu'il est dans un état de &lt;strong&gt;sous-apprentissage, ou underfitting&lt;/strong&gt;.&lt;br&gt;
&lt;strong&gt;Dans les deux cas, le modèle va avoir de mauvaises performances prédictives sur des nouvelles données&lt;/strong&gt;. Ce constat peut être schématisé de la manière suivante :&lt;/p&gt;
&lt;p&gt;&lt;img alt="Pelican" src="../images/biais_variance/courb_apprent.png"&gt;  &lt;/p&gt;
&lt;p&gt;Notons bien ici que cette relation entre complexité du modèle et décomposition de l'erreur de prédiction s'entend &lt;strong&gt;à taille d'échantillon fixée&lt;/strong&gt;. Ainsi, plus l'échantillon sera grand, plus le modèle pourra être complexe avant d'entrer dans la phase de surapprentissage.  &lt;/p&gt;
&lt;h1 id="conclusion"&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;Dans le cadre d'une &lt;strong&gt;démarche prédictive&lt;/strong&gt;, il est donc tout à fait naturel de limiter l'apprentissage du modèle pour optimiser ses capacités prédictives. Cela peut être fait en réduisant le nombre de variables prédictives utilisées, en limitant le nombre de couches de neurones dans un réseau, mais aussi en utilisant des méthodes de réduction des dimensions, comme &lt;a href="https://blog.statoscop.fr/acp-python.html"&gt;nous vous l'avions montré avec l'analyse en composantes principales&lt;/a&gt;. Bien sûr, dans une &lt;strong&gt;démarche explicative&lt;/strong&gt;, il sera au contraire normal de sacrifier éventuellement une meilleure capacité prédictive pour mettre en évidence une relation avec une variable explicative. Si vous souhaitez aller plus loin, vous pouvez parcourir l'excellente étude de &lt;a href="https://www.stat.berkeley.edu/~aldous/157/Papers/shmueli.pdf"&gt;Shmueli, 2010&lt;/a&gt; qui expose les enjeux croisés des démarches explicative et prédictive dans la modélisation.&lt;br&gt;
Il me reste à remercier &lt;a href="https://twitter.com/EParoissien"&gt;Emmanuel Paroissien&lt;/a&gt;, chercheur à l'Inra, pour nos échanges qui m'ont aidé à construire cette note. N'hésitez pas à &lt;a href="https://www.statoscop.fr"&gt;visiter notre site&lt;/a&gt; et à nous suivre sur &lt;a href="https://twitter.com/stato_scop"&gt;Twitter&lt;/a&gt; et &lt;a href="https://www.linkedin.com/company/statoscop"&gt;Linkedin&lt;/a&gt;. Pour retrouver le code ayant servi à générer cette note, vous pouvez vous rendre sur le &lt;a href="https://github.com/Statoscop/notebooks-blog"&gt;dépôt github de nos notes de blog&lt;/a&gt;.  &lt;/p&gt;</content><category term="R"></category><category term="R"></category><category term="Rstats"></category><category term="data science"></category><category term="statistiques"></category><category term="Machine Learning"></category></entry><entry><title>Analyse en composantes principales avec Python</title><link href="https://blog.statoscop.fr/acp-python.html" rel="alternate"></link><published>2021-04-16T00:00:00+02:00</published><updated>2021-04-16T00:00:00+02:00</updated><author><name>Antoine</name></author><id>tag:blog.statoscop.fr,2021-04-16:/acp-python.html</id><summary type="html">&lt;p&gt;Présentation et exemples d'utilisation de l'ACP en statistiques et data science.&lt;/p&gt;</summary><content type="html">&lt;div class="toc"&gt;&lt;span class="toctitle"&gt;Table des matières&lt;/span&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#explication-introductive"&gt;Explication introductive&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#mise-en-oeuvre-dune-acp"&gt;Mise en oeuvre d'une ACP&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#analyse-exploratoire-de-nos-donnees"&gt;Analyse exploratoire de nos données&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#utilisation-de-lacp-pour-la-reduction-de-dimensions"&gt;Utilisation de l'ACP pour la réduction de dimensions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;Dans cet article, nous allons essayer de comprendre intuitivement comment fonctionne l'analyse en composantes principales. Nous présenterons ensuite à quoi celle-ci peut servir en prenant les exemples d'une analyse exploratoire des données et d'une problématique de réduction de dimension.   &lt;/p&gt;
&lt;h1 id="explication-introductive"&gt;Explication introductive&lt;/h1&gt;
&lt;p&gt;L'analyse en composantes principales est une méthode consistant à transformer des variables corrélées entre elles en nouvelles variables. Chacune de ces nouvelles variables est le résultat d'une combinaison linéaire des anciennes variables. &lt;/p&gt;
&lt;p&gt;&lt;em&gt;Note : une combinaison linéaire de 3 variables &lt;span class="math"&gt;\(V_1\)&lt;/span&gt;, &lt;span class="math"&gt;\(V_2\)&lt;/span&gt; et &lt;span class="math"&gt;\(V_3\)&lt;/span&gt; s'écrit &lt;span class="math"&gt;\(\alpha_1.V_1 + \alpha_2.V_2 + \alpha_3.V_3\)&lt;/span&gt; où les &lt;span class="math"&gt;\(\alpha_i\)&lt;/span&gt; sont des coefficients réels.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Ces nouvelles variables sont appelées &lt;strong&gt;composantes principales&lt;/strong&gt; et sont, par contruction, décorrélées les unes des autres.  &lt;/p&gt;
&lt;p&gt;Autrement dit, l'ACP projette vos données dans un nouvel espace. La première composante principale est construite de manière à capter la plus grande variance possible de vos données, la seconde la part la plus importante de la variance possible &lt;strong&gt;restant à expliquer&lt;/strong&gt;, et ainsi de suite.  &lt;/p&gt;
&lt;p&gt;Une illustration brillante de ce processus est proposée par &lt;a href="https://www.allisonhorst.com/" target="_blank"&gt;Allison Horst&lt;/a&gt;. Elle &lt;a href="https://twitter.com/allison_horst/status/1288904459490213888" target="_blank"&gt;représente&lt;/a&gt; un jeu de données à deux dimensions avec des crevettes et l'analyse en composantes principales comme les passages d'un requin-baleine affamé :  &lt;/p&gt;
&lt;p&gt;&lt;img alt="Pelican" src="../images/acp/output_3_0.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="Pelican" src="../images/acp/output_4_0.png"&gt;&lt;/p&gt;
&lt;p&gt;La problématique du requin-baleine est en effet la même que celle de la création d'une première composante principale : quel axe choisir pour avaler un maximum de crevettes dès le premier passage? L'axe choisi va ressembler à celui-ci :  &lt;/p&gt;
&lt;p&gt;&lt;img alt="Pelican" src="../images/acp/output_6_0.png"&gt;&lt;/p&gt;
&lt;p&gt;Il s'agit pour le requin de choisir la droite de sorte qu'il y ait un maximum de crevettes sur son parcours ce qui revient à ce que les crevettes soient le plus proche possible de cette droite. Mathématiquement, la première composante principale est la combinaison linéaire des deux axes &lt;span class="math"&gt;\(x\)&lt;/span&gt; et &lt;span class="math"&gt;\(y\)&lt;/span&gt; qui maximise l'inertie projetée ce qui revient à minimiser les écarts entre les points et cette droite.&lt;/p&gt;
&lt;p&gt;Dans cet exemple, la seconde composante principale sera l'axe perpendiculaire à ce premier axe.&lt;/p&gt;
&lt;p&gt;Si les points étaient parfaitement alignés sur une ligne, l'ensemble de la variance serait expliqué par la première composante et on serait parvenus à réduire le nombre de dimensions de notre problème sans perte d'information.&lt;/p&gt;
&lt;h1 id="mise-en-oeuvre-dune-acp"&gt;Mise en oeuvre d'une ACP&lt;/h1&gt;
&lt;p&gt;D'accord, on a projeté notre jeu de données dans un nouvel espace avec des nouvelles "variables" décrites comme combinaisons linéaires des précédentes telles que la première explique la plus grande partie de la variance possible, la seconde la plus grande partie de la variance restant à expliquer, etc... Mais ça nous sert à quoi?   &lt;/p&gt;
&lt;h2 id="analyse-exploratoire-de-nos-donnees"&gt;Analyse exploratoire de nos données&lt;/h2&gt;
&lt;p&gt;La caractéristique des composantes principales par rapport au jeu de données non transformé est que les premières composantes principales ont un fort pouvoir discriminant, puisqu'elles expliquent une grande partie de la variance totale du jeu de données. Ainsi, représenter notre jeu de données par rapport aux deux premiers axes de l'ACP peut permettre de vérifier que ces données permettent bien de distinguer différentes classes.  &lt;/p&gt;
&lt;p&gt;Prenons comme exemple la base de données &lt;code&gt;wine&lt;/code&gt; que l'on peut charger directement depuis le module &lt;code&gt;sklearn&lt;/code&gt;. Cette base de données contient des résultats d'analyses chimiques de 178 vins de 3 différents producteurs. Ces résultats sont synthétisés par 13 mesures différentes que l'on retrouve dans les données. Pour voir si ces mesures permettent ou non de distinguer les vins des trois producteurs, nous allons commencer par représenter les vins sur l'espace des deux premières composantes principales. Pour cela, on importe les données et on les centre-réduit avant d'appliquer notre ACP avec la fonction &lt;code&gt;sklearn.decomposition.PCA&lt;/code&gt;. On paramètre celle-ci pour qu'elle nous renvoie seulement les deux premières composantes :  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="c1"&gt;# Import fonction ACP&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.decomposition&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;PCA&lt;/span&gt;

&lt;span class="c1"&gt;# Import données&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.datasets&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;load_wine&lt;/span&gt;

&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;target&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;load_wine&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;return_X_y&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;target_names&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;load_wine&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;target_names&lt;/span&gt;
&lt;span class="n"&gt;feature_names&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;load_wine&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;feature_names&lt;/span&gt;
&lt;span class="c1"&gt;# on standardise nos données : &lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.preprocessing&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;StandardScaler&lt;/span&gt;
&lt;span class="n"&gt;values_cr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;StandardScaler&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# On paramètre notre PCA pour garder les deux premières composantes&lt;/span&gt;
&lt;span class="n"&gt;pca&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;PCA&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;pca_wine&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pca&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;values_cr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# en sortie : le même nombre de lignes que les données en entrées&lt;/span&gt;
&lt;span class="c1"&gt;# et le nombre de variables correspondant au nombre de composantes&lt;/span&gt;
&lt;span class="c1"&gt;# conservées&lt;/span&gt;
&lt;span class="n"&gt;pca_wine&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="err"&gt;(178, 2)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;En sortie, nous obtenons les vecteurs des deux premières composantes dans l'objet &lt;code&gt;pca_wine&lt;/code&gt;. Notons que nous aurions pu paramétrer la fonction &lt;code&gt;PCA&lt;/code&gt; de manière à ce qu'elle nous renvoie le nombre de composantes nécessaire à expliquer &lt;code&gt;X&lt;/code&gt;% de la variance, comme nous le ferons par la suite. Depuis l'objet &lt;code&gt;pca&lt;/code&gt;, on peut voir le vecteur de la variance expliquée par chaque composante avec &lt;code&gt;pca.explained_variance_ratio_&lt;/code&gt; et donc la variance totale expliquée par nos deux composantes en sommant les éléments de ce vecteur :  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;pca&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;explained_variance_ratio_&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="err"&gt;0.554063383569353&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;On explique donc 55 % de la variance totale de nos données avec 2 composantes, alors que celle-ci contient 13 variables. Voyons si cela suffit à discriminer nos 3 producteurs visuellement :  &lt;/p&gt;
&lt;!--- ![Pelican](../images/acp/output_13_0.png)--&gt;
&lt;p&gt;&lt;img alt="Pelican" src="../images/acp/output_13_0.png" style="max-width:80% !important" &gt;&lt;/p&gt;
&lt;p&gt;On constate ici que les 3 producteurs sont bien répartis dans des zones distinctes du plan et ce résultat semble montrer que chacun produit des types de vin caractéristiques.&lt;/p&gt;
&lt;p&gt;On peut se convaincre que l'ACP a bien joué son rôle en produisant le même type de schéma avec deux autres variables originales du jeu de données (sans transformation linéaire), disons le degré d'alcool et l'intensité de la couleur. On s'attend bien sûr à ce que les classes soient moins discriminées qu'avec les deux premières composantes principales :  &lt;/p&gt;
&lt;p&gt;&lt;img alt="Pelican" src="../images/acp/output_15_0.png" style="max-width:80% !important" &gt;&lt;/p&gt;
&lt;p&gt;Ces variables permettent de distinguer des tendances, comme le fait que le producteur 1 produit des vins plutôt moins alcoolisés et dont la couleur est peu intense alors que le producteur 0 produit des vins plus alcoolisés. Mais ces variables seules ne permettent pas de partitionner nos classes aussi clairement qu'avec les deux premières composantes de notre ACP.   &lt;/p&gt;
&lt;p&gt;L'ACP ne permet certes pas au premier coup d'oeil de proposer une interprétation des résultats, mais il est néanmoins possible d'étudier comment chaque variable contribue aux composantes avec l'instruction &lt;code&gt;pca.components_&lt;/code&gt; :  &lt;/p&gt;
&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Noms des variables&lt;/th&gt;
      &lt;th&gt;Composante 1&lt;/th&gt;
      &lt;th&gt;Composante 2&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;alcohol&lt;/td&gt;
      &lt;td&gt;0.144329&lt;/td&gt;
      &lt;td&gt;-0.483652&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;malic_acid&lt;/td&gt;
      &lt;td&gt;-0.245188&lt;/td&gt;
      &lt;td&gt;-0.224931&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;ash&lt;/td&gt;
      &lt;td&gt;-0.002051&lt;/td&gt;
      &lt;td&gt;-0.316069&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;alcalinity_of_ash&lt;/td&gt;
      &lt;td&gt;-0.239320&lt;/td&gt;
      &lt;td&gt;0.010591&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;magnesium&lt;/td&gt;
      &lt;td&gt;0.141992&lt;/td&gt;
      &lt;td&gt;-0.299634&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;5&lt;/th&gt;
      &lt;td&gt;total_phenols&lt;/td&gt;
      &lt;td&gt;0.394661&lt;/td&gt;
      &lt;td&gt;-0.065040&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;6&lt;/th&gt;
      &lt;td&gt;flavanoids&lt;/td&gt;
      &lt;td&gt;0.422934&lt;/td&gt;
      &lt;td&gt;0.003360&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;7&lt;/th&gt;
      &lt;td&gt;nonflavanoid_phenols&lt;/td&gt;
      &lt;td&gt;-0.298533&lt;/td&gt;
      &lt;td&gt;-0.028779&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;8&lt;/th&gt;
      &lt;td&gt;proanthocyanins&lt;/td&gt;
      &lt;td&gt;0.313429&lt;/td&gt;
      &lt;td&gt;-0.039302&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;9&lt;/th&gt;
      &lt;td&gt;color_intensity&lt;/td&gt;
      &lt;td&gt;-0.088617&lt;/td&gt;
      &lt;td&gt;-0.529996&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;10&lt;/th&gt;
      &lt;td&gt;hue&lt;/td&gt;
      &lt;td&gt;0.296715&lt;/td&gt;
      &lt;td&gt;0.279235&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;11&lt;/th&gt;
      &lt;td&gt;od280/od315_of_diluted_wines&lt;/td&gt;
      &lt;td&gt;0.376167&lt;/td&gt;
      &lt;td&gt;0.164496&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;12&lt;/th&gt;
      &lt;td&gt;proline&lt;/td&gt;
      &lt;td&gt;0.286752&lt;/td&gt;
      &lt;td&gt;-0.364903&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;Ce tableau représente les coefficients de la combinaison linéaire des variables pour chaque composante. Il nous permet par exemple de constater que l'intensité de la couleur et l'alcool jouent fortement et négativement sur la seconde composante. Cela correspond à ce que l'on observait dans les deux graphiques précédents puisque les vins des producteurs 0 et 2 ont des valeurs négatives sur l'axe de la seconde composante (1er graphique) et ce sont bien ceux dont le taux en alcool et l'intensité de la couleur sont les plus importants (2e graphique)&lt;/p&gt;
&lt;h2 id="utilisation-de-lacp-pour-la-reduction-de-dimensions"&gt;Utilisation de l'ACP pour la réduction de dimensions&lt;/h2&gt;
&lt;p&gt;La propriété de l'ACP de capter une partie importante de la variance des données à partir de moins de variables est particulièrement intéressante dans le domaine du Machine Learning pour être capable de fournir des prédictions avec des modèles plus légers (car utilisant moins de variables) et des résultats au moins aussi performants.&lt;br&gt;
Pour notre exemple, même si la réduction de dimensions n'est pas un enjeu fondamental vu le faible nombre de variables, nous pouvons tester si nous parvenons à faire un modèle de prédiction de l'origine du vin (producteur 0, 1 ou 2) en réduisant le nombre de dimensions.&lt;br&gt;
Tout d'abord, commençons par déterminer ce nombre de dimensions. Le graphique suivant nous donne l'évolution de la variance expliquée en fonction du nombre de composantes :   &lt;/p&gt;
&lt;p&gt;&lt;img alt="Pelican" src="../images/acp/output_20_0.png" style="max-width:80% !important" &gt;&lt;/p&gt;
&lt;p&gt;L'ACP permettrait d'expliquer plus de 70% de la variance totale dès 4 composantes. Pour voir si cela est suffisant pour entraîner un modèle de prédiction, on peut comparer les performances d'un arbre de classification sur les données transformées après PCA et sur les données brutes. On utilise une méthode de validation croisée pour estimer les performances du modèle qui consiste à partitionner les données en 5 groupes et à entraîner les données sur 4 groupes et les tester sur celui restant. On fait cela 5 fois pour parcourir le champ des possibles et on évalue la précision globale du modèle en faisant la moyenne de ces 5 résultats. Cette méthode doit permettre d'estimer la qualité du modèle sur des données sur lesquelles il n'a pas été entraîné et de ne pas prendre en compte le surapprentissage dans son évaluation. Le tableau suivant donne les taux de précision obtenus pour chaque méthode, c'est à dire le nombre de vins correctement classifiés sur le nombre de vins total.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# Plutôt que de renseigner le nombre de composantes &lt;/span&gt;
&lt;span class="c1"&gt;# on renseigne la valeur minimum de la variance &lt;/span&gt;
&lt;span class="c1"&gt;# expliquée totale que l&amp;#39;on souhaite&lt;/span&gt;
&lt;span class="n"&gt;pca&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;PCA&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.70&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; 
&lt;span class="n"&gt;wine_pca&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pca&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_transform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;values_cr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# On entraîne notre modèle et on l&amp;#39;évalue avec une &lt;/span&gt;
&lt;span class="c1"&gt;# méthode de validation croisée &lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.model_selection&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;cross_val_score&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.tree&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;DecisionTreeClassifier&lt;/span&gt;
&lt;span class="n"&gt;clf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;DecisionTreeClassifier&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;mean_pca&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cross_val_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;clf&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;wine_pca&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;target&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cv&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;mean_all&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cross_val_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;clf&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;target&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cv&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Précision moyenne après ACP&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;mean_pca&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; 
              &lt;span class="s2"&gt;&amp;quot;Précision moyenne sans ACP&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;mean_all&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; 
              &lt;span class="s2"&gt;&amp;quot;Nombre de composantes&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;wine_pca&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]]})&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe"&gt;
  &lt;thead&gt;
    &lt;tr style="text-align: right;"&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Précision moyenne après ACP&lt;/th&gt;
      &lt;th&gt;Précision moyenne sans ACP&lt;/th&gt;
      &lt;th&gt;Nombre de composantes&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;0.933175&lt;/td&gt;
      &lt;td&gt;0.887619&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;On constate que l'ACP n'a pas seulement permis de réduire le nombre de dimensions de notre problème, elle nous offre aussi une précision globale du modèle supérieure. Cela n'est pas toujours le cas - puisque ça dépend de votre problématique, des variables explicatives dont vous disposez et du nombre de composantes que vous retenez - mais ici c'est dû au fait qu'elle permet de réduire le bruit associé aux données en ne conservant qu'une partie de l'information totale. Cela permet ainsi de prévenir les problèmes de surapprentissage, c'est à dire le fait que le modèle explique parfaitement les données d'entraînement mais se généralise mal à de nouvelles données. Ce sujet est abordé dans &lt;a href="https://blog.statoscop.fr/larbitrage-biaisvariance-dans-la-modelisation-de-donnees.html"&gt;cet article de notre blog sur l'arbitrage biais/variance&lt;/a&gt;.  &lt;/p&gt;
&lt;p&gt;C'est tout pour aujourd'hui! Si vous voulez voir d'autres exemples d'utilisation de l'ACP, je vous conseille &lt;a href="https://jakevdp.github.io/PythonDataScienceHandbook/05.09-principal-component-analysis.html" target="_blank"&gt;cet article&lt;/a&gt; qui aborde notamment le cas du traitement des images, pour lequel il est particulièrement intéressant de réduire le nombre de dimensions. N'hésitez pas à &lt;a href="https://www.statoscop.fr"&gt;visiter notre site&lt;/a&gt; et à nous suivre sur &lt;a href="https://twitter.com/stato_scop"&gt;Twitter&lt;/a&gt; pour ne pas rater les prochains articles! Vous pouvez trouver le notebook avec l'ensemble du code ayant servi à générer cette note sur le &lt;a href="https://github.com/Statoscop/notebooks-blog" target="_blank"&gt;github de Statoscop&lt;/a&gt;.   &lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="Python"></category><category term="Python"></category><category term="Machine Learning"></category><category term="Statistiques"></category><category term="Data Science"></category></entry></feed>