<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Le blog - R</title><link href="https://blog.statoscop.fr/" rel="alternate"></link><link href="https://blog.statoscop.fr/feeds/r.atom.xml" rel="self"></link><id>https://blog.statoscop.fr/</id><updated>2021-11-08T00:00:00+01:00</updated><entry><title>L'arbitrage biais/variance dans la modélisation de données</title><link href="https://blog.statoscop.fr/larbitrage-biaisvariance-dans-la-modelisation-de-donnees.html" rel="alternate"></link><published>2021-11-08T00:00:00+01:00</published><updated>2021-11-08T00:00:00+01:00</updated><author><name>Antoine</name></author><id>tag:blog.statoscop.fr,2021-11-08:/larbitrage-biaisvariance-dans-la-modelisation-de-donnees.html</id><summary type="html">&lt;p&gt;Présentation des enjeux théoriques et pratiques de l'arbitrage biais/variance dans la construction d'un modèle de prédiction.&lt;/p&gt;</summary><content type="html">&lt;div class="toc"&gt;&lt;span class="toctitle"&gt;Table des matières&lt;/span&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#que-sont-le-biais-et-la-variance"&gt;Que sont le biais et la variance?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#enjeux-de-larbitrage-biaisvariance"&gt;Enjeux de l'arbitrage biais/variance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#liens-avec-loverfitting-et-lunderfitting-dans-les-modeles-de-machine-learning"&gt;Liens avec l'overfitting et l'underfitting dans les modèles de Machine Learning&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#appelons-un-chat-un-chat"&gt;Appelons un chat un chat&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#courbe-dapprentissage-dun-modele"&gt;Courbe d'apprentissage d'un modèle&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#conclusion"&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;L'arbitrage biais/variance est souvent évoqué pour caractériser les enjeux de la construction d'un modèle de prédiction performant. L'idée de cet article est d'essayer de donner au lecteur les outils théoriques de cette question en essayant de privilégier une approche intuitive et pratique du problème. Après avoir défini ce que sont le biais et la variance, on présente les enjeux de cet arbitrage puis l'application concrète dans le cas de l'entraînement d'un modèle de Machine Learning.&lt;/p&gt;
&lt;h1 id="que-sont-le-biais-et-la-variance"&gt;Que sont le biais et la variance?&lt;/h1&gt;
&lt;p&gt;Pour expliquer le plus simplement possible ces concepts, on se place dans le contexte de l'observation de deux variables &lt;code&gt;Y&lt;/code&gt; et &lt;code&gt;X&lt;/code&gt;. Dans le cas d'une modélisation d'une relation entre &lt;code&gt;X&lt;/code&gt; et &lt;code&gt;Y&lt;/code&gt;, le biais d'un estimateur est son écart avec sa "vraie" valeur si on observait parfaitement la relation entre ces variables. On entend donc le biais comme &lt;strong&gt;l'écart entre la fonction modélisée et la fonction théorique&lt;/strong&gt; qui permettrait de restituer le lien entre &lt;code&gt;X&lt;/code&gt; et &lt;code&gt;Y&lt;/code&gt;. &lt;/p&gt;
&lt;p&gt;Une manière de jouer sur le biais d'un modèle c'est de modifier sa variance. La variance est une mesure de dispersion de valeurs, qui donne une estimation de l'écart de celles-ci à leur moyenne. La variance d'un modèle estime &lt;strong&gt;à quel point celui-ci fluctue autour de sa moyenne pour coller aux données&lt;/strong&gt;. Une mesure utilisée couramment dans le cas des régressions linéaires est le coefficient de détermination R2. Celui-ci calcule &lt;strong&gt;la part de la variance des données expliquée par la variance du modèle&lt;/strong&gt;. Autrement dit, plus mon modèle sera proche des points de mes données, plus sa variance et donc le R2 seront élevés. Pour illustrer ce concept, on présente plusieurs modèles appliqués au même jeu de données avec une variance plus ou moins élevée :&lt;/p&gt;
&lt;p&gt;&lt;img alt="Pelican" src="../images/biais_variance/unnamed-chunk-1-1.png"&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Pour chaque modèle, la courbe du modèle est celle qui apparaît en rouge et on a mis en évidence en vert la projection de chaque point sur sa valeur prédite par le modèle. Voyons comment interpréter ces graphiques :  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Le 1er modèle est un modèle naïf qui se contente de prédire que pour chaque valeur de &lt;code&gt;X&lt;/code&gt;, &lt;code&gt;Y&lt;/code&gt; sera égale à sa moyenne. Par définition donc, sa variance est nulle et sa capacité prédictive faible.  &lt;/li&gt;
&lt;li&gt;Le second modèle est une régression linéaire simple qui a un R2 d'environ 50%. Il a donc une meilleure qualité prédictive que le premier modèle du fait qu'il capte une partie de la variance des données, ici à travers une corrélation positive entre &lt;code&gt;X&lt;/code&gt; et &lt;code&gt;Y&lt;/code&gt;.  &lt;/li&gt;
&lt;li&gt;Le troisième modèle est un modèle polynomial dont on voit qu'il est plus ajusté que le second. Les points prédits (en vert) par la courbe sont en effet plus proche des points que pour le précédent modèle et mécaniquement cela fait augmenter le R2. Le fait d'utiliser un modèle polynomial a donné au modèle une plus grande souplesse ce qui lui a permis de se rapprocher de certains points extrêmes qui étaient éloignés de la droite de régression du second modèle.  &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ainsi, plus la variance augmente, plus le modèle prédit en moyenne des valeurs proches de leurs vraies valeurs, ce qui fait diminuer le biais, puisqu'il est défini comme l'écart entre notre fonction de prédiction et une fonction qui permettrait de prédire parfaitement les données observées.  &lt;/p&gt;
&lt;h1 id="enjeux-de-larbitrage-biaisvariance"&gt;Enjeux de l'arbitrage biais/variance&lt;/h1&gt;
&lt;p&gt;D'après ce qu'on a vu, pourquoi alors ne pas simplement chercher à maximiser la variance pour minimiser le biais, c'est-à-dire son écart aux vraies valeurs? Tout simplement parce que dans le cas de la construction d'un modèle de prédiction, nous modélisons des relations entre des données à partir d'un échantillon pour prédire un résultat sur une nouvelle population. C'est donc la performance de ce modèle sur de nouvelles données qui va nous intéresser. Or, comme vous avez pu le pressentir en observant les graphiques précédents, &lt;strong&gt;un modèle avec une variance très élevée se généralise mal à de nouvelles données&lt;/strong&gt;. D'un autre côté, &lt;strong&gt;un modèle avec une faible variance aura lui aussi une qualité prédictive très faible&lt;/strong&gt; car il captera mal une éventuelle relation entre les variables.&lt;/p&gt;
&lt;p&gt;Tout le problème de cet arbitrage (ou dilemme) biais-variance est donc de &lt;strong&gt;trouver un modèle qui ait une variance suffisamment forte pour limiter le biais mais suffisamment faible pour qu'il soit généralisable&lt;/strong&gt;. Les modèles précédents avaient été entraînés sur une base de données qui était un échantillon aléatoire correspondant à 10% des données d'un échantillon plus important. Pour mesurer la qualité prédictive de ces modèles on les applique donc aux données entières et on calcule l'écart moyen au carré de la prédiction à la vraie valeur, c'est-à-dire l'erreur quadratique moyenne ou en anglais &lt;strong&gt;MSE&lt;/strong&gt; pour &lt;em&gt;Mean Squared Error&lt;/em&gt; :&lt;/p&gt;
&lt;p&gt;&lt;img alt="Pelican" src="../images/biais_variance/unnamed-chunk-2-1.png"&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;On constate que, comme attendu, le modèle avec le plus de variance se généralise mal à des données non connues et présente une erreur de prédiction supérieure à celle du modèle linéaire simple. En effet, les variations de la courbe polynomiale qui lui permettait de coller au plus près des données sur lesquelles elle a été construite entraîne beaucoup de prédictions très éloignées de la vraie valeur des nouvelles données.&lt;br&gt;
L'erreur attendue d'un modèle de prédiction sur des données sur lesquelles il ne s'est pas entraîné peut en effet se décomposer en &lt;strong&gt;la somme du biais au carré et de la variance de ce modèle, c'est la décomposition biais-variance de l'erreur quadratique&lt;/strong&gt;. Si vous préférez vous en convaincre avec la formule et la démonstration mathématique, vous pouvez vous référer à &lt;a href="https://fr.wikipedia.org/wiki/Dilemme_biais-variance#Décomposition_biais-variance_de_l'erreur_quadratique"&gt;la page wikipédia qui en parle&lt;/a&gt;. Comme le biais diminue avec la variance, il faut donc trouver un niveau de complexité du modèle qui permette à la fois de minimiser l'écart à la vraie valeur (faible biais en augmentant la variance) et d'être généralisable en dehors de son échantillon d'entraînement (faible variance).&lt;/p&gt;
&lt;h1 id="liens-avec-loverfitting-et-lunderfitting-dans-les-modeles-de-machine-learning"&gt;Liens avec l'overfitting et l'underfitting dans les modèles de Machine Learning&lt;/h1&gt;
&lt;h2 id="appelons-un-chat-un-chat"&gt;Appelons un chat un chat&lt;/h2&gt;
&lt;p&gt;Le principe de l'apprentissage automatique supervisé est le même que celui qu'on a présenté jusqu'à maintenant : on renseigne au modèle des variables explicatives (&lt;code&gt;X&lt;/code&gt;) et une variable d'intérêt (&lt;code&gt;Y&lt;/code&gt;) qu'on aimerait pouvoir ensuite prédire à partir de nouvelles données &lt;code&gt;X&lt;/code&gt;. Par exemple, on renseigne des photos de chats et de chiens étiquettées : &lt;code&gt;Y&lt;/code&gt; est alors le label "chien" ou "chat" de la photo, &lt;code&gt;X&lt;/code&gt; la matrice de pixels de la photo. Le modèle devra être ensuite capable de prédire à partir d'une photo qu'il n'a jamais vue si celle-ci représente un chat ou un chien. Pour mesurer la qualité prédictive de notre modèle, on réserve des données labellisées sur lesquelles il ne s'entraînera pas. On va ensuite lui demander de prédire les labels déjà connus de ces données, ce qui va nous permettre d'évaluer la qualité de ces prédictions. Cet échantillon est en général appelé &lt;strong&gt;échantillon test&lt;/strong&gt; (&lt;em&gt;test set&lt;/em&gt; en anglais), et les données sur lesquelles le modèle est entraîné s'appelle l'&lt;strong&gt;échantillon d'entraînement&lt;/strong&gt; (&lt;em&gt;train set&lt;/em&gt;). En général, si l'on dispose de suffisamment de données, on n'aura pas trop de mal à construire un modèle qui parviendra à labelliser quasiment parfaitement &lt;strong&gt;nos données d'entraînement&lt;/strong&gt;. Tout le problème est d'avoir un modèle qui se généralise correctement à de nouvelles données.&lt;/p&gt;
&lt;h2 id="courbe-dapprentissage-dun-modele"&gt;Courbe d'apprentissage d'un modèle&lt;/h2&gt;
&lt;p&gt;Pour schématiser, imaginons que dans les données d'entraînement les chiens soient en général photographiées à l'extérieur et les chats à l'intérieur. Si mon modèle a une forte variance, cela signifie qu'il va prendre en compte beaucoup de détails de la photo. Il va par exemple donner du poids aux éléments de fond dans sa prédiction et sera incapable de labelliser correctement un chien photographié à l'intérieur. Un modèle bien plus basique qui se serait appuyé par exemple uniquement sur la forme des oreilles de l'animal aurait peut-être de meilleurs résultats.&lt;br&gt;
Dans le premier cas, on dit que l'on est dans une situation de &lt;strong&gt;surapprentissage, ou overfitting&lt;/strong&gt;. Le modèle a intégré des éléments anecdotiques, du bruit, dans son processus décisionnel et cela va réduire sa performance prédictive sur des données non connues. Autrement dit, &lt;strong&gt;sa variance est trop élevée&lt;/strong&gt;. Si au contraire le modèle est trop peu complexe et n'a pas intégré assez d'informations pour différencier un chat d'un chien même sur les données d'apprentissage, on dit qu'il est dans un état de &lt;strong&gt;sous-apprentissage, ou underfitting&lt;/strong&gt;.&lt;br&gt;
&lt;strong&gt;Dans les deux cas, le modèle va avoir de mauvaises performances prédictives sur des nouvelles données&lt;/strong&gt;. Ce constat peut être schématisé de la manière suivante :&lt;/p&gt;
&lt;p&gt;&lt;img alt="Pelican" src="../images/biais_variance/courb_apprent.png"&gt;  &lt;/p&gt;
&lt;p&gt;Notons bien ici que cette relation entre complexité du modèle et décomposition de l'erreur de prédiction s'entend &lt;strong&gt;à taille d'échantillon fixée&lt;/strong&gt;. Ainsi, plus l'échantillon sera grand, plus le modèle pourra être complexe avant d'entrer dans la phase de surapprentissage.  &lt;/p&gt;
&lt;h1 id="conclusion"&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;Dans le cadre d'une &lt;strong&gt;démarche prédictive&lt;/strong&gt;, il est donc tout à fait naturel de limiter l'apprentissage du modèle pour optimiser ses capacités prédictives. Cela peut être fait en réduisant le nombre de variables prédictives utilisées, en limitant le nombre de couches de neurones dans un réseau, mais aussi en utilisant des méthodes de réduction des dimensions, comme &lt;a href="https://blog.statoscop.fr/acp-python.html"&gt;nous vous l'avions montré avec l'analyse en composantes principales&lt;/a&gt;. Bien sûr, dans une &lt;strong&gt;démarche explicative&lt;/strong&gt;, il sera au contraire normal de sacrifier éventuellement une meilleure capacité prédictive pour mettre en évidence une relation avec une variable explicative. Si vous souhaitez aller plus loin, vous pouvez parcourir l'excellente étude de &lt;a href="https://www.stat.berkeley.edu/~aldous/157/Papers/shmueli.pdf"&gt;Shmueli, 2010&lt;/a&gt; qui expose les enjeux croisés des démarches explicative et prédictive dans la modélisation.&lt;br&gt;
Il me reste à remercier &lt;a href="https://twitter.com/EParoissien"&gt;Emmanuel Paroissien&lt;/a&gt;, chercheur à l'Inra, pour nos échanges qui m'ont aidé à construire cette note. N'hésitez pas à &lt;a href="https://www.statoscop.fr"&gt;visiter notre site&lt;/a&gt; et à nous suivre sur &lt;a href="https://twitter.com/stato_scop"&gt;Twitter&lt;/a&gt; et &lt;a href="https://www.linkedin.com/company/statoscop"&gt;Linkedin&lt;/a&gt;. Pour retrouver le code ayant servi à générer cette note, vous pouvez vous rendre sur le &lt;a href="https://github.com/Statoscop/notebooks-blog"&gt;dépôt github de nos notes de blog&lt;/a&gt;.  &lt;/p&gt;</content><category term="R"></category><category term="R"></category><category term="Rstats"></category><category term="data science"></category><category term="statistiques"></category><category term="Machine Learning"></category></entry><entry><title>Gestion des packages sur R avec renv</title><link href="https://blog.statoscop.fr/gestion-des-packages-sur-r-avec-renv.html" rel="alternate"></link><published>2021-10-07T00:00:00+02:00</published><updated>2021-10-07T00:00:00+02:00</updated><author><name>Antoine</name></author><id>tag:blog.statoscop.fr,2021-10-07:/gestion-des-packages-sur-r-avec-renv.html</id><summary type="html">&lt;p&gt;Présentation du gestionnaire de packages de R&lt;/p&gt;</summary><content type="html">&lt;div class="toc"&gt;&lt;span class="toctitle"&gt;Table des matières&lt;/span&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#interet-dun-gestionnaire-de-packages-dans-un-projet-avec-r"&gt;Intérêt d'un gestionnaire de packages dans un projet avec R&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#organisation-du-projet"&gt;Organisation du projet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#avantages-dun-gestionnaire-de-packages-dans-un-projet-r"&gt;Avantages d'un gestionnaire de packages dans un projet R&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#votre-projet-sera-isole"&gt;Votre projet sera isolé&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#votre-projet-sera-portable-et-reproductible"&gt;Votre projet sera portable et reproductible&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#utilisation-de-renv"&gt;Utilisation de renv&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#initialisation-de-renv"&gt;Initialisation de renv&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#mettre-a-jour-les-dependances-avec-le-fichier-lock"&gt;Mettre à jour les dépendances avec le fichier lock&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#utilisation-de-renvrestore"&gt;Utilisation de renv::restore()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#utilisation-de-renvsnapshot"&gt;Utilisation de renv::snapshot()&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#petite-note-sur-git"&gt;Petite note sur git&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#conclusion"&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;En 2019, je présentais brièvement le package &lt;code&gt;packrat&lt;/code&gt; dans &lt;a href="https://antoinesir.rbind.io/post/gestion-des-packages-sur-r-pr%C3%A9sentation-de-packrat/"&gt;un article de blog&lt;/a&gt;. Ce package R permettait de gérer les dépendances aux packages d'un projet R à la manière des environnements de Python. Il comportait cependant un certain nombre d'inconvénients, dont celui d'un temps long de téléchargement des packages. Depuis 2020, il a été remplacé par &lt;code&gt;renv&lt;/code&gt; qui gomme la plupart de ces défauts, et c'est l'occasion de vous montrer pourquoi et comment vous devriez vous servir d'un gestionnaire de packages pour vos projets R à partir d'un exemple concret!&lt;/p&gt;
&lt;p&gt;On commence cet article par la présentation du projet dont on se sert comme exemple et de l'intérêt d'un gestionnaire de packages avant d'illustrer l'utilisation de &lt;code&gt;renv&lt;/code&gt; dans ce contexte. Cet article a pour but de présenter un cas concret d'utilisation de &lt;code&gt;renv&lt;/code&gt; mais ne se substitue pas à la &lt;a href="https://rstudio.github.io/renv/articles/renv.html"&gt;documentation officielle du package&lt;/a&gt;.  &lt;/p&gt;
&lt;h1 id="interet-dun-gestionnaire-de-packages-dans-un-projet-avec-r"&gt;Intérêt d'un gestionnaire de packages dans un projet avec R&lt;/h1&gt;
&lt;p&gt;La première étape pour aller vers plus de reproductibilité sur R est de connaître le fonctionnement des projets (fichiers .Rproj), qui permettent d'ouvrir R à la racine de votre projet et de proposer un code avec seulement des chemins relatifs. Si vous n'êtes pas du tout familiers avec ce fonctionnement, je vous conseille de lire &lt;a href="http://larmarange.github.io/analyse-R/organiser-ses-fichiers.html"&gt;cet article&lt;/a&gt; de l'excellent blog de Joseph Larmarange.  &lt;/p&gt;
&lt;h2 id="organisation-du-projet"&gt;Organisation du projet&lt;/h2&gt;
&lt;p&gt;On propose pour illustrer le propos un projet tout simple dont l'organisation est présentée ci-dessous :  &lt;/p&gt;
&lt;p&gt;&lt;img alt="Pelican" src="../images/renv/orga_dossier.png"&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Ce projet contient un dossier &lt;code&gt;data&lt;/code&gt; dans lequel se trouve notre base de données et un dossier &lt;code&gt;scripts&lt;/code&gt; avec un code R contenant quelques traitements basiques. À la racine du dossier, on remarque également notre fichier &lt;code&gt;Presentation renv.Rproj&lt;/code&gt; qui définit donc l'emplacement de notre répertoire de travail. Le script R contient les instructions suivantes :  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# Chargement des packages&lt;/span&gt;
&lt;span class="nf"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dplyr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Import des données&lt;/span&gt;
&lt;span class="n"&gt;mon_iris&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="n"&gt;data.table&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="nf"&gt;fread&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;data/iris.csv&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;results&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="n"&gt;mon_iris&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; 
  &lt;span class="nf"&gt;summarise&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;across&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;starts_with&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Sepal&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Ce code tout simple permet donc de calculer la moyenne des largeur et longueur des sépales de la base de données &lt;code&gt;iris&lt;/code&gt;. L'utilisation d'un fichier .Rproj, d'un chemin relatif pour importer les données et le fait que les deux packages utilisés (&lt;code&gt;dplyr&lt;/code&gt; et &lt;code&gt;data.table&lt;/code&gt;) soient chargés explicitement semblent rendre la reproductibilité des résultats aisée : il me suffit de récupérer l'ensemble du dossier, d'installer les deux packages s'ils ne sont pas déjà installés et de faire tourner le code. Seulement, je pourrais avoir sur mon poste une version de dplyr installée trop ancienne et dans laquelle &lt;code&gt;across&lt;/code&gt; n'existerait pas encore. Bien sûr il suffirait ici de mettre à jour mon package, mais peut-être que la version la plus récente de &lt;code&gt;dplyr&lt;/code&gt; ne correspond pas non plus à la version du code utilisé par la personne ayant écrit le code, et que cela peut causer de nouveaux problèmes...&lt;/p&gt;
&lt;h2 id="avantages-dun-gestionnaire-de-packages-dans-un-projet-r"&gt;Avantages d'un gestionnaire de packages dans un projet R&lt;/h2&gt;
&lt;p&gt;Tout d'abord, sachez qu'en général les développeurs de package R, et en particulier ceux ayant un très grand nombre d'utilisateurs, portent une attention particulière à faire en sorte que les mises à jour ne "cassent" pas les codes existants, en d'autres termes que ce qui a été codé dans une ancienne version du package tourne toujours avec la nouvelle version. Ceci étant dit, une mise à jour peut toujours avoir des conséquences sur vos résultats (anticipés ou non par les développeurs) et il est bien plus facile d'utiliser un gestionnaire de packages, et nous allons vous expliquer pourquoi.  &lt;/p&gt;
&lt;h3 id="votre-projet-sera-isole"&gt;Votre projet sera isolé&lt;/h3&gt;
&lt;p&gt;Avec le système classique de packages R, tous les packages installés le sont dans un répertoire commun à votre ordinateur. Quand vous mettez à jour un package, l'ancienne version est écrasée et ce pour &lt;strong&gt;tous&lt;/strong&gt; vos projets. Ce que va permettre un gestionnaire de packages, c'est de faire dépendre une version d'un package à un projet en particulier. C'est ce qui va permettre à chacun de vos projets d'être &lt;strong&gt;isolés&lt;/strong&gt; les uns des autres. En plus, &lt;code&gt;renv&lt;/code&gt; fonctionne sur un système de caches qui lui permet malgré tout de ne pas avoir à télécharger deux fois la même version du même package si elle est utilisée dans deux projets différents. Cette propriété est particulièrement importante pour des gros projets pour lesquels vous n'auriez pas le temps d'adapter le code à une mise à jour d'un package, tout en voulant bénéficier de cette mise à jour pour vos autres travaux.  &lt;/p&gt;
&lt;h3 id="votre-projet-sera-portable-et-reproductible"&gt;Votre projet sera portable et reproductible&lt;/h3&gt;
&lt;p&gt;La portabilité d'un projet, c'est sa capacité à pouvoir tourner sur n'importe quelle machine, n'importe quel OS, etc... C'est ce qui permet sa reproductibilité, c'est-à-dire la capacité à reproduire les résultats dans des conditions identiques. C'est extrêmement précieux pour les projets en équipe mais aussi pour soi : en effet rien ne nous assure que notre projet codé il y a deux ans va tourner après les nombreuses mises à jour qu'ont dû subir les packages utilisés. &lt;code&gt;renv&lt;/code&gt; permet de répondre à cette problématique en vous renvoyant 2 ans en arrière dans le même environnement de packages, à condition bien sûr que les versions utilisées alors soient encore disponibles sur le CRAN ou sur la source de laquelle vous les avez téléchargés.  &lt;/p&gt;
&lt;h1 id="utilisation-de-renv"&gt;Utilisation de renv&lt;/h1&gt;
&lt;p&gt;Après, je l'espère, vous avoir convaincu de l'utilité d'un gestionnaire de packages, je vais vous présenter rapidement comment utiliser &lt;code&gt;renv&lt;/code&gt; dans le petit projet que je vous ai présenté.  &lt;/p&gt;
&lt;h2 id="initialisation-de-renv"&gt;Initialisation de &lt;code&gt;renv&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;Pour commencer à utiliser le gestionnaire de packages, vous ouvrez votre projet dans RStudio et vous lancez dans la console &lt;code&gt;renv::init()&lt;/code&gt;. Votre projet va maintenant ressembler à ça :  &lt;/p&gt;
&lt;p&gt;&lt;img alt="Pelican" src="../images/renv/orga_dossier_renv.png"&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;On constate l'apparition d'un dossier &lt;code&gt;renv&lt;/code&gt;, qui contient les fichiers de lancement et de paramétrage du gestionnaire ainsi que les liens vers les packages à charger. Contrairement à &lt;code&gt;packrat&lt;/code&gt;, renv utilise en effet un cache dans lequel il installe les packages, ce qui permet de ne pas dupliquer l'installation de la même version du même package pour deux projets différents. Mais ce qui nous intéresse plus, c'est l'apparition à la racine du projet du fichier &lt;code&gt;renv.lock&lt;/code&gt;, qui ressemble à ça :  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="s"&gt;&amp;quot;R&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="s"&gt;&amp;quot;Version&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;4.1.1&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s"&gt;&amp;quot;Repositories&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
      &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="s"&gt;&amp;quot;Name&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;CRAN&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s"&gt;&amp;quot;URL&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;https://cloud.r-project.org&amp;quot;&lt;/span&gt;
      &lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;},&lt;/span&gt;
  &lt;span class="s"&gt;&amp;quot;Packages&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="s"&gt;&amp;quot;R6&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
      &lt;span class="s"&gt;&amp;quot;Package&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;R6&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="s"&gt;&amp;quot;Version&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;2.5.0&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="s"&gt;&amp;quot;Source&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Repository&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="s"&gt;&amp;quot;Repository&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;CRAN&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="s"&gt;&amp;quot;Hash&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;b203113193e70978a696b2809525649d&amp;quot;&lt;/span&gt;
    &lt;span class="p"&gt;},&lt;/span&gt;
    &lt;span class="s"&gt;&amp;quot;cli&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
      &lt;span class="s"&gt;&amp;quot;Package&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;cli&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="s"&gt;&amp;quot;Version&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;2.5.0&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="s"&gt;&amp;quot;Source&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Repository&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="s"&gt;&amp;quot;Repository&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;CRAN&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="s"&gt;&amp;quot;Hash&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;a94ba44cee3ea571e813721e64184172&amp;quot;&lt;/span&gt;
    &lt;span class="p"&gt;},&lt;/span&gt;
    &lt;span class="s"&gt;&amp;quot;crayon&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
      &lt;span class="s"&gt;&amp;quot;Package&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;crayon&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="s"&gt;&amp;quot;Version&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;1.4.1&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="s"&gt;&amp;quot;Source&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Repository&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="s"&gt;&amp;quot;Repository&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;CRAN&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="s"&gt;&amp;quot;Hash&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;e75525c55c70e5f4f78c9960a4b402e9&amp;quot;&lt;/span&gt;
    &lt;span class="p"&gt;},&lt;/span&gt;
    &lt;span class="s"&gt;&amp;quot;data.table&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
      &lt;span class="s"&gt;&amp;quot;Package&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;data.table&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="s"&gt;&amp;quot;Version&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;1.14.0&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="s"&gt;&amp;quot;Source&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Repository&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="s"&gt;&amp;quot;Repository&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;CRAN&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
      &lt;span class="s"&gt;&amp;quot;Hash&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;d1b8b1a821ee564a3515fa6c6d5c52dc&amp;quot;&lt;/span&gt;
    &lt;span class="p"&gt;},&lt;/span&gt;&lt;span class="kc"&gt;...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Le gestionnaire a repéré les packages utilisés dans mon script et a recensé toutes leurs informations utiles ainsi que celles de leurs dépendances : nom, version, source d'installation... Il renseigne aussi les caractéristiques du logiciel R installé sur mon poste. C'est à partir de ce fichier que le gestionnaire va ensuite être capable de vérifier l'adéquation de l'environnement de packages de l'utilisateur et celui enregistré le plus récemment. C'est aussi là qu'il va écrire les références des packages que j'installerai après avoir commencé à travailler sur le poste.  &lt;/p&gt;
&lt;p&gt;À noter que &lt;strong&gt;&lt;code&gt;renv&lt;/code&gt; peut aussi bien être utilisé au lancement de votre projet qu'au cours de celui-ci&lt;/strong&gt;. S'il est utilisé au lancement, vous enregistrerez dans le fichier lock les informations des packages au fur et à mesure de votre utilisation. Si le projet est déjà bien avancé comme dans notre exemple, il va partir d'un fichier lock contenant déjà les références des packages installés et utilisés. &lt;/p&gt;
&lt;h2 id="mettre-a-jour-les-dependances-avec-le-fichier-lock"&gt;Mettre à jour les dépendances avec le fichier lock&lt;/h2&gt;
&lt;p&gt;On présente les deux instructions les plus utiles de &lt;code&gt;renv&lt;/code&gt; : &lt;code&gt;restore()&lt;/code&gt; et &lt;code&gt;snapshot()&lt;/code&gt;. Ce sont elles qui permettent de raccorder l'état de votre environnement de packages en local par rapport à celui qui sera proposé à l'ouverture de votre projet &lt;code&gt;renv&lt;/code&gt;. C'est la fonction &lt;code&gt;status()&lt;/code&gt; qui permet de vérifier que votre environnement de packages utilisé à un moment T correspond bien à celui enregistré dans le fichier lock.   &lt;/p&gt;
&lt;h3 id="utilisation-de-renvrestore"&gt;Utilisation de &lt;code&gt;renv::restore()&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Imaginons que j'ouvre ce même projet sur un autre poste sur lequel &lt;code&gt;data.table&lt;/code&gt; n'est pas installé. En ouvrant le projet RStudio je vais avoir un message d'avertissement m'indiquant que mon environnement pourrait ne pas être à jour du projet. Je lance alors &lt;code&gt;renv::status()&lt;/code&gt;, qui me renvoie en effet :  &lt;/p&gt;
&lt;p&gt;&lt;img alt="Pelican" src="../images/renv/warning_renv.png"&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;L'absence d'installation de &lt;code&gt;data.table&lt;/code&gt; a bien été repérée. Comme suggéré, il suffit de lancer &lt;code&gt;renv::restore()&lt;/code&gt; pour que mon environnement de packages soit de nouveau à jour avec celui décrit dans le fichier lock. Il aurait fallu aussi envoyer cette instruction si la version de &lt;code&gt;data.table&lt;/code&gt; enregistrée sur votre poste ne correspondait plus à celle enregistrée dans le fichier lock. Cette instruction sert donc à rendre mon environnement de packages en local cohérent avec celui renseigné dans le fichier lock.     &lt;/p&gt;
&lt;h3 id="utilisation-de-renvsnapshot"&gt;Utilisation de &lt;code&gt;renv::snapshot()&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Je peux aussi vouloir changer le fichier lock suite à une évolution du code. Imaginons par exemple que je n'utilise plus &lt;code&gt;data.table&lt;/code&gt; pour importer mes données mais directement la fonction &lt;code&gt;read.csv()&lt;/code&gt;, qui fait partie des fonctions chargées automatiquement au lancement de RStudio. Cette modification des dépendances va être repérée et &lt;code&gt;renv::status()&lt;/code&gt; va renvoyer le message suivant :  &lt;/p&gt;
&lt;p&gt;&lt;img alt="Pelican" src="../images/renv/warning_renv2.png"&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Si au contraire j'avais installé et utilisé un nouveau package, c'est la même instruction qui m'aurait permis d'ajouter ses références au fichier lock. &lt;code&gt;renv::snapshot()&lt;/code&gt; permet donc de mettre à jour le fichier lock afin que mes modifications dans l'utilisation des packages soient prises en compte. &lt;strong&gt;Avant d'avoir lancé cette instruction, les modifications dans les dépendances de mon projet ne seront pas prises en compte par le gestionnaire de packages&lt;/strong&gt;.   &lt;/p&gt;
&lt;h2 id="petite-note-sur-git"&gt;Petite note sur git&lt;/h2&gt;
&lt;p&gt;Comme on l'a vu, l'utilisation de &lt;code&gt;renv&lt;/code&gt; est particulièrement intéressante dans le cadre d'un travail collaboratif. C'est donc naturellement qu'on l'utilisera avec git. Il est important de noter qu'il n'est pas nécessaire de versionner tout le dossier &lt;code&gt;renv&lt;/code&gt;, mais seulement le fichier lock, le script &lt;code&gt;renv/activate.R&lt;/code&gt; et le fichier &lt;code&gt;.Rprofile&lt;/code&gt; de la personne ayant initialisé le projet. Le reste du dossier &lt;code&gt;renv&lt;/code&gt; contient en effet des informations spécifiques à chaque poste, comme les liens vers le cache ayant stocké les packages installés. Il se mettra à jour automatiquement avec les trois fichiers versionnés. Pensez à vous &lt;a href="https://rstudio.github.io/renv/articles/collaborating.html"&gt;référer à la documentation avant de vous lancer&lt;/a&gt;.  &lt;/p&gt;
&lt;h1 id="conclusion"&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;Vous l'avez compris, &lt;code&gt;renv&lt;/code&gt; est un outil très précieux pour s'assurer que d'autres personnes ou vous-même pourront refaire tourner votre code sans difficultés. Il est sans doute nécessaire, mais pas suffisant : certains packages ont des dépendances externes comme javascript, il faut bien sûr veiller à ce que les données soient accessibles et identiques pour tous et que les scripts ne contiennent pas de paramètres spécifiques à un utilisateur. &lt;br&gt;
En plus des qualités présentées dans l'article, &lt;code&gt;renv&lt;/code&gt; vous permettra aussi de vous rendre compte du nombre de packages sur lequel repose votre projet, qui ne se limitent pas qu'aux packages installés mais aussi à leurs dépendances. Cela peut être une bonne occasion d'essayer de les réduire dans la mesure du possible. Récemment, un frisson a parcouru les quelques milliers de développeurs de packages R dépendant du package &lt;code&gt;lubridate&lt;/code&gt; quand ils ont reçu un mail du CRAN leur annonçant que ce dernier risquait d'être supprimé et qu'ils devaient ajuster leurs packages en conséquence. Naturellement, au vu de la popularité de &lt;code&gt;lubridate&lt;/code&gt;, cela &lt;a href="https://twitter.com/dvaughan32/status/1445459240718458881"&gt;n'arrivera finalement pas&lt;/a&gt;, mais c'est un rappel utile de la fragilité relative d'un projet avec de trop nombreuses dépendances.&lt;/p&gt;</content><category term="R"></category><category term="R"></category><category term="Rstats"></category><category term="renv"></category><category term="packages"></category><category term="CRAN"></category></entry><entry><title>Fonctionnement et performances d'across dans dplyr</title><link href="https://blog.statoscop.fr/fonctionnement-et-performances-dacross-dans-dplyr.html" rel="alternate"></link><published>2021-06-02T00:00:00+02:00</published><updated>2021-06-02T00:00:00+02:00</updated><author><name>Antoine</name></author><id>tag:blog.statoscop.fr,2021-06-02:/fonctionnement-et-performances-dacross-dans-dplyr.html</id><summary type="html">&lt;p&gt;Mise à jour de l'évaluation des performances du verbe &lt;code&gt;across&lt;/code&gt; dans dplyr version 1.0.6&lt;/p&gt;</summary><content type="html">&lt;div class="toc"&gt;&lt;span class="toctitle"&gt;Table des matières&lt;/span&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#across-ca-marche-comment"&gt;across(), ça marche comment?&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#syntaxe-de-base"&gt;Syntaxe de base&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#selection-avec-des-conditions"&gt;Sélection avec des conditions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#selection-a-partir-du-nom"&gt;Sélection à partir du nom&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#autres-proprietes"&gt;Autres propriétés&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#across-ca-tourne-comment"&gt;across(), ça tourne comment?&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#instructions-sur-lesquelles-on-compare-les-methodes"&gt;Instructions sur lesquelles on compare les méthodes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#resultats-de-la-version-106"&gt;Résultats de la version 1.0.6&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#resultats-de-la-version-100"&gt;Résultats de la version 1.0.0&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;A la sortie de l'été dernier, j'ai réalisé une &lt;a href="https://antoinesir.rbind.io/post/fonctionnement-de-across-dans-dplyr/" target="_blank"&gt;note sur mon blog personnel&lt;/a&gt; sur un élément important d'une mise à jour majeure de dplyr : &lt;code&gt;across()&lt;/code&gt;, un nouveau verbe pour réaliser des opérations sur plusieurs colonnes. Dans cette note, on utilisait la version &lt;code&gt;1.0.2&lt;/code&gt; de &lt;code&gt;dplyr&lt;/code&gt; et on comparait &lt;code&gt;across&lt;/code&gt; aux verbes équivalents que cela devait remplacer (fonctions indexées par &lt;code&gt;_at&lt;/code&gt;, &lt;code&gt;_if&lt;/code&gt; et &lt;code&gt;_all&lt;/code&gt;) . On constatait une moins bonne performance d' &lt;code&gt;across&lt;/code&gt; en termes de temps d'exécution. Cet élément était bien connu des développeurs de RStudio et a été constamment pris en compte dans les différentes mises à jour. On reprend ici cette note en la mettant à jour avec la version &lt;code&gt;1.0.6&lt;/code&gt; de &lt;code&gt;dplyr&lt;/code&gt; disponible à ce jour pour voir où se place désormais &lt;code&gt;across&lt;/code&gt; en termes de temps d'exécution.&lt;/p&gt;
&lt;p&gt;Si vous voulez balayer plus largement les différents éléments de la mise à jour de &lt;code&gt;dplyr&lt;/code&gt;, vous pouvez vous rendre sur &lt;a href="https://www.tidyverse.org/blog/2020/06/dplyr-1-0-0/" target="_blank"&gt;le site du tidyverse&lt;/a&gt; (en anglais) ou sur &lt;a href="https://thinkr.fr/hey-quoi-de-neuf-dplyr-le-point-sur-la-v1/#La_fonction_de_calcul_avec_conditions_sur_les_variables_across()" target="_blank"&gt;cet article du blog de ThinkR&lt;/a&gt; (en français) qui en présentent les changements majeurs. &lt;/p&gt;
&lt;h1 id="across-ca-marche-comment"&gt;&lt;code&gt;across()&lt;/code&gt;, ça marche comment?&lt;/h1&gt;
&lt;h2 id="syntaxe-de-base"&gt;Syntaxe de base&lt;/h2&gt;
&lt;p&gt;Le verbe &lt;code&gt;across()&lt;/code&gt; vise à remplacer toutes les fonctions suffixées par &lt;code&gt;_if&lt;/code&gt;, &lt;code&gt;_at&lt;/code&gt; et &lt;code&gt;_all&lt;/code&gt;. Il regroupe ces méthodes dans une seule et permet ainsi de les associer, ce qui n'était pas possible avant. Il s'utilise dans &lt;code&gt;mutate&lt;/code&gt; et &lt;code&gt;summarise&lt;/code&gt;. La syntaxe associée à ce verbe est la suivante :   &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nf"&gt;across&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;.cols&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;.fns&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Dans laquelle :&lt;br&gt;
 - Les colonnes &lt;code&gt;.cols&lt;/code&gt; peuvent être sélectionnées en utilisant la même syntaxe que pour la méthode &lt;code&gt;vars()&lt;/code&gt; (nom des variables, &lt;code&gt;starts_with&lt;/code&gt;, &lt;code&gt;end_with&lt;/code&gt;, &lt;code&gt;contains&lt;/code&gt;,...), mais aussi avec des conditions rentrées dans &lt;code&gt;where()&lt;/code&gt; qui sélectionneront de la même manière que le faisaient les fonctions suffixées par &lt;code&gt;_if&lt;/code&gt;.&lt;br&gt;
 - La fonction &lt;code&gt;.fns&lt;/code&gt; est définie comme auparavant (le nom de la fonction ou sa définition "à la volée" avec &lt;code&gt;~ my_fun(.)&lt;/code&gt;).  &lt;/p&gt;
&lt;p&gt;On présente quelques exemples en utilisant la table &lt;code&gt;penguins&lt;/code&gt; promue par &lt;a href="https://github.com/allisonhorst/palmerpenguins" target="_blank"&gt;Allison Horst&lt;/a&gt; pour remplacer l'usage de la table iris. Vous pouvez l'obtenir depuis le package &lt;code&gt;palmerpenguins&lt;/code&gt; sur le CRAN.  &lt;/p&gt;
&lt;h2 id="selection-avec-des-conditions"&gt;Sélection avec des conditions&lt;/h2&gt;
&lt;p&gt;À partir de cette table, l'instruction visant à sortir la moyenne de toutes les variables numériques s'écrivait auparavant :  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;penguins&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; &lt;span class="nf"&gt;summarise_if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;is.numeric&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;na.rm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;## # A tibble: 1 x 5&lt;/span&gt;
&lt;span class="c1"&gt;##   bill_length_mm bill_depth_mm flipper_length_mm body_mass_g  year&lt;/span&gt;
&lt;span class="c1"&gt;##            &amp;lt;dbl&amp;gt;         &amp;lt;dbl&amp;gt;             &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;&lt;/span&gt;
&lt;span class="c1"&gt;## 1           43.9          17.2              201.       4202. 2008.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Elle se réécrit avec &lt;code&gt;across()&lt;/code&gt; en utilisant &lt;code&gt;where()&lt;/code&gt; :  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;penguins&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; &lt;span class="nf"&gt;summarise&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;across&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;where&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;is.numeric&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;na.rm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="c1"&gt;## # A tibble: 1 x 5&lt;/span&gt;
&lt;span class="c1"&gt;##   bill_length_mm bill_depth_mm flipper_length_mm body_mass_g  year&lt;/span&gt;
&lt;span class="c1"&gt;##            &amp;lt;dbl&amp;gt;         &amp;lt;dbl&amp;gt;             &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;&lt;/span&gt;
&lt;span class="c1"&gt;## 1           43.9          17.2              201.       4202. 2008.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2 id="selection-a-partir-du-nom"&gt;Sélection à partir du nom&lt;/h2&gt;
&lt;p&gt;Si l'on souhaite sélectionner à partir du nom des variables, la nouvelle syntaxe est la suivante :  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# Ancienne version&lt;/span&gt;
&lt;span class="n"&gt;penguins&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; &lt;span class="nf"&gt;summarise_at&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;vars&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;matches&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;bill*|flipper*&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;na.rm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;## # A tibble: 1 x 3&lt;/span&gt;
&lt;span class="c1"&gt;##   bill_length_mm bill_depth_mm flipper_length_mm&lt;/span&gt;
&lt;span class="c1"&gt;##            &amp;lt;dbl&amp;gt;         &amp;lt;dbl&amp;gt;             &amp;lt;dbl&amp;gt;&lt;/span&gt;
&lt;span class="c1"&gt;## 1           43.9          17.2              201.&lt;/span&gt;

&lt;span class="c1"&gt;# Avec across()&lt;/span&gt;
&lt;span class="n"&gt;penguins&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; &lt;span class="nf"&gt;summarise&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;across&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;matches&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;bill*|flipper*&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;na.rm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="c1"&gt;## # A tibble: 1 x 3&lt;/span&gt;
&lt;span class="c1"&gt;##   bill_length_mm bill_depth_mm flipper_length_mm&lt;/span&gt;
&lt;span class="c1"&gt;##            &amp;lt;dbl&amp;gt;         &amp;lt;dbl&amp;gt;             &amp;lt;dbl&amp;gt;&lt;/span&gt;
&lt;span class="c1"&gt;## 1           43.9          17.2              201.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2 id="autres-proprietes"&gt;Autres propriétés&lt;/h2&gt;
&lt;p&gt;On note également qu'on peut combiner dorénavant les sélections sur les types des colonnes et sur leur nom dans une seule instruction &lt;code&gt;across()&lt;/code&gt;, ce qui n'était pas possible avant. Pour enlever les années des moyennes numériques, on peut par exemple écrire :   &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;penguins&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; &lt;span class="nf"&gt;summarise&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;across&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;where&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;is.numeric&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nf"&gt;contains&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;year&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;na.rm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="c1"&gt;## # A tibble: 1 x 4&lt;/span&gt;
&lt;span class="c1"&gt;##   bill_length_mm bill_depth_mm flipper_length_mm body_mass_g&lt;/span&gt;
&lt;span class="c1"&gt;##            &amp;lt;dbl&amp;gt;         &amp;lt;dbl&amp;gt;             &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt;&lt;/span&gt;
&lt;span class="c1"&gt;## 1           43.9          17.2              201.       4202.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Enfin, le paramètre &lt;code&gt;.names&lt;/code&gt; de &lt;code&gt;across()&lt;/code&gt; est également très pratique et permet notamment dans une instruction &lt;code&gt;mutate()&lt;/code&gt; de créer de nouvelles colonnes nommées à partir des anciennes auxquelles on peut se référer avec &lt;code&gt;.col&lt;/code&gt;. Par exemple, si je veux créer deux nouvelles colonnes passant les informations sur le bec en pouces mais en conservant les anciennes colonnes, je peux écrire :  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;penguins&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; 
  &lt;span class="nf"&gt;mutate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;across&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;starts_with&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;bill&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="o"&gt;~&lt;/span&gt; &lt;span class="n"&gt;.&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="m"&gt;0.04&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;.names&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;pouces_{.col}&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; 
  &lt;span class="nf"&gt;select&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;contains&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;bill&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; &lt;span class="nf"&gt;head&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;## # A tibble: 5 x 4&lt;/span&gt;
&lt;span class="c1"&gt;##   bill_length_mm bill_depth_mm pouces_bill_length_mm pouces_bill_depth_mm&lt;/span&gt;
&lt;span class="c1"&gt;##            &amp;lt;dbl&amp;gt;         &amp;lt;dbl&amp;gt;                 &amp;lt;dbl&amp;gt;                &amp;lt;dbl&amp;gt;&lt;/span&gt;
&lt;span class="c1"&gt;## 1           39.1          18.7                  1.56                0.748&lt;/span&gt;
&lt;span class="c1"&gt;## 2           39.5          17.4                  1.58                0.696&lt;/span&gt;
&lt;span class="c1"&gt;## 3           40.3          18                    1.61                0.72 &lt;/span&gt;
&lt;span class="c1"&gt;## 4           NA            NA                   NA                  NA    &lt;/span&gt;
&lt;span class="c1"&gt;## 5           36.7          19.3                  1.47                0.772&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h1 id="across-ca-tourne-comment"&gt;&lt;code&gt;across()&lt;/code&gt;, ça tourne comment?&lt;/h1&gt;
&lt;p&gt;À la sortie de la mise à jour de &lt;code&gt;dplyr&lt;/code&gt;, il avait été signalé que la méthode &lt;code&gt;across()&lt;/code&gt; impliquerait peut-être de légères pertes en termes de vitesse d'exécution par rapport aux anciennes méthodes &lt;code&gt;_at&lt;/code&gt;, &lt;code&gt;_if&lt;/code&gt; et &lt;code&gt;_all&lt;/code&gt;. On a mis en évidence ce problème avec la version &lt;code&gt;1.0.2&lt;/code&gt; de dplyr dans &lt;a href="https://antoinesir.rbind.io/post/fonctionnement-de-across-dans-dplyr/" target="_blank"&gt;la première version de cet article&lt;/a&gt;. Sur ce même modèle, on va comparer les instructions &lt;code&gt;_if&lt;/code&gt; et &lt;code&gt;_at&lt;/code&gt; d'un summarise groupé avec leurs équivalents dans &lt;code&gt;across()&lt;/code&gt; pour différentes tailles d'échantillons et de groupes.   &lt;/p&gt;
&lt;h2 id="instructions-sur-lesquelles-on-compare-les-methodes"&gt;Instructions sur lesquelles on compare les méthodes&lt;/h2&gt;
&lt;p&gt;On crée un tibble comportant 4 variables numériques et une variable facteur, et on va comparer la vitesse d'exécution des moyennes de ces variables numériques groupées par modalité de la variable facteur en faisant varier le nombre de lignes du tibble et le nombre de groupes (de modalités distinctes de la variable facteur). Le tibble est créé par exemple ainsi, pour 100 lignes et deux groupes :  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;nbrow&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="m"&gt;100&lt;/span&gt;
&lt;span class="n"&gt;nbgpe&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="m"&gt;2&lt;/span&gt;
&lt;span class="nf"&gt;as_tibble&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;data.frame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;rnorm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nbrow&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;x2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="nf"&gt;rnorm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nbrow&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; 
                     &lt;span class="n"&gt;x3&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;runif&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nbrow&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;x4&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;runif&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nbrow&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                     &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;as.factor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;floor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nbgpe&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;replace&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
                               &lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; 
  &lt;span class="nf"&gt;arrange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; 
  &lt;span class="nf"&gt;mutate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;across&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;where&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;is.numeric&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="o"&gt;~&lt;/span&gt; &lt;span class="nf"&gt;round&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;span class="c1"&gt;## # A tibble: 100 x 5&lt;/span&gt;
&lt;span class="c1"&gt;##       x1    x2    x3    x4 y    &lt;/span&gt;
&lt;span class="c1"&gt;##    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;fct&amp;gt;&lt;/span&gt;
&lt;span class="c1"&gt;##  1 -3.36  0.9   0.32  0.36 2    &lt;/span&gt;
&lt;span class="c1"&gt;##  2 -3.04  0.92  0.61  0.46 2    &lt;/span&gt;
&lt;span class="c1"&gt;##  3 -2.4   1.37  0.32  0.98 2    &lt;/span&gt;
&lt;span class="c1"&gt;##  4 -2.08  1.64  0.87  0.72 2    &lt;/span&gt;
&lt;span class="c1"&gt;##  5 -2.05  1.22  0.62  0.79 2    &lt;/span&gt;
&lt;span class="c1"&gt;##  6 -1.78 -1.28  0.58  0.31 2    &lt;/span&gt;
&lt;span class="c1"&gt;##  7 -1.56  1.19  0.96  0.58 2    &lt;/span&gt;
&lt;span class="c1"&gt;##  8 -1.55 -1.18  0.4   0.85 2    &lt;/span&gt;
&lt;span class="c1"&gt;##  9 -1.47  1.77  0.71  0.21 2    &lt;/span&gt;
&lt;span class="c1"&gt;## 10 -1.29 -0.6   0.68  0.4  2    &lt;/span&gt;
&lt;span class="c1"&gt;## # … with 90 more rows&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Sur chaque tibble (chaque combinaison du nombre de lignes et de groupes), les différentes instructions testées sont les suivantes :  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# summarise_if  &lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; &lt;span class="nf"&gt;group_by&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; &lt;span class="nf"&gt;summarise_if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;is.numeric&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; 

&lt;span class="c1"&gt;# across + where()  &lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; &lt;span class="nf"&gt;group_by&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; &lt;span class="nf"&gt;summarise&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;across&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;where&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;is.numeric&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;  

&lt;span class="c1"&gt;# summarise_at  &lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; &lt;span class="nf"&gt;group_by&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; &lt;span class="nf"&gt;summarise_at&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;vars&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;starts_with&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;x&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; 

&lt;span class="c1"&gt;# across + starts_with()  &lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; &lt;span class="nf"&gt;group_by&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; &lt;span class="nf"&gt;summarise&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;across&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;starts_with&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;x&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Toutes les instructions font la même chose : une moyenne groupée par &lt;code&gt;y&lt;/code&gt; des 4 variables numériques. L'idée est de vérifier que l'option &lt;code&gt;across&lt;/code&gt; n'est pas plus lente que les options &lt;code&gt;summarise_if&lt;/code&gt; et &lt;code&gt;summarise_at&lt;/code&gt;. &lt;/p&gt;
&lt;h2 id="resultats-de-la-version-106"&gt;Résultats de la version 1.0.6&lt;/h2&gt;
&lt;p&gt;Les résultats du &lt;code&gt;microbenchmark()&lt;/code&gt; pour les différentes combinaisons de nombres de groupes et de lignes sont présentés dans un graphique qui représente la distribution du temps d’exécution des 10 occurences testées pour chaque méthode :     &lt;/p&gt;
&lt;p&gt;&lt;img alt="Pelican" src="../images/across_files/unnamed-chunk-10-1.png"&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Sur nos exemples, il semblerait qu'&lt;code&gt;across&lt;/code&gt; ait complètement rattrapé son retard sur ses équivalents &lt;code&gt;_at&lt;/code&gt; et &lt;code&gt;_if&lt;/code&gt;. Il semble même légèrement plus performant dans certains cas de figure.  &lt;/p&gt;
&lt;h2 id="resultats-de-la-version-100"&gt;Résultats de la version 1.0.0&lt;/h2&gt;
&lt;p&gt;Pour illustrer le chemin parcouru, on peut refaire tourner cette même comparaison avec la version &lt;code&gt;1.0.0&lt;/code&gt; de &lt;code&gt;dplyr&lt;/code&gt; :  &lt;/p&gt;
&lt;p&gt;&lt;img alt="Pelican" src="../images/across_files/unnamed-chunk-11-1.png"&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;On constate bien que dans sa première version, &lt;code&gt;across&lt;/code&gt; connaissait de bien moins bonnes performances, en particulier sur les dataframes avec beaucoup de lignes et/ou beaucoup de groupes. Les mises à jour successives ont donc bien permis de combler ces problèmes de performance et c'est une excellente nouvelle car au niveau de la syntaxe, nous, on adore!  &lt;/p&gt;
&lt;p&gt;C'est tout pour aujourd'hui ! Comme d'habitude vous pouvez retrouver le fichier Rmarkdown ayant servi à générer cette note sur le &lt;a href="https://github.com/Statoscop/notebooks-blog" target="_blank"&gt;github de Statoscop&lt;/a&gt;.&lt;/p&gt;</content><category term="R"></category><category term="R"></category><category term="Rstats"></category><category term="dplyr"></category><category term="across"></category><category term="tidyverse"></category></entry><entry><title>Comparaisons base R, dplyr et data.table</title><link href="https://blog.statoscop.fr/comparaisons-base-dplyr-datatable.html" rel="alternate"></link><published>2021-03-30T00:00:00+02:00</published><updated>2021-03-30T00:00:00+02:00</updated><author><name>Antoine</name></author><id>tag:blog.statoscop.fr,2021-03-30:/comparaisons-base-dplyr-datatable.html</id><summary type="html">&lt;p&gt;Comparaisons des temps d'exécution de base R, dplyr et data.table sur quelques cas d'étude&lt;/p&gt;</summary><content type="html">&lt;div class="toc"&gt;&lt;span class="toctitle"&gt;Table des matières&lt;/span&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#rappels-sur-dplyr-et-datatable"&gt;Rappels sur dplyr et data.table&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#dplyr-et-le-tidyverse"&gt;dplyr et le tidyverse&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#datatable"&gt;Data.table&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#vitesses-dexecution"&gt;Vitesses d'exécution&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#comparaisons-sur-une-etude-de-cas-simple"&gt;Comparaisons sur une étude de cas simple&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#notre-etude-de-cas"&gt;Notre étude de cas&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#moyenne-des-retards-et-fusion-des-tables"&gt;Moyenne des retards et fusion des tables&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#comparaisons-des-vitesses-dexecution"&gt;Comparaisons des vitesses d'exécution&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;Cet article est une mise à jour de l'article du &lt;a href="https://antoinesir.rbind.io/post/comparaisons-base-r-dplyr-data-table/" target="_blank"&gt;blog d'Antoine&lt;/a&gt; réalisé en 2018. L'idée est de comparer les performances de trois alternatives dans R pour l'analyse de données : &lt;br&gt;
- l'utilisation des seules fonctions de base R&lt;br&gt;
- dplyr&lt;br&gt;
- data.table  &lt;/p&gt;
&lt;h1 id="rappels-sur-dplyr-et-datatable"&gt;Rappels sur dplyr et data.table&lt;/h1&gt;
&lt;p&gt;On rappelle ici les principales caractéristiques de ces packages mais pour se former à leur utilisation on peut se référer au &lt;a href="https://teaching.slmc.fr/perf/presentation_handout.pdf" target="_blank"&gt;cours de perfectionnement de Martin Chevalier&lt;/a&gt;. Pour une exploration de ce qu'englobe le &lt;code&gt;tidyverse&lt;/code&gt; et notamment une présentation des commandes de &lt;code&gt;dplyr&lt;/code&gt;, vous pouvez jeter un oeil à &lt;a href="https://juba.github.io/tidyverse/index.html" target="_blank"&gt;l'introduction à R et au tidyverse&lt;/a&gt; de J. Barnier. Enfin pour data.table, on trouve des informations utiles sur le cours &lt;a href="http://larmarange.github.io/analyse-R/manipulations-avancees-avec-data-table.html" target="_blank"&gt;Manipulations avancée avec data.table&lt;/a&gt; de J. Larmarange et on vous conseille l'excellent article &lt;a href="https://atrebas.github.io/post/2020-06-17-datatable-introduction/" target="_blank"&gt;a gentle introduction to data.table&lt;/a&gt;.  &lt;/p&gt;
&lt;h2 id="dplyr-et-le-tidyverse"&gt;dplyr et le tidyverse&lt;/h2&gt;
&lt;p&gt;Le &lt;code&gt;tidyverse&lt;/code&gt; (contraction de "tidy" et "universe") est un concept initié par Hadley Wickham, chef statisticien de RStudio. Il regroupe un ensemble de packages utiles au traitement statistique et au nettoyage de bases de données. On va s'intéresser ici presque seulement au package &lt;code&gt;dplyr&lt;/code&gt; (dont les instructions seront appliquées aux &lt;code&gt;tibbles&lt;/code&gt;, un format de data.frame issu du &lt;code&gt;tidyverse&lt;/code&gt;), mais vous pouvez parcourir les packages proposés dans le tidyverse sur &lt;a href="https://www.tidyverse.org/" target="_blank"&gt;le site officiel&lt;/a&gt;.  &lt;/p&gt;
&lt;p&gt;&lt;code&gt;dplyr&lt;/code&gt; propose un ensemble d'opérations de traitement de données sous une syntaxe différente de celle utilisée dans les fonctions de base de R. Ce langage présente le double avantage d'être à la fois lisible pour quelqu'un habitué aux langages tels que SAS ou SQL et de proposer des fonctions optimisées qui présentent de bonnes performances en termes de temps d'exécution. La grammaire &lt;code&gt;dplyr&lt;/code&gt; s'appuie en effet sur des fonctions au nom explicite :  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;mutate(data, newvar1=fonction(var1,var2...))&lt;/code&gt; et &lt;code&gt;transmute(data, newvar1=fonction(var1,var2...))&lt;/code&gt; créent de nouvelles variables&lt;/li&gt;
&lt;li&gt;&lt;code&gt;filter(data, condition)&lt;/code&gt; sélectionne au sein d'une table certaines observations, à la manière de &lt;code&gt;where&lt;/code&gt; dans SAS.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;arrange(data, var1, descending var2,...)&lt;/code&gt; trie une base selon une ou plusieurs variables (l'équivalent d'une &lt;code&gt;proc sort&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;select(data, var1 : varX)&lt;/code&gt; sélectionne certaines variables dans une base, à la manière de &lt;code&gt;keep&lt;/code&gt; dans SAS. &lt;/li&gt;
&lt;li&gt;&lt;code&gt;summarise(data, newvar1=mean(var1), newvar2=sum(var2))&lt;/code&gt; réalise toute sorte d'opérations statistiques sur une table.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;group_by(data, var)&lt;/code&gt; regroupe une table par une variable&lt;/li&gt;
&lt;li&gt;et bien d'autres...  &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Un aspect pratique de ce langage est que toutes ces opérations peuvent être chaînées à l'aide de l'opérateur &lt;code&gt;%&amp;gt;%&lt;/code&gt; ("pipe" en anglais, issu du package &lt;code&gt;magrittr&lt;/code&gt;) dont la syntaxe est la suivante : &lt;code&gt;data %&amp;gt;% fonction(...)&lt;/code&gt; est équivalent à &lt;code&gt;fonction(data, ...)&lt;/code&gt;. Cette syntaxe permet de chaîner un grand nombre d'opérations sur une base commune, en limitant le nombre de fois où l'on écrit des tables intermédiaires tout en conservant une grande lisibilité du code. Ce petit exemple vous en convaincra peut-être :  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nf"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dplyr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# on crée un data frame avec 100 lignes, &lt;/span&gt;
&lt;span class="c1"&gt;# chaque individu appartenant à un des 50 groupes&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;data.frame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;id1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="m"&gt;100&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;idgpe&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;50&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;replace&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# on y applique les instructions de dplyr&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; &lt;span class="nf"&gt;as_tibble&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; &lt;span class="nf"&gt;mutate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;var&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;rnorm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;100&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; 
  &lt;span class="nf"&gt;group_by&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;idgpe&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; &lt;span class="nf"&gt;summarise&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;var_mean&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;var&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;output_tibble&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Un regard peu habitué contesterait peut-être l'aspect très lisible de l'instruction, mais ça l'est réellement. Le déroulé est le suivant :  &lt;/p&gt;
&lt;p&gt;1) on transforme notre data.frame en tibble (pour rappel : format optimisé de data.frame pour dplyr) avec &lt;code&gt;as_tibble&lt;/code&gt;&lt;br&gt;
2) on crée une variable &lt;code&gt;var&lt;/code&gt; avec &lt;code&gt;mutate&lt;/code&gt;&lt;br&gt;
3) on agrège par  &lt;code&gt;idgpe&lt;/code&gt; avec &lt;code&gt;group_by&lt;/code&gt; &lt;br&gt;
4) on calcule la moyenne de &lt;code&gt;var&lt;/code&gt; avec &lt;code&gt;summarise&lt;/code&gt;, que l'on stocke dans &lt;code&gt;var_mean&lt;/code&gt;. Comme cette instruction suit un group_by, elle est réalisée à l'intérieur de chaque groupe (défini par &lt;code&gt;idgpe&lt;/code&gt;), sinon elle aurait été réalisé sur l'ensemble de la table.    &lt;/p&gt;
&lt;p&gt;Tout cela est stocké dans une table output_tibble, qui est ainsi un tibble agrégé par &lt;code&gt;idgpe&lt;/code&gt; et qui a donc 50 lignes. L'intérêt de ce chaînage est qu'il permet une économie de code et d'écriture d'éventuelles tables intermédiaires.  &lt;/p&gt;
&lt;h2 id="datatable"&gt;Data.table&lt;/h2&gt;
&lt;p&gt;Le package &lt;code&gt;data.table&lt;/code&gt; ne prétend pas, contrairement au &lt;code&gt;tidyverse&lt;/code&gt;, proposer une syntaxe concurrente à base R mais enrichir celle-ci. Il est axé autour d'un nouveau format d'objet, le data.table, qui est un type de data.frame qui permet une utilisation optimisée de l'opérateur &lt;code&gt;[&lt;/code&gt;.&lt;br&gt;
Tout data.frame peut être converti en data.table grâce à la fonction &lt;code&gt;as.data.table&lt;/code&gt;, ou, de manière plus optimale pour l'utilisation de la mémoire, grâce à la fonction &lt;code&gt;setDT&lt;/code&gt; qui permet de directement transformer la nature de l'objet sans avoir à en écrire un autre. Il est important d'avoir en tête qu'un data.frame converti en data.table conserve les caractéristiques d'un data.frame. Cependant, l'opérateur &lt;code&gt;[&lt;/code&gt; appliqué au data.table change de signification et devient :  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;DT&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;by&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Avec &lt;code&gt;i&lt;/code&gt; qui permet de sélectionner des observations (sans avoir besoin de répéter le nom de la base dans laquelle on se trouve), &lt;code&gt;j&lt;/code&gt; qui permet de créer ou sélectionner des variables et &lt;code&gt;by&lt;/code&gt; de regrouper les traitement selon les modalités d'une variable définie. Comme dans &lt;code&gt;dplyr&lt;/code&gt;, il est possible de chaîner les opérations réalisées comme le montre l'exemple suivant, qui reprend le même cas de figure que celui illustrant le package &lt;code&gt;dplyr&lt;/code&gt; :  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nf"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data.table&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; 
&lt;span class="c1"&gt;# on convertit notre data frame précédemment créé en data.table&lt;/span&gt;
&lt;span class="n"&gt;dt&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;as.data.table&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# on y applique les même instructions&lt;/span&gt;
&lt;span class="n"&gt;dt&lt;/span&gt;&lt;span class="p"&gt;[,&lt;/span&gt; &lt;span class="nf"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;var_mean&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;rnorm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;100&lt;/span&gt;&lt;span class="p"&gt;))),&lt;/span&gt; &lt;span class="n"&gt;by&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;idgpe&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;idgpe&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;output_dt&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Le fait de renseigner les variables au sein de &lt;code&gt;list()&lt;/code&gt; permet d'avoir une table en sortie au niveau de &lt;code&gt;idgpe&lt;/code&gt; (donc 50 observations), sans cela la variable est bien moyennée par groupe mais la table en sortie est toujours au niveau &lt;code&gt;id1&lt;/code&gt; (100 observations).   &lt;/p&gt;
&lt;h2 id="vitesses-dexecution"&gt;Vitesses d'exécution&lt;/h2&gt;
&lt;p&gt;Voilà donc pour les présentations! Allez, on montre le résultat d'un petit &lt;code&gt;microbenchmark&lt;/code&gt; des deux juste pour voir : &lt;/p&gt;
&lt;table class="dataframe"&gt;
&lt;caption&gt;Temps d'exécution en microsecondes&lt;/caption&gt;
&lt;thead&gt;
    &lt;tr&gt;&lt;th scope=col&gt;expr&lt;/th&gt;&lt;th scope=col&gt;lq&lt;/th&gt;&lt;th scope=col&gt;mean&lt;/th&gt;&lt;th scope=col&gt;uq&lt;/th&gt;&lt;th scope=col&gt;neval&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
    &lt;tr&gt;&lt;td&gt;dplyr     &lt;/td&gt;&lt;td&gt;9.79270&lt;/td&gt;&lt;td&gt;13.23297&lt;/td&gt;&lt;td&gt;14.367579&lt;/td&gt;&lt;td&gt;100&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;data.table&lt;/td&gt;&lt;td&gt;1.40644&lt;/td&gt;&lt;td&gt; 2.13729&lt;/td&gt;&lt;td&gt; 2.546176&lt;/td&gt;&lt;td&gt;100&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Sur cet exemple, on voit un avantage clair à data.table! Mais on est sur une toute petite table en entrée. On va essayer de se rapprocher de cas plus concrets en s'intéressant à un exemple sur des bases plus importantes.  &lt;/p&gt;
&lt;h1 id="comparaisons-sur-une-etude-de-cas-simple"&gt;Comparaisons sur une étude de cas simple&lt;/h1&gt;
&lt;p&gt;Les avantages et inconvénients de ces deux packages sont à l'origine de nombreux débats. Vous pouvez vous en convaincre en suivant &lt;a href="https://stackoverflow.com/questions/21435339/data-table-vs-dplyr-can-one-do-something-well-the-other-cant-or-does-poorly" target="_blank"&gt;cette discussion sur stackoverflow&lt;/a&gt;. On peut quand même dégager deux compromis :   &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Le choix de l'un ou l'autre des packages dépend beaucoup de ce que l'on va en faire (types d'analyses, taille des données, profils des utilisateurs du code...).   &lt;/li&gt;
&lt;li&gt;Les deux packages sont plus intéressants que base R pour l'analyse de données, que ce soit en termes de facilité d'écriture ou de performances.   &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Pour ce deuxième point, on va essayer de s'en convaincre ensemble avec ce petit exemple.&lt;/p&gt;
&lt;h2 id="notre-etude-de-cas"&gt;Notre étude de cas&lt;/h2&gt;
&lt;p&gt;Pour cet exemple, on utilise les données du package de Hadley Wickham que l'on trouve dans &lt;code&gt;nycflights13&lt;/code&gt;. En particulier, la base &lt;code&gt;flights&lt;/code&gt; donne toutes les heures de départ et d'arrivée selon les aéroports de départ et d'arrivée ainsi que les retards au départ et à l'arrivée. La base &lt;code&gt;weather&lt;/code&gt; donne elle des indications météo, heure par heure, dans chaque aéroport. &lt;br&gt;
Commençons par charger nos packages (n'oubliez pas de faire &lt;code&gt;install.packages("nom_pck")&lt;/code&gt; avant si vous ne l'avez jamais fait) et nos données : &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# Les packages nécessaires&lt;/span&gt;
&lt;span class="nf"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tidyverse&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# Regroupe différents packages, voir https://www.tidyverse.org/ &lt;/span&gt;
&lt;span class="nf"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data.table&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nf"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;microbenchmark&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# Pour les calculs de vitesse d&amp;#39;exécution&lt;/span&gt;
&lt;span class="nf"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nycflights13&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# Pour les données&lt;/span&gt;

&lt;span class="c1"&gt;# data.table pour tests avec data.table&lt;/span&gt;
&lt;span class="n"&gt;flightsdt&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;as.data.table&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;flights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;weatherdt&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;as.data.table&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weather&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2 id="moyenne-des-retards-et-fusion-des-tables"&gt;Moyenne des retards et fusion des tables&lt;/h2&gt;
&lt;p&gt;Un rapide examen des bases vous montre que la première étape avant toute analyse est comme souvent de regrouper les éléments de flights par heure et aéroport de départ pour pouvoir les fusionner avec la table weather, qui donnent les indications météo minute par minute. On écrit cette instruction de  3 manières différentes :  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;En base R&lt;/strong&gt;  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;flights_time_hour&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;aggregate.data.frame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="nf"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;arr_delay&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;flights&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;&lt;span class="n"&gt;arr_delay&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
         &lt;span class="n"&gt;dep_delay&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;flights&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;&lt;span class="n"&gt;dep_delay&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; 
    &lt;span class="nf"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;time_hour&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;flights&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;&lt;span class="n"&gt;time_hour&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
         &lt;span class="n"&gt;origin&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;flights&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;&lt;span class="n"&gt;origin&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; 
    &lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;output_base&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;merge&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weather&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;flights_time_hour&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                     &lt;span class="n"&gt;by&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;time_hour&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;origin&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; 
                     &lt;span class="n"&gt;sort&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;FALSE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;En dplyr&lt;/strong&gt;  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;flights&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; &lt;span class="nf"&gt;group_by&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;time_hour&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;origin&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; 
  &lt;span class="nf"&gt;summarise&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;arr_delay&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;arr_delay&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
            &lt;span class="n"&gt;dep_delay&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dep_delay&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; 
  &lt;span class="nf"&gt;ungroup&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt; 
  &lt;span class="nf"&gt;inner_join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weather&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;by&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;time_hour&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;origin&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;output_dplyr&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;En data.table&lt;/strong&gt;  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;output_DT&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;merge&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;flightsdt&lt;/span&gt;&lt;span class="p"&gt;[,&lt;/span&gt; &lt;span class="nf"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;arr_perc_delay&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;arr_delay&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                                    &lt;span class="n"&gt;dep_perc_delay&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dep_delay&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; 
                             &lt;span class="n"&gt;by&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;time_hour&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;origin&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)],&lt;/span&gt; 
                   &lt;span class="n"&gt;weatherdt&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                   &lt;span class="n"&gt;by&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;time_hour&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;origin&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;On utilise la fonction &lt;code&gt;merge&lt;/code&gt; plutôt que &lt;code&gt;DT1[DT2, on = c("time_hour", "origin"), nomatch = 0]&lt;/code&gt; car on a constaté qu'elle était plus rapide, conformément à ce que montre bien cet &lt;a href="https://jozefhajnala.gitlab.io/r/r006-merge/" target="_blank"&gt;article du Jozef's Rblog&lt;/a&gt;.  &lt;/p&gt;
&lt;h2 id="comparaisons-des-vitesses-dexecution"&gt;Comparaisons des vitesses d'exécution&lt;/h2&gt;
&lt;p&gt;Chacun jugera de la lisibilité de chacune de ces instructions, qui font toutes la même chose, car c'est finalement assez subjectif. On donne ici les résultats d'un &lt;code&gt;microbenchmark&lt;/code&gt; de ces instructions : &lt;/p&gt;
&lt;table class="dataframe"&gt;
&lt;caption&gt;Temps d'exécution en millisecondes&lt;/caption&gt;
&lt;thead&gt;
    &lt;tr&gt;&lt;th scope=col&gt;expr&lt;/th&gt;&lt;th scope=col&gt;lq&lt;/th&gt;&lt;th scope=col&gt;mean&lt;/th&gt;&lt;th scope=col&gt;uq&lt;/th&gt;&lt;th scope=col&gt;neval&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
    &lt;tr&gt;&lt;td&gt;Base &lt;/td&gt;&lt;td&gt;1182.33161&lt;/td&gt;&lt;td&gt;1396.52780&lt;/td&gt;&lt;td&gt;1559.42968&lt;/td&gt;&lt;td&gt;10&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;dplyr&lt;/td&gt;&lt;td&gt; 223.45642&lt;/td&gt;&lt;td&gt; 313.16457&lt;/td&gt;&lt;td&gt; 360.95388&lt;/td&gt;&lt;td&gt;10&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;DT   &lt;/td&gt;&lt;td&gt;  22.83487&lt;/td&gt;&lt;td&gt;  24.68264&lt;/td&gt;&lt;td&gt;  26.32068&lt;/td&gt;&lt;td&gt;10&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Les résultats sont très nettement en faveur des packages &lt;code&gt;dplyr&lt;/code&gt; et &lt;code&gt;data.table&lt;/code&gt;. Ce dernier est même assez largement le plus rapide, son avantage s'étant accru depuis la première version de cette article. Sans doute existe-t-il des moyens de plus optimiser l'instruction en base R, mais là n'est pas vraiment la question. On voit qu'avec une syntaxe simple et lisible, &lt;code&gt;dplyr&lt;/code&gt; et &lt;code&gt;data.table&lt;/code&gt; font beaucoup mieux en termes de vitesse d'exécution que les fonctions de base R. &lt;/p&gt;</content><category term="R"></category><category term="R"></category><category term="Rstats"></category><category term="dplyr"></category><category term="data.table"></category><category term="benchmark"></category></entry></feed>