Title: Entra√Ænement de Yolo V7 sur des donn√©es personnelles
Author: Louis
Date: '2023-01-09'
Slug: yolov7-gradient
Category: Python, Deep Learning
Tags: Python, PyTorch, Machine Learning, Deep Learning, Computer Vision, Object Detection, Image segmentation, Yolo, Paperspace, Paperspace Gradient, GPU training, GPU cloud
Cover: images/cover_14.jpg
Summary: Entra√Ænement de Yolo V7 sur des donn√©es personnelles et sans GPU hardware

[TOC]  

Vous avez tr√®s envie d'utiliser Yolo V7 sur votre probl√©matique de reconnaissance d'objet ou de segmentation mais vous n'avez pas de gros ordinateur avec une groooosse carte graphique pour faire de grooooooooooos calculs d'optimisation de poids. Pas de panique, il y a des solutions et on vous en propose une ici.

# Utilisation du GPU

Le petite magicien qui rend l'entra√Ænement des mod√®les de deep learning tr√®s profonds, c'est lui : le GPU. *Cool mais d√©j√† c'est quoi ? Et puis comment je fais si j'en ai pas ?*

## Le GPU

Une unit√© de traitement graphique ou GPU (*Graphics Processing Unit*) est une puce informatique pour traiter les t√¢ches de rendu graphique. Les GPU sont con√ßus pour effectuer de nombreux calculs simultan√©ment, ce qui les rend particuli√®rement efficaces pour le rendu graphiques 2D/3D ou le traitement de vid√©os mais pas seulement. Le GPU fonctionne conjointement avec le CPU et permet, en fonctionnant sp√©cialement pour le rendu images, de lib√©rer de la puissance de traitement pour le CPU qui peut se consacrer aux autres t√¢ches sans limiter les performances de la carte graphique.

Le GPU est g√©n√©ralement dispos√© sur la carte graphique (d'o√π la confusion parfois entre les 2) mais pas n√©cessairement. En effet la puce GPU peut √™tre int√©gr√©e √† un CPU sur le m√™me circuit, sur une carte graphique ou dans la carte m√®re d'un ordinateur ou d'un serveur. 

## GPU, CPU, JSUIPERDU...

Un GPU est plus efficace qu'un CPU pour le rendu d'images gr√¢ce √† son architecture de traitement parall√®le lui permettant d'effectuer de nombreux calculs simultan√©ment. Un seul CPU ne dispose pas de cette fonctionnalit√© (bien que ce soit possible avec des processeurs multic≈ìurs). En revanche un CPU a une fr√©quence plus √©lev√©e et peut effectuer un calcul plus rapidement qu'un GPU.

Pour r√©sumer, le GPU est con√ßu pour le parall√©lisme des donn√©es et pour appliquer la m√™me op√©ration √† plusieurs √©l√©ments de donn√©es (SIMD pour *Single Instruction to Multiple Data*) tandis qu'un CPU est con√ßu pour le parall√©lisme des t√¢ches et l'ex√©cution de diff√©rentes op√©rations non li√©es.

Si votre ordinateur est forc√©ment √©quip√© d'un CPU, il n'a pas n√©cessairement de GPU puisque le chipset de la carte m√®re peut g√©rer le rendu graphique (beaucoup moins bien qu'une carte graphique certes).

## GPU et *Deep Learning*

*"Bon ok, je suis toujours pas sp√©cialiste, mais je vois le principe. Par contre, on √©tait pas sur YoloV7 nous ?"*  

YoloV7 est un r√©seau de neurones √† convolution qui a quasi 37 millions de param√®tres...lorsque vous souhaitez utiliser le mod√®le d√©j√† entra√Æn√© sur le jeu de donn√©es [COCO](https://cocodataset.org/#home), pas de probl√®mes de hardware, √ßa fonctionnera sans ressources suppl√©mentaires. Si par contre vous voulez r√©-entra√Æner le mod√®le sur vos donn√©es, l√† √ßa se complique et si vous n'avez pas de GPU, vous avez int√©r√™t √† avoir √©norm√©ment de temps devant vous, et d'ailleurs √ßa ne suffira m√™me pas, car alors c'est la m√©moire qui vous manquera.

Sans entrer dans les d√©tails de l'optimisation de r√©seau de neurones, les op√©rations √† effectuer sont des calculs matriciels pas tellement complexe mais r√©p√©titifs et surtout, extr√™mement nombreux. La parall√©lisation de ces op√©rations sur un GPU est donc id√©ale et n√©cessaire pour optimiser le r√©seau dans un temps viable.

## Les sevices de GPU cloud

*"On y voit un peu plus clair...mais comment on fait quand on en a pas ?"*

Puisqu'on a pas les capacit√©s localement, on va le faire √† distance gr√¢ce aux services Cloud qui proposent du GPU. Ils sont nombreux (Linode, Paperspace, Google Cloud GPUs, Elastic GPU Service, Azure N series, IBM Cloud, AWS and NVIDIA, OVHcloud, etc...) mais on va s'en tenir a un : [Paperspace](https://www.paperspace.com/). L'int√©r√™t est d'utiliser [Paperspace Gradient](https://www.paperspace.com/gradient) qui facilite la cr√©ation de machine avec des templates int√©gr√©s (au hasard, PyTorch), l'utilisation et l'entra√Ænement de mod√®les √† parir de notebooks. Si on le souhaite, on peut louer directement du GPU avec Paperspace CORE.

# Cas pratique : la reconnaissance de d√©chets

L'objectif est d'entra√Æner le mod√®le Yolo V7 √† identifier et reconna√Ætre des d√©chets. On utilisera pour cela le dataset [TACO](http://tacodataset.org/) et on va faire l'entra√Ænement sur Paperspace Gradient.

## Gradient Paperspace

Que ce soit clair, on pas de parts dans Paperspace, c'est juste un des fournisseurs de GPU cloud et que Gradient est bien pens√© pour des probl√©matiques Machine Learning. √âvidemment, si vous souhaitez utiliser un autre fournisseur et y faire tourner ce notebook, c'est tout √† fait possible, il faudra juste d'installer sur votre VM l'ensemble des d√©pendances n√©cessaires et notamment jupyter. Ceci √©tant dit, voil√† comment faire avec Gradient :

1. Cr√©ez un compte sur [Paperspace](https://console.paperspace.com/signup)  
2. Cr√©ez un projet  
<img src="../images/yolov7_gradient/gradient1.png" width="50%"/>
3. Dans votre projet, cr√©ez un notebook en choisissant un template (PyTorch par exemple ou bien From Scratch) et un type de GPU selon votre compte et la disponibilit√©  
<img src="../images/yolov7_gradient/gradient2.png" width="50%"/>
4. Bienvenus sur votre VM avec son GPU associ√© qui doit avoir le statut "Running", vous pouvez uploader un notebook par exemple celui-ci  
<img src="../images/yolov7_gradient/gradient3.png" width="50%"/>

On s'√©tendra pas plus sur cette partie qui est sp√©cifique √† Gradient et pas aux services de GPU cloud en g√©n√©ral. On vous laisse creuser si vous le souhaitez mais consid√©rons √† partir de maintenant que tout le code qui suit est ex√©cut√© directement dans l'IDE Jupyter Lab de notre VM Gradient (Jupyter Lab est disponible dans le barre d'outils √† gauche).

## Le dataset TACO

On ne d√©taillera pas ici le traitement du dataset car ce n'est pas l'objet de cette note. En revanche, le notebook [TACO_dataset](https://github.com/Statoscop/notebooks-blog/tree/main/Entrainer%20YoloV7/TACO_dataset.ipynb) reprend l'ensemble des op√©rations concernant le jeu de donn√©es, √† savoir :

1. clonage du repo TACO  
2. installation du `requirements.txt`  
3. r√©cup√©ration des images annot√©es au format YOLO
4. exploration du dataset avec les fonctions disponibles dans le script [`cocoviz.py`](https://github.com/Statoscop/notebooks-blog/tree/main/Entrainer%20YoloV7/cocoviz.py)
5. transformation des annotations du format COCO au format YOLO. Encore une fois, on explicite pas ici cette transformation mais quelques √©l√©ments toutefois : COCO utilise un seul fichier json dans lequel il stocke toutes les annotations de toutes les images avec des positions absolues alors que YOLO utilise des positions relatives et normalis√©es dans un fichier txt par image  
6. modification des classes pour ne garder que les super-cat√©gories : ce n'est pas optimal pour la d√©tection d'objets mais √ßa permet de simplifier un peu ce cas pratique th√©orique o√π le pouvoir pr√©dictif de notre mod√®le n'a pas une grande importance

Vous pouvez uploader ce notebook [TACO_dataset](https://github.com/Statoscop/notebooks-blog/tree/main/Entrainer%20YoloV7/TACO_dataset.ipynb) sur Gradient et l'ex√©cuter directement pour t√©l√©charger les images, annotations et effectuer l'ensemble des pr√©traitements. √Ä la fin de l'ex√©cution, vous disposerez donc, sur votre VM, des donn√©es pr√™tes (ou presque) √† √™tre utilis√©es pour l'entra√Ænement de YoloV7. On y vient.

## L'entra√Ænement de YoloV7

### R√©cup√©ration du code de YoloV7

On clone directement le d√©p√¥t de [yolov7](https://github.com/WongKinYiu/yolov7.git) pour pouvoir r√©entrainer le mod√®le sur nos donn√©es. Bien noter que le repo sera clon√© sur votre VM Gradient d'o√π vous ex√©cuter ce notebook.


```python
!git clone https://github.com/WongKinYiu/yolov7.git
```

    Clonage dans 'yolov7'...
    remote: Enumerating objects: 1127, done.
    remote: Counting objects: 100% (29/29), done.
    remote: Compressing objects: 100% (25/25), done.
    remote: Total 1127 (delta 12), reused 14 (delta 4), pack-reused 1098
    R√©ception d'objets: 100% (1127/1127), 69.96 Mio | 16.98 Mio/s, fait.
    R√©solution des deltas: 100% (522/522), fait.


On installe ensuite les d√©pendances n√©cessaires de YoloV7. Selon la machine GPU choisie sur Gradient, vous pourrez avoir besoin ou pas de downgrader les versions de `Torch` et `Torchvision`. Ici c'√©tait le cas avec une VM A4000.


```python
!pip install -r ./yolov7/requirements.txt
!pip install setuptools==59.5.0
!pip install torchvision==0.11.3+cu111 -f https://download.pytorch.org/whl/cu111/torch_stable.html
```

    Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.9/dist-packages (from -r ./yolov7/requirements.txt (line 4)) (3.5.2)
    Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from -r ./yolov7/requirements.txt (line 5)) (1.23.1)
    Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.9/dist-packages (from -r ./yolov7/requirements.txt (line 6)) (4.6.0.66)
    Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.9/dist-packages (from -r ./yolov7/requirements.txt (line 7)) (9.2.0)
    Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.9/dist-packages (from -r ./yolov7/requirements.txt (line 8)) (5.4.1)

       [............]

    WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
    Looking in links: https://download.pytorch.org/whl/cu111/torch_stable.html
    Collecting torchvision==0.11.3+cu111
      Downloading https://download.pytorch.org/whl/cu111/torchvision-0.11.3%2Bcu111-cp39-cp39-linux_x86_64.whl (24.5 MB)
         ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 24.5/24.5 MB 63.2 MB/s eta m0:00:0000:0100:01
    Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision==0.11.3+cu111) (9.2.0)
    Collecting torch==1.10.2
      Downloading https://download.pytorch.org/whl/cu111/torch-1.10.2%2Bcu111-cp39-cp39-linux_x86_64.whl (2137.7 MB)
         ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2.1/2.1 GB 1.2 MB/s eta m0:00:00:00:0100:02m
    Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision==0.11.3+cu111) (1.23.1)
    Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.10.2->torchvision==0.11.3+cu111) (4.3.0)
    Installing collected packages: torch, torchvision
      Attempting uninstall: torch
        Found existing installation: torch 1.12.1
        Uninstalling torch-1.12.1:
          Successfully uninstalled torch-1.12.1
      Attempting uninstall: torchvision
        Found existing installation: torchvision 0.13.1
        Uninstalling torchvision-0.13.1:
          Successfully uninstalled torchvision-0.13.1
    ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
    torchaudio 0.12.0+cu116 requires torch==1.12.0, but you have torch 1.10.2+cu111 which is incompatible.
    Successfully installed torch-1.10.2+cu111 torchvision-0.11.3+cu111
    WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
    

√Ä ce stade, vous avez vos donn√©es ainsi que le code et les d√©pendances pour pouvoir l'utiliser. Il n'y donc plus qu'√† entra√Æner.  
*"Ah oui mais non mon petit bonhomme, on va pas entra√Æner un mod√®le sur toutes nos donn√©es, sans faire de d√©coupage √©chantillons entra√Ænement/validation/test"* me direz-vous...

### Train test split

Si elle n'est pas au coeur de notre article, le *train test split* reste une √©tape fondamentale pour l'entra√Ænement de tout mod√®le de machine learning. On pr√©sente donc la streat√©gie utilis√©e, une m√©thode "√† la main" √† partir des noms d'images en cr√©ant des dossiers associ√©s √† chaque sous-√©chantillons. On met directement les datasets `train`, `val`, `test` ainsi que le fichier .yaml associ√© dans le repo yolov7 pour l'entra√Ænement puisque c'est √† partir de ce repo, en utilisant le script `train.py` qu'on va r√©entrainer le mod√®le YoloV7.

**Petite note en passant :** le fichier .yaml dont on parle est le fichier de configuration de l'entra√Ænement. Il contient comme informations les chemins des diff√©rents datasets ainsi que le nombre de cat√©gories √† identifier et leur nom. On le cr√©e directement dans la cellule ci-dessous.


```python
import json
import os
import random
from tqdm import tqdm
import shutil
import datetime
import re
```


```python
# Split dataset

# read json file
with open('./TACO/data/images/annotations_wo_subdir.json', 'r+') as file:
    json_file = json.load(file)
    
# create directories (with replacement if exists)
for dirname in ['train', 'val', 'test']:
    dirpath = f"./yolov7/data/TACOpoly/{dirname}"
    if os.path.exists(dirpath):
        shutil.rmtree(dirpath)
    os.makedirs(dirpath + '/images')
    os.makedirs(dirpath + '/labels')
    
# create yaml file (with replacement if exists)
cats = [cat['name'] for cat in json_file['categories']]

with open('./yolov7/data/TACOpoly.yaml', 'w') as f:
    f.write(
f"""train: ./data/TACOpoly/train/images
val: ./data/TACOpoly/val/images
test: ./data/TACOpoly/test/images

nc: {len(cats)}
names: {cats}""")
    
    
# read json annotations file
with open('./TACO/data/images/annotations_wo_subdir.json', 'r+') as file:
    json_file = json.load(file)

# get images names and shuffle
img_names = [img['file_name'].split('.')[0] for img in json_file['images']]
random.shuffle(img_names)

# create a splitting dictionnary
split = {
    'train' : img_names[:1200],
    'val' : img_names[1200:1400],
    'test' : img_names[1400:]
}

# copy each image and its label in the right directory
for setname, sample in split.items():
    print(f"Copying images to {setname.upper()} directory")
    for imgname in tqdm(sample):
        shutil.copy(f"./TACO/data/images/{imgname}.jpg", f"./yolov7/data/TACOpoly/{setname}/images/{imgname}.jpg")
        shutil.copy(f"./TACO/data/labels_poly/{imgname}.txt", f"./yolov7/data/TACOpoly/{setname}/labels/{imgname}.txt")
```

    Copying images to TRAIN directory
    100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1200/1200 [01:50<00:00, 10.84it/s]
    Copying images to VAL directory
    100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:17<00:00, 11.56it/s]
    Copying images to TEST directory
    100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:08<00:00, 11.31it/s]


Voil√†, cette fois plus de contretemps, on est par√© pour l'entra√Ænement.

### Entra√Ænement

Pour gagner du temps, on ne va pas repartir de z√©ro avec des poids initiaux compl√©tement al√©atoires mais on va charger les poids d'un mod√®le pr√©-entra√Æn√©. On doit dans un premier temps t√©l√©charger ces poids puis lancer l'entra√Ænement sur nos donn√©es. Pour cela, on se place dans le repo yolov7 et on t√©l√©charge les poids en question.


```python
%cd /notebooks/yolov7
```

    /notebooks/yolov7



```python
if os.path.exists('yolov7_training.pt'):
    print("D√©j√† t√©l√©charg√©")
else:
    !wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt
```

    D√©j√† t√©l√©charg√©


La fonction `get_last_weights` ci-dessous n'est pas du tout n√©cessaire √† l'entra√Ænement de YoloV7 mais peut avoir son utilit√©. Je vous invite donc √† regarder rapidement ce qu'elle fait sans pour autant vous y attarder.

**Une petite explication quand m√™me :** les machines Gradient s'arr√™te automatiquement au bout de 6 heures ce qui n'est pas mal mais pas assez pour atteindre de bonnes performances du mod√®le. Il faudra donc relancer l'entra√Ænement plusieurs fois pour atteindre un nombre d'√©poques suffisant. Deux strat√©gies sont possibles :

1. la plus √©vidente : on lance d√®s le d√©part un entra√Ænement avec un grand d'√©poques et si la machine se stoppe, alors il suffira de relancer l'entra√Ænement avec l'option `--resume` qui offre la possibilit√© de reprendre l'entra√Ænement o√π il s'√©tait arr√™t√© (`!python train.py --resume`). Le probl√®me de cette m√©thode est que `train.py` sauvegarde des poids interm√©diaires tout au long de l'entra√Ænement et que ces fichiers sont lourds. Il faudra donc supprimer en partie ces fichiers √† la main avant de relancer l'entra√Ænement pour √©viter d'atteindre le plafond de stockage offert par Gradient.
2. un approche plus ma√Ætris√©e : on fait un nombre d'√©poques plus restreint dont on sait qu'il sera termin√© en moins de 6 heures et on repart √† chaque fois du meilleur poids du dernier entra√Ænement. La fonction `get_last_weights` r√©cup√®re simplement ces meilleurs derniers poids. Cela va permettre de ne pas garder en m√©moire les autres fichiers de poids en les supprimant d√®s la nouvelle s√©rie d'√©poques termin√©e.


```python
def get_last_weights(modelname):
    """
    This function retrieves the best weights from the last training in order to
    restart new traing from those weights.
    
    Parameters
    ----------
    modelname : str
        Name of the model (such as --name argument from Yolov7 train.py script).
        This is the name looked for in the yolov7/runs/train directory.
    nb_epochs : int
        Number of epochs done per each training.

    Returns
    -------
    str :
        Path to weights used to initiate new training.
    int :
        Number of epochs already trained.  
    """
        
    # keep only directories containg modelname in their name
    train_dirs = []
    for dirname in os.listdir('/notebooks/yolov7/runs/train/'):
        if modelname in dirname:
            train_dirs.append(dirname)
    train_dirs.sort()
    
    # returns yolov7_training weights and 0 epochs if never trained
    if len(train_dirs) == 0:
        return 'yolov7_training.pt', 0

    # else retrieve the last weights and compute number of epochs
    # this assumes that the number of epochs is the same over each training
    nmax = 0
    for dirname in train_dirs:
        if dirname.split(modelname)[-1] == '' :
            dirmax = dirname
        else:
            n = int(dirname.split(modelname)[-1])
            if n > nmax :
                nmax = n
                dirmax = dirname

    return f"runs/train/{dirmax}/weights/best.pt"
```

Cette fois √ßa y est. C'est vraiment le moment de l'entra√Ænement ! Pour ce qui concerne les diff√©rents param√®tres pass√©s en arguments de la commande `python train.py`, vous √™tes cordialement convi√©s √† regarder du c√¥t√© de l'aide pour y voir plus clair. Allez, on arr√™te de bosser et on laisse le GPU transpirer un peu. 

<iframe src="https://giphy.com/embed/l4FATJpd4LWgeruTK" width="480" height="270" frameBorder="0" class="giphy-embed" allowFullScreen></iframe>


```python
epochs_per_training = 150
init_weights = get_last_weights('TACOpoly')
start = datetime.datetime.now()

print(f"ENTRA√éNEMENT D√âBUT√â √Ä {start.strftime('%H:%M')} AVEC LES POIDS INITIAUX {init_weights}")
print(f"_________________________________________________________________")


!python train.py --workers 8 --device 0 --batch-size 16 --data data/TACOpoly.yaml --img 640 640 \
    --cfg cfg/training/yolov7.yaml --weights {init_weights} --name TACOpoly \
    --hyp data/hyp.scratch.custom.yaml --epochs {epochs_per_training}

print(f"_________________________________________________________________")
print(f"DUR√âE DE L'ENTRA√éNEMENT : {datetime.datetime.now() - start}")
```

    ENTRA√éNEMENT D√âBUT√â √Ä 10:24 AVEC LES POIDS INITIAUX runs/train/TACOpoly7/weights/best.pt
    _________________________________________________________________
    YOLOR üöÄ v0.1-115-g072f76c torch 1.10.2+cu111 CUDA:0 (NVIDIA RTX A4000, 16117.3125MB)
    
    Namespace(weights='runs/train/TACOpoly7/weights/best.pt', cfg='cfg/training/yolov7.yaml', data='data/TACOpoly.yaml', hyp='data/hyp.scratch.custom.yaml', epochs=150, batch_size=16, img_size=[640, 640], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='0', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=8, project='runs/train', entity=None, name='TACOpoly', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', freeze=[0], v5_metric=False, world_size=1, global_rank=-1, save_dir='runs/train/TACOpoly8', total_batch_size=16)

       [............]
    
         Epoch   gpu_mem       box       obj       cls     total    labels  img_size
       145/149       11G  0.008686  0.003024 0.0004638   0.01217        82       640
                   Class      Images      Labels           P           R      mAP@.5
                     all         200         648        0.43       0.204       0.194       0.162
    
         Epoch   gpu_mem       box       obj       cls     total    labels  img_size
       146/149       11G  0.008719  0.003078 0.0004409   0.01224        52       640
                   Class      Images      Labels           P           R      mAP@.5
                     all         200         648       0.555        0.18       0.193        0.16
    
         Epoch   gpu_mem       box       obj       cls     total    labels  img_size
       147/149       11G  0.008701  0.003087 0.0005799   0.01237        89       640
                   Class      Images      Labels           P           R      mAP@.5
                     all         200         648       0.427       0.212       0.193       0.161
    
         Epoch   gpu_mem       box       obj       cls     total    labels  img_size
       148/149       11G   0.00864  0.003092 0.0004653    0.0122        73       640
                   Class      Images      Labels           P           R      mAP@.5
                     all         200         648       0.621       0.174       0.191       0.159
    
         Epoch   gpu_mem       box       obj       cls     total    labels  img_size
       149/149       11G  0.008513  0.003076 0.0005339   0.01212        70       640
                   Class      Images      Labels           P           R      mAP@.5
                     all         200         648       0.626       0.171       0.194        0.16
          Aluminium foil         200          11       0.919       0.545       0.565       0.556
            Blister pack         200           1           1           0           0           0
                  Bottle         200          54       0.655       0.574       0.628       0.535
              Bottle cap         200          32       0.579       0.281       0.416       0.317
            Broken glass         200          15           1           0           0           0
                     Can         200          29       0.457       0.552       0.473       0.428
                  Carton         200          35       0.454         0.2        0.22        0.16
                     Cup         200          26        0.53       0.269       0.294       0.215
              Food waste         200           2           1           0           0           0
               Glass jar         200           1           1           0           0           0
                     Lid         200          18       0.782       0.333       0.353       0.333
           Other plastic         200          57       0.325      0.0702      0.0748      0.0585
                   Paper         200          21       0.375       0.143       0.128        0.11
               Paper bag         200           5       0.469         0.4       0.361       0.345
    Plastic bag & wrapper         200         132       0.498       0.308        0.34       0.273
       Plastic container         200           8       0.364        0.25       0.292       0.281
         Plastic glooves         200           1           1           0           0           0
        Plastic utensils         200           3           0           0      0.0198      0.0198
                 Pop tab         200           8       0.452        0.25       0.284       0.224
          Rope & strings         200           3           0           0      0.0953      0.0695
             Scrap metal         200           7           1           0           0           0
                    Shoe         200           1           1           0           0           0
         Squeezable tube         200           1           1           0      0.0476      0.0476
                   Straw         200          41       0.697      0.0976       0.141      0.0793
         Styrofoam piece         200           9       0.231       0.111       0.158      0.0891
        Unlabeled litter         200          59       0.418      0.0735       0.113      0.0811
               Cigarette         200          68       0.694       0.162       0.236        0.11
    150 epochs completed in 4.421 hours.
    
    Optimizer stripped from runs/train/TACOpoly8/weights/last.pt, 75.1MB
    Optimizer stripped from runs/train/TACOpoly8/weights/best.pt, 75.1MB
    _________________________________________________________________
    DUR√âE DE L'ENTRA√éNEMENT : 4:26:29.827454


Comme √©voqu√© pr√©c√©dement, si l'entra√Ænement s'est bien termin√© sans erreur, on peut supprimer **le contenu du dossier** de l'entra√Ænement pr√©c√©dent pour √©viter de surcharger le stockage du compte Paperspace Gradient. Il faut en revanche **conserver le dossier**, m√™me vide, car sinon les nouveaux entra√Ænement seront stock√©s dans ces dossiers-l√† et on va se perdre dans quels sont les derniers poids (c'est d√ª √† la m√©thode d'indentation des noms de dossiers dans le code source de yolov7).


```python
last_weights = get_last_weights('TACOpoly')

if (init_weights != 'yolov7_training.pt') & os.path.exists(last_weights):
    dir_to_empty = os.path.dirname(os.path.dirname(init_weights))
    shutil.rmtree(dir_to_empty)
    os.makedirs(dir_to_empty)
```

√áa y est, enfin, apr√®s un certain nombre d'√©poques (entre 600 et 1000 √† la grosse louche), votre mod√®le devrait √™tre suffisamment performant et vous n'avez plus qu'√† r√©cup√©rer les poids `best.pt` de votre dernier entra√Ænement pour faire votre inf√©rence. Bonne chance et amusez-vous bien !


C'est la fin de cet article! N'h√©sitez pas √† [visiter notre site](https://www.statoscop.fr) et √† nous suivre sur [Twitter](https://twitter.com/stato_scop) et [Linkedin](https://www.linkedin.com/company/statoscop). Pour retrouver l'ensemble du code ayant servi √† g√©n√©rer cette note, vous pouvez vous rendre sur le [github de Statoscop](https://github.com/Statoscop/notebooks-blog).  
